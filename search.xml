<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos7基于ansible批量部署SSH免密钥]]></title>
    <url>%2F2018%2F06%2F14%2FCentos-ansible-nokey-deploy.html</url>
    <content type="text"><![CDATA[应用场景：作为运维，经常会遇到批量管理Linux服务器，为了免去输入远程服务器的账号密码苦恼，可使用SSH的免秘钥登录 解决方案：生成密钥对1ssh-keygen -t rsa -f ~/.ssh/id_rsa -P &quot;&quot; 添加/etc/ansible/hosts主机123[server]172.16.2.31172.16.2.32 批量分发秘钥1ansible server -m authorized_key -a &quot;user=root key=&apos;&#123;&#123; lookup(&apos;file&apos;,&apos;/root/.ssh/id_rsa.pub&apos;) &#125;&#125;&apos;&quot; -k]]></content>
      <categories>
        <category>运维部署记录</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consul集群搭建，配合nginx完成服务动态发现和健康检查]]></title>
    <url>%2F2018%2F06%2F13%2Fnginx-consul-upsync.html</url>
    <content type="text"><![CDATA[概述介绍consul是一个服务发现和配置共享的服务软件，结合nginx的主动健康检查模块nginx_upstream_check_module和服务发现模块nginx-upsync-module，实现一套服务动态发现机制。nginx的upstream不再通过手动配置，而是定时向consul发送请求，获取consul数据中心的配置文件，动态更新upstream地址池。 术语consul：是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件 nginx_upstream_check_module：nginx主动健康检查模块 nginx-upsync-module：nginx服务发现模块 安装nginxnginx需要编译两个模块：nginx_upstream_check_module：nginx主动健康检查模块1https://github.com/xiaokai-wang/nginx_upstream_check_module nginx-upsync-module：nginx服务发现模块1https://github.com/weibocom/nginx-upsync-module 1./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_realip_module --http-client-body-temp-path=/var/tmp/nginx/client/ --http-proxy-temp-path=/var/tmp/nginx/proxy/ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi --http-scgi-temp-path=/var/tmp/nginx/scgi --with-pcre --add-module=../nginx-upsync-module-master --add-module=/root/nginx-module-vts consul官网 https://www.consul.io 下载consul,linux 64位 下载解压即可，产生一个consul可执行文件。 ./consul 列出一些常用指令。 consul启动123456789101112131415161718./consul agent -server –bootstrap-expect 1 –data-dir /tmp/consul –bind=172.16.2.30 –ui –client 0.0.0.0 &amp;server： 以server身份启动。bootstrap-expect：集群要求的最少server数量，当低于这个数量，集群即失效。经测试，低于这个数量也不影响访问data-dir：data存放的目录，更多信息请参阅consul数据同步机制node：节点id，在同一集群不能重复。bind：监听的ip地址。client 客户端的ip地址&amp; ：在后台运行，此为linux脚本语法ui：启动webui，端口8500 访问ip:8500/ consul其它命令关闭1./consul leave 查看成员1./consul members 启动consul集群以上介绍的都是以单机模式启动，实战中consul多以集群模式存在，建议server节点数为3~5个。以下以3台为例，分别为ip1、ip2、ip3：1234567./consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=consul1 -bind=ip1 -ui -client=0.0.0.0 &amp;./consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=consul2 -bind=ip2 -join=ip1 -ui -client=0.0.0.0 &amp;./consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=consul3 -bind=ip3 -join=ip1 -ui -client=0.0.0.0 &amp;-join 加入一个集群 加入后端服务器(或可以在界面KEY/VALUE操作)1234在任一节点上执行如下命令，即可添加2个key-value信息：curl -X PUT -d &apos;&#123;&quot;weight&quot;:10, &quot;max_fails&quot;:2, &quot;fail_timeout&quot;:10, &quot;down&quot;:0&#125;&apos; http://172.16.2.30:8500/v1/kv/upstreams/test/172.16.2.31:80curl -X PUT -d &apos;&#123;&quot;weight&quot;:10, &quot;max_fails&quot;:2, &quot;fail_timeout&quot;:10, &quot;down&quot;:0&#125;&apos; http://172.16.2.30:8500/v1/kv/upstreams/test/172.16.2.32:80 删除后端服务器(或可以在界面KEY/VALUE操作)123curl -X DELETE http://172.16.2.30:8500/v1/kv/upstreams/test/172.16.2.31:80curl -X DELETE http://172.16.2.30:8500/v1/kv/upstreams/test/172.16.2.32:80 调整后端服务的参数(或可以在界面KEY/VALUE操作)1curl -X PUT -d &apos;&#123;&quot;weight&quot;:10, &quot;max_fails&quot;:2, &quot;fail_timeout&quot;:10, &quot;down&quot;:0&#125;&apos; http://172.16.2.30:8500/v1/kv/upstreams/test/172.16.2.31:80 使用nginx&amp;upstream配置consul是针对nginx的upstream所做的一项改善，地址池不再需要手动配置，而是从consul的数据中心抓取。新的upstream配置如下： 123456789upstream tomcat_http_server &#123; server 127.0.0.1:11111; upsync 172.16.2.30:8500/v1/kv/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/server/server_test.conf; check interval=1000 rise=2 fall=2 timeout=3000 type=http default_down=false; check_http_send &quot;HEAD / HTTP/1.0\r\n\r\n&quot;; check_http_expect_alive http_2xx http_3xx;&#125; server 127.0.0.1:11111是占位机器，这个配置必须要有不然校验配置文件不通过。 upsync配置语法： upsync $consul/etcd.api.com:$port/v1/kv/upstreams/$upstream_name/ [upsync_type=consul/etcd] [upsync_interval=second/minutes] [upsync_timeout=second/minutes] [strong_dependency=off/on] 默认upsync_interval=5s upsync_timeout=6m strong_dependency=off 172.16.2.30:8500/v1/kv/upstreams/tomcat_http_server为同步地址；upsync_timeout同步超时时间；upsync_interval同步间隔；upsync_type同步类型，默认为consul；strong_dependency，配置为on时，每次启动或重启nginx，都会强制去consul拉一次upstream servers。 upsync_dump_path将拉取到的upstreams地址池写入一个文件； 此处想要多说两句，即使consul中途挂掉，nginx仍然可以从upsync_dump_path配置的文件中取到数据，继续分发流量，只是此时upstream池变为静态了，跟之前的情形一样，启停重启nginx等操作并没有问题。所以consul单节点配置中心的可用性也是很高的。 check代表健康检查；interval检查间隔，单位为毫秒；rise成功该次数后，标记为up；fall失败该次数后，标记为down；timeout；type包括tcp、ssl_hello、http、mysql、ajp、fastcgi；default_down设置后端server的初始状态； 默认配置interval=30000 fall=5 rise=2 timeout=1000 default_down=true type=tcp check_http_send 健康检查发送的请求包； check_http_expect_alive 这些状态代表后端server是活着的； 查询健康检查状态健康检查模块提供了一个接口check_status，用于检查consul数据中心配置的所有server的健康检查状态。需要在nginx稍作配置： 在80端口下，配置nstatus的接口：1234location /nstatus &#123; check_status; access_log off;&#125;]]></content>
      <categories>
        <category>运维部署记录</category>
      </categories>
      <tags>
        <tag>Ngins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡之LVS-基本概念和三种模式]]></title>
    <url>%2F2018%2F06%2F11%2Fload-balance-lvs-base.html</url>
    <content type="text"><![CDATA[LVS简介LVS中文官方手册：http://www.linuxvirtualserver.org/zh/index.html。这个手册对于了解lvs的背景知识很有帮助。 LVS英文官方手册：http://www.linuxvirtualserver.org/Documents.html。这个手册比较全面，对于了解和学习lvs的原理、配置很有帮助。 LVS是章文嵩开发的一个国产开源负载均衡软件。LVS最初是他在大学期间的玩具，随着后来使用的用户越来越多，LVS也越来越完善，最终集成到了Linux的内核中。有不少开源牛人都为LVS开发过辅助工具和辅助组件，最出名的就是Alexandre为LVS编写的Keepalived，它最初专门用于监控LVS，后来加入了通过VRRP实现高可用的功能。LVS的全称是Linux virtual server，即Linux虚拟服务器。之所以是虚拟服务器，是因为LVS自身是个负载均衡器(director)，不直接处理请求，而是将请求转发至位于它后端真正的服务器realserver上。 LVS是四层(传输层tcp/udp)、七层(应用层)的负载均衡工具，只不过大众一般都使用它的四层负载均衡功能ipvs，而七层的内容分发负载工具ktcpvs(kernel tcp virtual server)不怎么完善，使用的人并不多。 ipvs是集成在内核中的框架，可以通过用户空间的程序ipvsadm工具来管理，该工具可以定义一些规则来管理内核中的ipvs。就像iptables和netfilter的关系一样。 LVS-ipvs三种模式的工作原理首先要解释的是LVS相关的几种IP： VIP:virtual IP，LVS服务器上接收外网数据包的网卡IP地址。DIP:director IP，LVS服务器上转发数据包到realserver的网卡IP地址。RIP:realserver(常简称为RS)上接收Director转发数据包的IP，即提供服务的服务器IP。CIP:客户端的IP。 LVS的三种工作模式：通过网络地址转换(NAT)将一组服务器构成一个高性能的、高可用的虚拟服务器，是VS/NAT技术。在分析VS/NAT的缺点和网络服务的非对称性的基础上，提出了通过IP隧道实现虚拟服务器的方法VS/TUN（Virtual Server via IP Tunneling），和通过直接路由实现虚拟服务器的方法VS/DR（Virtual Server via Direct Routing），它们可以极大地提高系统的伸缩性。 VS/NAT模式客户端发送的请求到达Director后，Director根据负载均衡算法改写目标地址为后端某个RIP(web服务器池中主机之一)并转发给该后端主机，就像NAT一样。当后端主机处理完请求后，后端主机将响应数据交给Director，并由director改写源地址为VIP后传输给客户端。大多数商品化的IP负载均衡硬件都是使用此方法，如Cisco的LocalDirector、F5的Big/IP。这种模式下： RIP和DIP一般处于同一私有网段中。但并非必须，只要它们能通信即可。 各RealServer的网关指向DIP，这样能保证将响应数据交给Director。 VS/NAT模式的最大缺点是Director负责所有进出数据：不仅处理客户端发起的请求，还负责将响应传输给客户端。而响应数据一般比请求数据大得多，调度器Director容易出现瓶颈。(也就是像7层负载的处理方式一样，但却没有7层负载那么”多功能”) 这种模式配置起来最简单。 VS/TUN模式采用NAT技术时，由于请求和响应报文都必须经过调度器地址重写，当客户请求越来越多时，调度器的处理能力将成为瓶颈。为了解决这个问题，调度器把请求报文通过IP隧道转发至真实服务器，而真实服务器将响应直接返回给客户，所以调度器只处理请求报文。由于一般网络服务响应报文比请求报文大许多，采用VS/TUN技术后，调度器得到极大的解放，集群系统的最大吞吐量可以提高10倍。VS/TUN模式的工作原理： (1)IP隧道技术又称为IP封装技术，它可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上； (2)VS/TUN模式下，调度器和后端服务器组之间使用IP隧道技术。当客户端发送的请求(CIP–&gt;VIP)被director接收后，director修改该报文，加上IP隧道两端的IP地址作为新的源和目标地址，并将请求转发给后端被选中的一个目标； (3)当后端服务器接收到报文后，首先解封报文得到原有的CIP–&gt;VIP，该后端服务器发现自身的tun接口上配置了VIP，因此接受该数据包。 (4)当请求处理完成后，结果将不会重新交给director，而是直接返回给客户端。此时响应数据包的源IP为VIP，目标IP为CIP。 采用VS/TUN模式时的基本属性和要求： RealServer的RIP和director的DIP不用处于同一物理网络中，且RIP必须可以和公网通信。也就是说集群节点可以跨互联网实现。 realserver的tun接口上需要配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。 director给realserver时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而realsever响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是director的还是服务器组中的。 director只处理入站请求，响应请求由realserver完成。 一般来说，VS/TUN模式会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在Cache服务器本地命中的情况下，Cache服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。 VS/DR模式VS/TUN模式下，调度器对数据包的处理是使用IP隧道技术进行二次封装。VS/DR模式和VS/TUN模式很类似，只不过调度器对数据包的处理是改写数据帧的目标MAC地址，通过链路层来负载均衡。 VS/DR通过改写请求报文的目标MAC地址，将请求发送到真实服务器，而真实服务器将响应直接返回给客户。同VS/TUN技术一样，VS/DR技术可极大地提高集群系统的伸缩性。这种方法没有IP隧道的开销，对集群中的真实服务器也没有必须支持IP隧道协议的要求，但是要求调度器与真实服务器都有一块网卡连在同一物理网段上，以便使用MAC地址通信转发数据包。VS/DR模式的工作原理： (1)客户端发送的请求被director接收后，director根据负载均衡算法，改写数据帧的目标MAC地址为后端某RS的MAC地址，并将该数据包转发给该RS(实际上是往整个局域网发送，但只有该MAC地址的RS才不会丢弃)。 (2)RS接收到数据包后，发现数据包的目标IP地址为VIP，而RS本身已经将VIP配置在了某个接口上，因此RS会接收下这个数据包并进行处理。 (3)处理完毕后，RS直接将响应报文响应给客户端。此时数据包源IP为VIP，目标IP为CIP。也就是说，客户端请求发送到LB上，源和目标IP为CIP:VIP，LB上有VIP和DIP，重新改写MAC地址后通过DIP发送给某个realserver，如RS1，此时源和目标IP还是CIP:VIP，但是目标MAC地址改写为RIP1所在网卡的MAC地址”RS1_MAC”，RS1发现自身有VIP地址，所以收下此数据报文(所以在RS上必须配置VIP)。返回时，RS1根据路由表直接返回给客户端，此时，源和目标IP是VIP–&gt;CIP。但由于流出接口为RIP所在网卡接口，因此源MAC地址为RIP所在接口的MAC地址。这一细节在考虑CIP、RIP不同网段时的配置时很重要。 采用VS/DR模式时的基本属性和要求： RealServer的RIP和director的DIP必须处于同一网段中，以便使用MAC地址进行通信。 realserver上必须配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。 realsever响应给客户端的数据包的源和目标IP为VIP–&gt;CIP。 director只处理入站请求，响应请求由realserver完成。 lvs-ipvs的三种模式比较在性能上，VS/DR和VS/TUN远高于VS/NAT，因为调度器只处于从客户到服务器的半连接中，按照半连接的TCP有限状态机进行状态迁移，极大程度上减轻了调度器的压力(真正建立TCP连接的是RS和Client)。VS/DR性能又稍高于VS/TUN，因为少了隧道的开销。但是，VS/DR和VS/TUN的主要区别是VS/TUN可以跨网络实现后端服务器负载均衡(也可以局域网内)，而VS/DR只能和director在局域网内进行负载均衡。 VS/TUN和VS/DR模式中的ARP问题当一个目标IP地址为VIP的数据包进入Director前端的路由器时，路由器会向局域网内发送ARP广播，以找出VIP地址的MAC地址在哪台主机上。 Director和各RS都配置了VIP。当路由器发送ARP广播后，Director和RS都会收到这个广播包，且都认为这个广播包找的就是自己，于是都回应给路由器，这样路由器上的ARP缓存表中的条目VIPvip_MAC就不断被覆盖直到最后一个回应。这样一来，路由器将把客户端的数据包发送给最后一个回应的主机，这台主机的VIP可能是Director上的，也可能是某个RS上的。在一定时间内，路由器收到目标IP为VIP的数据包都会发送给该主机。但路由器会定时发送ARP广播包，这样一来ARP缓存表中的VIP对应的MAC地址可能会换成另一台主机。 因此，必须要保证路由器只保存Director上VIP对应的MAC地址，即只允许Director才对路由器的ARP广播进行回应。也就是说，所有RS上的VIP必须隐藏起来。 一般通过将Real Server上的VIP设置在lo接口的别名接口上(如lo:0)，并设置arp_ignore=1和arp_announce=2的方式来隐藏RS上的VIP。12echo 1 &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho 2 &gt;/proc/sys/net/ipv4/conf/all/arp_announce 或者12sysctl -w net.ipv4.conf.all.arp_ignore=1sysctl -w net.ipv4.conf.all.arp_announce=2 或者将arp参数设置到内核参数配置文件中以让其永久生效。123echo &quot;net.ipv4.conf.all.arp_ignore=1&quot; &gt;&gt;/etc/sysctl.confecho &quot;net.ipv4.conf.all.arp_announce=2&quot; &gt;&gt;/etc/sysctl.confsysctl -p 在网上几乎所有文章还设置了lo接口上的arp参数：12echo 1 &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho 2 &gt;/proc/sys/net/ipv4/conf/lo/arp_announce 但这没有任何意义，因为从lo接口不受arp参数的影响。 应该在配置VIP之前就设置arp参数，以防止配置VIP后、设置arp抑制之前被外界主机发现。 LVS负载均衡的调度算法LVS的调度算法，详细内容见官方手册：http://www.linuxvirtualserver.org/zh/lvs4.html 。 IPVS在内核中的负载均衡调度是以连接为粒度的。在HTTP协议（非持久）中，每次从WEB服务器上获取资源都需要建立一个TCP连接，同一用户的不同请求会被调度到不同的服务器上，所以这种细粒度的调度在一定程度上可以避免单个用户访问的突发性引起服务器间的负载不平衡。 LVS分为两种调度方式：静态调度和动态反馈调度。 静态调度方式是指不管RS的繁忙程度，根据调度算法计算后轮到谁就调度谁。例如两台realserver，一开始双方都在处理500个连接，下一个请求到来前，server1只断开了10个，而server2断开了490个，但是此时轮到了server1，就会调度server1而不管繁忙的程度。 动态调度方式是指根据RS的繁忙程度反馈，计算出下一个连接应该调度谁(动态反馈负载均衡算法考虑服务器的实时负载和响应情况，不断调整服务器间处理请求的比例，来避免有些服务器超载时依然收到大量请求，从而提高整个系统的吞吐率)。 在内核中的连接调度算法上，IPVS已实现了以下八种调度算法：默认的算法为wlc。 静态调度： 轮叫调度（Round-Robin Scheduling,rr） 加权轮叫调度（Weighted Round-Robin Scheduling,wrr），按照权重比例作为轮询标准 目标地址散列调度（Destination Hashing Scheduling,dh），目标地址哈希，对于同一目标IP的请求总是发往同一服务器 源地址散列调度（Source Hashing Scheduling,sh），源地址哈希，在一定时间内，只要是来自同一个客户端的请求，就发送至同一个realserver 动态反馈调度： 最小连接调度（Least-Connection Scheduling,lc），调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某服务器，其连接数加1；当连接中止或超时，其连接数减1。当各个服务器的处理能力不同时，该算法不理想。 加权最小连接调度（Weighted Least-Connection Scheduling,wlc） 基于本地的最少连接（Locality-Based Least Connections Scheduling,lblc），目前该算法主要用于cache集群系统。 带复制的基于局部性最少连接（Locality-Based Least Connections with Replication Scheduling,lblcr），目前主要用于Cache集群系统。]]></content>
      <categories>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署Gitolite、Centos7记录]]></title>
    <url>%2F2018%2F06%2F08%2Fdeployment-gitolite-recode.html</url>
    <content type="text"><![CDATA[Gitolite架构 安装Gitolie(服务端操作)12345678910111213141516171819202122232425# install from EPEL[root@server01 ~]# yum --enablerepo=epel -y install gitolite3[root@server01 ~]# su - gitolite3-sh-4.2$ ssh-keygen -f ~/.ssh/gitadmin -sh-4.2$ gitolite setup -pk ~/.ssh/gitadmin.pub-sh-4.2$ vi ~/.ssh/config# create new# any name you likehost GitServer user gitolite3 # Git server&apos;s hostname or IP address hostname 172.16.2.30 port 22 # secret key identityfile ~/.ssh/gitadmin-sh-4.2$ chmod 600 ~/.ssh/config -sh-4.2$ git config --global user.name &quot;gitolite3&quot; -sh-4.2$ git config --global user.email &quot;ywthings@qq.com&quot; -sh-4.2$ git config --global push.default simple-sh-4.2$ git clone ssh://GitServer/gitolite-admin至此，gitolite已经安装完成 生成SSH Key（客户端操作，以下linux操作，windows使用git工具）123[root@server02 ~]# ssh-keygen#一路回车键即可，不要输入密码，如输入密码，git clone时会提示输入密码 将生成的SSH public key拷贝到服务器（客户端操作）123[root@server02 ~]# scp /root/.ssh/id_rsa.pub gitolite3@172.16.2.30:/var/lib/gitolite3/gitolite-admin/keydir#可以直接复制密钥内容即可，以上方式注意权限问题 修改gitolite配置文件（服务端操作）1234#使用gitolite3用户登录服务器#客户端的公钥保存在/var/lib/gitolite3/gitolite-admin/keydir#修改权限/var/lib/gitolite3/gitolite-admin/conf/gitolite.conf#上传代码即可 增加仓库只需要在/var/lib/gitolite3/gitolite-admin/conf/gitolite.conf文件修改即可12repo ljs-bis RW+ = @developer 然后提交代码，自动创建git仓库]]></content>
      <categories>
        <category>运维部署记录</category>
      </categories>
      <tags>
        <tag>gitolite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7上使用Tripwire监控和检测修改的文件]]></title>
    <url>%2F2018%2F05%2F30%2Flinux-filesystem-tripwire.html</url>
    <content type="text"><![CDATA[Tripwire是一个免费的开源入侵检测系统（IDS）。 它是用于监视和警告系统上文件更改的安全工具。 Tripwire是一个功能强大的IDS，可以保护您的系统免受不必要的更改。 您可以使用它来监控您的系统文件，包括网站文件，因此当有不需要的文件更改时，Tripwire会检查您的系统，如果设置正确，可以通过电子邮件提醒您。 在CentOS 7上安装Tripwire123yum updateyum install epel-releaseyum install tripwire 安装完成后，我们需要生成新的密钥文件。 Tripwire使用2个关键文件。 site-key：它用于保护Tripwire配置。 因此，除非我们再次生成配置，否则对tripwire配置所做的任何更改都不会生效，我们会提示您输入“site-key”密码。 local-key：它用于验证tripwire二进制文件。 当我们想要更新tripwire系统数据库时，我们需要运行tripwire命令，并且会提示我们输入’local-key’的密码。 我们使用下面的命令生成新的tripwire密钥文件（站点和本地密钥）。1tripwire-setup-keyfiles 该命令将生成两个密钥文件“site-key”和“local-key”，并且您将被要求输入每个密码。 输入您自己的“ 网站密钥 ”密码，然后按Enter键。 输入您自己的“ 本地密钥 ”密码并再次按Enter键。 接下来，使用’site-key’签署tripwire配置,输入您的“ 网站密钥 ”密码。现在，为了签署Tripwire政策，请输入您的“ 本地密钥 ”密码。 配置Tripwire策略使用下面的tripwire命令初始化tripwire数据库。1tripwire --init 您可能会收到错误消息“no such directory”，如下所示 是因为系统没有在tripwire配置中已经定义的目录和文件。 为了解决这个错误，我们需要编辑tripwire配置’twpol.txt’并重新签署tripwire配置。 现在使用下面的命令从tripwire生成日志错误。1sh -c &quot;tripwire --check | grep Filename &gt; no-directory.txt&quot; 所有不存在于CentOS 7系统上的目录和文件都列在文件no-directory.txt中使用以下bash脚本编辑tripwire配置’twpol.txt’ - 在终端上运行此脚本。123for f in $(grep &quot;Filename:&quot; no-directory.txt | cut -f2 -d:); dosed -i &quot;s|\($f\) |#\\1|g&quot; /etc/tripwire/twpol.txtdone 毕竟，我们需要使用twadmin命令重新生成并重新签署tripwire配置，如下所示。1twadmin -m P /etc/tripwire/twpol.txt 输入您的“网站密钥”密码。重新初始化tripwire数据库，并确保没有错误。1tripwire --init 验证Tripwire配置和检查系统要验证tripwire配置，我们可以运行系统检查命令如下。1tripwire --check 将新规则添加到Tripwire策略在这一步中，我们将向您展示如何将新规则添加到tripwire策略配置“twpol.txt”。 要执行这项工作，我们需要定义规则名称，严重程度，监视目录和文件类型。 在这一步中，我们将在/var/www/目录下为我们的WordPress安装创建一个名为Wordpress Data的新规则，严重程度为HIGH/SIG_HI,并且该目录中的所有文件都是关键的以及源代码不能更改）。 转到tripwire配置目录/etc/tripwire并使用vim编辑配置文件twpol.txt。12cd /etc/tripwire/vim twpol.txt 转到该行的末尾，并在那里粘贴以下WordPress规则。12345678# Ruleset for Wordpress ( rulename = &quot;Wordpress Data&quot;, severity= $(SIG_HI) ) &#123; /var/www -&gt; $(SEC_CRIT); &#125; 保存并退出。 使用twadmin命令重新生成并重新签名配置，如下所示。1twadmin -m P /etc/tripwire/twpol.txt 输入您的“网站密钥”密码。现在我们需要再次重新生成tripwire数据库。1tripwire --init 输入“本地密钥”密码。新的规则集已添加并应用于Tripwire策略配置。 安装Tripwire电子邮件通知和Cron在这一步中，我们将为特定tripwire规则集策略配置通知，并配置用于自动系统检查的cronjob。 我们会将任何违反WordPress数据规则的报告发送到电子邮件地址myemail@gmail.com。 对于电子邮件通知，tripwire在配置中提供了一个emailto功能。 默认情况下，tripwire使用Postfix或Sendmail通过电子邮件发送报告。 在配置电子邮件通知之前，请使用以下命令测试tripwire通知功能。1tripwire --test --email email@gmail.com 现在进入/etc/tripwire目录并编辑twpol.txt配置。12cd /etc/tripwire/vim twpol.txt 在WordPress数据规则中添加新行emailto，如下所示。123456789# Ruleset for Wordpress ( rulename = &quot;Wordpress Data&quot;, severity= $(SIG_HI), emailto = myemail@gmail.com ) &#123; /var/www -&gt; $(SEC_CRIT); &#125; 保存并退出。使用twadmin命令重新生成并签署配置。1twadmin -m P /etc/tripwire/twpol.txt 输入您的“网站密钥”密码。并重新生成tripwire数据库。1tripwire --init 输入您的tripwire’local-key’密码。Tripwire电子邮件通知的配置已完成。注意： –email-report：将系统报告发送到每个规则中定义的电子邮件地址。 接下来，我们将使用cron setup启用自动Tripwire系统检查。 为此，请使用下面的crontab命令在root用户下创建一个新的cron脚本。1crontab -e -u root 粘贴以下cron配置。10 0 * * * tripwire --check --email-report 保存并退出。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Tripwire</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[winscp 普通用户登录sftp后切换到root权限]]></title>
    <url>%2F2018%2F05%2F25%2Fwinscp-switch-root.html</url>
    <content type="text"><![CDATA[工具： Xshell、winscp服务器环境： linux RedHat 6.4遇到的问题：普通用户使用winscp账户登录服务器，没有操作权限！ 一、普通用户，通过Xshell登录服务器。输入以下命令，再输入密码。切换为root。1su 二、先查找sftp-server 文件夹所在的系统路径，得到sftp-server文件路径后。12[root@LJS-CSS-APP3 ~]# cat /etc/ssh/sshd_config|grep sftp[root@LJS-CSS-APP3 ~]# /usr/libexec/openssh/sftp-server 再输入vim命令来编辑修改 /etc/sudoers配置文件1[root@LJS-CSS-APP3 ~]# vim /etc/sudoers 或者visudo 修改内容具体如下： 1、在文本中找到下语句 1root ALL=(ALL) ALL 2、在其下面增加以下语句（ljs是普通用户名,改成你自己的!）1ljs ALL=NOPASSWD:/usr/libexec/openssh/sftp-server 3、然后向上找到下面语句，将其注释掉 123Defaults requiretty修改为#Defaults requiretty 4、保存并退出 三、打开winscp, 设置 sftp和shell12sudo /usr/libexec/openssh/sftp-serversudu -i]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装NFS]]></title>
    <url>%2F2018%2F05%2F18%2FCentOS7-install-NFS.html</url>
    <content type="text"><![CDATA[备注 简易安装nfs，用于k8s持久化存储 1、安装NFS 1yum install nfs-utils rpcbind 2、启动服务 1234systemctl start rpcbind.servicesystemctl enable rpcbind.servicesystemctl start nfs.servicesystemctl enable nfs.service 3、配置nfs 123[root@server01 ~]# cat /etc/exports/nfsdata *(rw,sync,no_root_squash) 4、加载nfs配置 1exportfs -rv 5、测试 1234nfs服务器挂载情况showmount -e挂载测试mount -t nfs 172.16.2.30:/nfsdata /test]]></content>
      <categories>
        <category>nfs</category>
      </categories>
      <tags>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s简易安装1.10.3]]></title>
    <url>%2F2018%2F05%2F15%2Fk8s-simple-install-1.10.3.html</url>
    <content type="text"><![CDATA[备注 12345678运行环境：CentOS 7.4k8s镜像：采用阿里云及阿里云私有仓库系统架构：master 172.16.2.30；node 172.16.2.31官网：https://kubernetes.io/docs/tasks/tools/install-kubeadm/ https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/日志：/var/log/message 1、初始化环境（master、node执行）1curl -s http://hyman.shop/k8s/sh/1.set.sh |bash 2、安装docker（master、node执行）1curl -s http://hyman.shop/k8s/sh/2.docker-install.sh |bash 3、下载镜像、安装相关镜像（master执行）1curl -s http://hyman.shop/k8s/sh/3.k8s-download.sh |bash 4、部署k8s master节点（master执行）1curl -s http://hyman.shop/k8s/sh/4.master-install.sh |bash 5、部署k8s node节点（node执行）1curl -s http://hyman.shop/k8s/sh/5.node-install.sh |bash 执行完第三步后会显示以下内容（每次运行生成不同的token）：1kubeadm join 172.16.2.30:6443 --token v1077m.jilim7xtw3pxeytq --discovery-token-ca-cert-hash sha256:46ba4041a7df8b5777e3be120d3bf93b420929309353dda6b379f233960f6f9e 如果安装Weave网络1kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\n&apos;)&quot; 如果在你的主机上启用了私有网络，那么，你可能需要去修改 Weavenet 使用的私有子网络，以便于为 Pod（容器）分配 IP 地址。下面是命令示例：12curl -SL &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\n&apos;)&amp;env.IPALLOC_RANGE=172.16.6.64/27&quot; \| kubectl apply -f -]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK5.x安装过程中所遇到的问题]]></title>
    <url>%2F2017%2F11%2F30%2Finstall-ELK5.x-some-problem.html</url>
    <content type="text"><![CDATA[问题一 [2017-11-30T17:37:20,165][WARN ][o.e.b.JNANatives ] unable to install syscall filter:java.lang.UnsupportedOperationException: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in 1解决：使用linux内核3.5版本，不更换也可以。 问题二[2017-11-30T17:37:24,329][WARN ][o.e.b.BootstrapChecks ] [m42Pcik] max number of threads [1024] for user [logtest] is too low, increase to at least [2048] 12345678解决：切换到root用户，进入limits.d目录下修改配置文件。vi /etc/security/limits.d/90-nproc.conf 修改如下内容：* soft nproc 1024#修改为* soft nproc 2048 问题三[2017-11-30T17:04:38,295][WARN ][o.e.b.BootstrapChecks ] [m42Pcik] max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536] 123456789解决：切换到root用户，编辑limits.conf 添加类似如下内容vi /etc/security/limits.conf 添加如下内容:* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 问题四max number of threads [1024] for user [lish] likely too low, increase to at least [2048] 12345678解决：切换到root用户修改配置sysctl.confvi /etc/sysctl.conf 添加下面配置：vm.max_map_count=655360并执行命令：sysctl -p 问题五org.elasticsearch.bootstrap.StartupException: java.lang.IllegalStateException: failed to obtain node locks, tried [[/usr/local/elasticsearch-5.2.0/data/my-application]] with lock id [0]; maybe these locations are not writable or multiple nodes were started without increasing 123解决：cd /usr/local/elasticsearch-5.2.0/datarm -rf nodes/]]></content>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[据说是小米招聘运维工程师的题目]]></title>
    <url>%2F2017%2F11%2F16%2F%E6%8D%AE%E8%AF%B4%E6%98%AF%E5%B0%8F%E7%B1%B3%E6%8B%9B%E8%81%98%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%A2%98%E7%9B%AE.html</url>
    <content type="text"><![CDATA[第一部分：Linux基础题目1：有一百个图片文件，它们的地址都是http://down.xiaomi.com/img/1.pnghttp://down.xiaomi.com/img/2.png…一直到http://down.xiaomi.com/img/100.png批量下载这100个图片文件，并找出其中大于500KB的文件。 12345678910111213同相册的图片地址会有一定的规律，可以用：[root@localhost ~]# echo http://down.xiaomi.com/img/&#123;001..100&#125;.png &gt; url.txt得到图片的地址是用空格分开的,再用vim编辑url文件，把空格替换成回车（\r）：s/ /\r/g在用wget命令批量下载：[root@localhost ~]# wget -i url.txt -P ./photowget命令的-i参数是从指定的文件读取地址，-P参数是把下载的文件放到指定的路径下。找出其中大于500KB的文件[root@localhost ~]# find ./photo -type f -size +500k 1234567891011#/bin/bashecho &quot;downloading the picture......&quot;for i in &#123;1..100&#125;do wget &quot;http://down.xiaomi.com/img/$i.png&quot;done echo &quot;download done!&quot;echo &quot;find the file which is big than 500k&quot;find . -type f -size +500c -print 题目2：一个文本文件info.txt的内容如下： aa,201zz,502bb,1ee,42 每行都是按照逗号分隔，其中第二列都是数字，请对该文件按照第二列数字从大到小排列。 12345[root@localhost ~]# sort -n -r -k 2 -t&apos;,&apos; info.txt zz,502aa,201ee,42bb,1 题目3：查看当前Linux服务器是否监听80端口，如果在监听，请找出其进程ID，并结束该进程。 123[root@localhost ~]# netstat -an | grep -i listen | grep 80[root@localhost ~]# lsof -i:80[root@localhost ~]# kill -9 PID 12345678方法一：使用for for i in `netstat -tanp |grep 3306 |awk &apos;&#123;print $NF&#125;&apos; |cut -d &quot;/&quot; -f 1`;do kill -9 $i;done方法二：使用xargsnetstat -tanp |grep 3306 |awk &apos;&#123;print $NF&#125;&apos; |cut -d &quot;/&quot; -f 1 |xargs -I &apos;&#123;&#125;&apos; kill -9 &#123;&#125;方法三：使用awknetstat -tanp |grep 3306 |awk &apos;&#123;print $NF&#125;&apos; |cut -d &quot;/&quot; -f 1 |awk &apos;&#123;print &quot;kill -9 &quot;$0&#125;&apos; |bash 题目4：使用curl或wget命令获取http服务的header信息。 12345678[root@localhost ~]# curl -I http://www.xiaomi.comHTTP/1.1 301 Moved PermanentlyServer: TengineDate: Thu, 16 Nov 2017 06:44:46 GMTContent-Type: text/htmlContent-Length: 275Connection: closeLocation: https://www.mi.com 题目5：关于Linux的用户账号，下面说法正确的有： A.用户的密码，是以明文形式存储在 /etc/passwd 文件中的 B.用户的密码，是以密文形式存储在 /etc/passwd 文件中的 C.用户的密码，是以密文形式存储在 /etc/shadow 文件中的 D.用户登录的时候，会把用户的密码明文与保存的密码做对比 题目6：对于N块硬盘组成的硬盘阵列，下面的说法哪个是错误的： A.raid1 与 raid5 相比，读取数据的速度 raid5 更快 B.raid1 与 raid5 相比，raid5 的磁盘空间利用率更高 C.raid1 在 （N-1）块磁盘损坏的情况下，不影响数据的完整性 D.raid0 相比于raid1、raid5，读写速度最快 题目7：负载均衡，你了解的常用软件有哪些？请写出至少三种以上，并评价各自的缺点。 1234567Nginx的缺点是：1. Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点。 2. 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。LVS的缺点是： 1. 软件本身不支持正则表达式处理（仅仅支持4层负载均衡），不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 2. 如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言Nginx/HAProxy+Keepalived就简单多了。 题目8：执行 $ time sleep 2，输出如下： real 0m2.003suser 0m0.004ssys 0m0.000s 请说明 real、user、sys三者具体代表的意思和区别。 12345当测试一个程序或比较不同算法时，执行时间是非常重要的，一个好的算法应该是用时最短的。所有类UNIX系统都包含time命令，使用这个命令可以统计时间消耗。real时间是指挂钟时间，也就是命令开始执行到结束的时间。这个短时间包括其他进程所占用的时间片，和进程被阻塞时所花费的时间。user时间是指进程花费在用户模式中的CPU时间，这是唯一真正用于执行进程所花费的时间，其他进程和花费阻塞状态中的时间没有计算在内。 sys时间是指花费在内核模式中的CPU时间，代表在内核中执系统调用所花费的时间，这也是真正由进程使用的CPU时间。 题目9：nginx rewrite 规则中 last、break、redirect、permanent 的含义。 12345678910111213141516171819202122232425262728293031323334353637rewite在server块下，会优先执行rewrite部分，然后才会去匹配location块 server中的rewrite break和last没什么区别，都会去匹配location，所以没必要用last再发起新的请求，可以留空location中的rewirte：不写last和break - 那么流程就是依次执行这些rewrite 1. rewrite break - url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 2. rewrite last - url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 3. rewrite redirect – 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时） 4. rewrite permanent – 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url使用last会对server标签重新发起请求如果location中rewrite后是对静态资源的请求，不需要再进行其他匹配，一般要使用break或不写，直接使用当前location中的数据源，完成本次请求 如果location中rewrite后，还需要进行其他处理，如动态fastcgi请求(.php,.jsp)等，要用last继续发起新的请求 (根的location使用last比较好, 因为如果有.php等fastcgi请求还要继续处理)使用alias指定源：必须使用lastif语句主要用来判断一些在rewrite语句中无法直接匹配的条件,比如检测文件存在与否,http header,cookie等location匹配规则及优先级= 严格匹配这个查询。如果找到，停止搜索。^~ 匹配路径的前缀，如果找到，停止搜索。~ 为区分大小写的正则匹配~* 为不区分大小写匹配 优先级： =, ^~, ~/~*, 无break语句放在server块rewrite语句前面 如果是直接请求某个真实存在的文件,则用break语句停止rewrite检查 if (-f $request_filename) &#123; break; &#125; 题目10：WEB 服务 cookies 和 session 的区别。 1234567891、cookie数据存放在客户的浏览器上，session数据放在服务器上 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能 4、单个cookie在客户端的限制是3K，就是说一个站点在客户端存放的COOKIE不能大于3K。出处：http://blog.csdn.net/u010168160/article/details/47128443更多解释：https://www.zhihu.com/question/19786827 题目11：http 1.0 和 http 1.1下有何区别？http 2.0的主要变化或优势有哪些？ 123456789101112131415HTTP 协议老的标准是HTTP/1.0，目前最通用的标准是HTTP/1.1。 在同一个tcp的连接中可以传送多个HTTP请求和响应,多个请求和响应可以重叠，多个请求和响应可以同时进行,更加多的请求头和响应头(比如HTTP1.0没有host的字段)。它们最大的区别：1、在 HTTP/1.0 中,大多实现为每个请求/响应交换使用新的连接。HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。2、在 HTTP/1.1 中,一个连接可用于一次或多次请求/响应交换,尽管连接可能由于各种原因被关闭。HTTP 1.1支持持久连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。相比 HTTP/1.x，HTTP/2 在底层传输做了很大的改动和优化：１.HTTP/2 采用二进制格式传输数据，而非 HTTP/1.x 的文本格式。二进制格式在协议的解析和优化扩展上带来更多的优势和可能。 2.HTTP/2 对消息头采用 HPACK 进行压缩传输，能够节省消息头占用的网络的流量。而 HTTP/1.x 每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。头压缩能够很好的解决该问题。 3.多路复用，直白的说就是所有的请求都是通过一个 TCP 连接并发完成。HTTP/1.x 虽然通过 pipeline 也能并发请求，但是多个请求之间的响应会被阻塞的，所以 pipeline 至今也没有被普及应用，而 HTTP/2 做到了真正的并发请求。同时，流还支持优先级和流量控制。 4.Server Push：服务端能够更快的把资源推送给客户端。例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 再发送这些请求。当客户端需要的时候，它已经在客户端了。 第二部分：安全部分题目12：请列举WEB常见安全问题（不少于三项），阐述其原理、危害。 题目13：请列举常见DOS攻击类型，并分别介绍其原理和防御方法。 1http://blog.csdn.net/libin_1/article/details/8116091 题目14：服务器遭到入侵，作为安全管理人员，你应做如何处理？ 1https://www.cnblogs.com/lidong94/p/7161793.html 第三部分：网络部分题目15：请简述TCP的三次握手过程。 1234567891011121314151617181920TCP(Transmission Control Protocol) 传输控制协议TCP是主机对主机层的传输控制协议，提供可靠的连接服务，采用三次握手确认建立一个连接:位码即tcp标志位,有6种标示:SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)Sequence number(顺序号码) Acknowledge number(确认号码)第一次握手：主机A发送位码为syn＝1,随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；第二次握手：主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1),syn=1,ack=1,随机产生seq=7654321的包第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1,以及位码ack是否为1，若正确，主机A会再发送ack number=(主机B的seq+1),ack=1，主机B收到后确认seq值与ack=1则连接建立成功。完成三次握手，主机A与主机B开始传送数据。在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。 第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。 完成三次握手，客户端与服务器开始传送数据. 题目16：发现系统中存在大量TIME_WAIT，分析原因并提出三条以上优化建议。 12http://blog.sina.com.cn/s/blog_5d74fde50102x3di.htmlhttp://kerry.blog.51cto.com/172631/105233/ 第四部分：Python部分题目17：xrange和range的异同。 123range range([start,] stop[, step])，根据start与stop指定的范围以及step设定的步长，生成一个序列。xrange 用法与 range 完全相同，所不同的是生成的不是一个list对象，而是一个生成器。要生成很大的数字序列的时候，用xrange会比range性能优很多，因为不需要一上来就开辟一块很大的内存空间。 题目18：列表 A 和 B，使用Python快速获取 A 和 B 中的共有元素。 12345(set(A) &amp; set(B))for i in A: if i in B: print i 题目19： 有20台服务器，需要在所有机器上 echo “123”，要求同时并行操作5台服务器，请使用Python或shell写出相关代码。 12345678910111213141516# encoding:utf-8 import timeimport sysimport osimport threadpool def cmd(ip): #需先设置远程无密码执行命令 os.system(‘ssh ip echo &quot;123&quot; 2&gt;&amp;1’) time.sleep(2) pool = threadpool.ThreadPool(5) #创建一个线程池，包括线程数10个requests = threadpool.makeRequests(cmd, ip_list) #传递函数和参数[pool.putRequest(req) for req in requests] #将请求放入线程池进行处理pool.wait()]]></content>
      <categories>
        <category>linux招聘题目</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy配置支持https协议转发]]></title>
    <url>%2F2017%2F11%2F06%2FHaproxy-configuration-https.html</url>
    <content type="text"><![CDATA[haproxy版本123[root@localhost ~]# haproxy -vHA-Proxy version 1.5.4 2014/09/02Copyright 2000-2014 Willy Tarreau &lt;w@1wt.eu&gt; 生成pem文件1234##申请通过的域名证书，下载后有两个文件1_52yifu.wang_bundle.crt和2_52yifu.wang.key##两个文件合成一个pem文件即可cat 1_52yifu.wang_bundle.crt 52yifu.pem | tree 52yifu.pem http跳转https把所有请求http://www.52yifu.wang的地址全部跳转为https://www.52yifu.com这个地址。123456789101112131415161718192021222324252627282930313233343536defaults mode http log global option dontlognull option http-server-close option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 tune.ssl.default-dh-param 2048frontend app bind *:80 acl is_http hdr_beg(host) 52yifu.wang redirect scheme https if !&#123; ssl_fc &#125; bind *:443 ssl crt /etc/haproxy/ilanni.com.pem# acl cloud url_sub -i /cloud use_backend app if cloud use_backend nginx if is_http default_backend appbackend nginx balance source server web1 127.0.0.1:86 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3backend app balance source server web1 127.0.0.1:8080 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 http与https并存配置服务器同时开放http://52yifu.wang和https://52yifu.wang的访问形式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748defaults mode http log global option dontlognull option http-server-close option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 tune.ssl.default-dh-param 2048frontend app bind *:80 acl is_http hdr_beg(host) 52yifu.wang redirect scheme https if !&#123; ssl_fc &#125; bind *:443 ssl crt /etc/haproxy/ilanni.com.pem use_backend nginx if is_http default_backend tomcatbackend nginx balance source server web1 127.0.0.1:86 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3backend tomcat balance source server web1 127.0.0.1:8080 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3frontend app443 bind *:443 ssl crt /etc/haproxy/52yifu.pem acl is_443 hdr_beg(host) 52yifu.wang use_backend nginx443 if is_443 default_backend tomcat443backend nginx443 balance source server web1 127.0.0.1:86 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3backend tomcat443 balance source server web1 127.0.0.1:8080 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 同台服务器不同域名之间的https与http配置同一台服务器对52yifu.wang域名访问的全部跳转为https://52yifu.wan，而对52yifu.com访问走http协议，也就是跳转到http://52yifu.com这个地址。1234567891011121314151617181920212223242526272829303132333435363738defaults mode http log global option dontlognull option http-server-close option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 tune.ssl.default-dh-param 2048frontend weblb bind *:80 acl is_com hdr_beg(host) 52yifu.com acl is_wang hdr_beg(host) 52yifu.wang redirect prefix https://52yifu.wang if is_wang use_backend haproxyserver if is_combackend haproxyserver balance source server web1 127.0.0.1:9090 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3frontend weblb443 bind *:443 ssl crt /etc/haproxy/52yifu.pem acl is_443 hdr_beg(host) 52yifu.wang use_backend httpserver443 if is_443backend httpserver443 balance source server web1 127.0.0.1:7070 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 同台服务器多域名均使用https配置同一台服务器对52yifu.wang和52yifu.com访问走https是协议。12345678910111213141516171819202122232425262728293031323334353637defaults mode http log global option dontlognull option http-server-close option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 tune.ssl.default-dh-param 2048frontend web80 bind *:80 acl is_http hdr_beg(host) 52yifu.wang redirect scheme https if !&#123; ssl_fc &#125; bind *:443 ssl crt /etc/haproxy/52yfiu.pem acl is_haproxy hdr_beg(host) 52yifu.com redirect scheme https if !&#123; ssl_fc &#125; bind *:443 ssl crt /etc/haproxy/52yifu.pem use_backend httpserver if is_http use_backend haproxyserver if is_haproxybackend httpserver balance source server web1 127.0.0.1:6060 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3backend haproxyserver balance source server web1 127.0.0.1:9090 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3]]></content>
      <categories>
        <category>haproxy</category>
      </categories>
      <tags>
        <tag>harpoxy</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL备份说明]]></title>
    <url>%2F2017%2F10%2F23%2FMySQL-backup-explain.html</url>
    <content type="text"><![CDATA[使用规范实例级备份恢复使用innobackupex，在业务空闲期执行，考虑到IO影响及 FLUSH TABLE WITH READ LOCAK 拷贝非INNODB文件的锁表时间。 常规备份中，使用innobackupex在从库备份执行，在无从库的情况下，允许在业务低峰期对整个实例拷贝。 库、表级别备份恢复考虑 数据量、磁盘IO情况、恢复难度问题。 mysqldump锁表时间长，备份时间长，但是导入方便，适合数据量小但是表格多 的库/表级别备份。 innobackupex锁表时间短，备份时间短，但是恢复较复杂，需要discord tablespace及 import TABLESPACE，除非允许备份文件成立单个实例，适合表数据量大但表格数量少的库/表级别备份。 SQL结果备份及恢复如果是单表简单查询，使用mysqldump，添加where条件，例如：mysqldump -S /tmp/mysql3330.sock -uroot -p –databases db1 –tables tb1 tb2 tb3 -d &gt;/data/backup/3330/mysqldump_20161229.sql 。 如果是复杂SQL查询结果，使用 INTO OUTFILE，如下：123456789#FIELDS TERMINATED BY &apos;,&apos; 字段间分割符#OPTIONALLY ENCLOSED BY &apos;&quot;&apos; 将字段包围 对数值型无效#LINES TERMINATED BY &apos;\n&apos; 换行符 #查询导出select * into outfile &apos;/tmp/pt.txt&apos; FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos; LINES TERMINATED BY &apos;\n&apos; from pt where id &gt;3; #加载数据load data infile &apos;/tmp/pt1.txt&apos; into table pt FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos; LINES TERMINATED BY &apos;\n&apos; 表结构备份使用mysqldump，添加-d参数。 mysqldump支持功能多且全面，但是锁表时间是个风险点，使用时注意，同时，若是5.6版本之前的，要充分考虑buffer pool的使用情况。 原理通过general log查看mysqldump运行原理，详细流程见代码块 mysqldump。 mysqldump运行中，第一步，会检查数据库的配置情况，例如是否设置GTID模式及参数配置；第二步，锁所有表格，只允许读操作；第三步，逐个拷贝表格，生成创建表格上SQL（字符集为binary），再SELECT * FROM 表格 生成数据脚步（字符集为UTF8）；第4步，解锁。 当导出全实例或者大数据库时，这里有2个需要注意到问题： 锁表的时间基本可以算是从开始到结束都是锁表期间，不能对数据库进行写操作，只能读线上主库无法支持这么长时间的锁表操作线上从库，应考虑对复制到影响 buffer pool的影响由于是采用SELECT * 生成SQL语句，大量读操作，会把缓存里的数据清理出来，导致热点数据移出，对线上DML操作带来严重影响5.6后版本,新增了young buffer pool，一秒内以这个数据被再次访问，则会进入到buffer pool 的warm区。youny区占buffer pool的3/8，剩下的5/8为warm区，可以有效保证热点数据不被清出。 重要参数以下参数在使用过程中，需要留意，根据实际情况添加： –master-data=1 /2生产change master to语句，这里注意，lock table 的时间，会提前到最开始的时候，不过相差的时间段非常小。1 则是生产 change master to语句 不加注释符号，直接执行；2 生成change master to语句，加注释符号 –singe-transaction确保事物一致性，建议在GTID模式添加 –set-gtid-purged=ON / OFF在GTID模式下的dump语句，会自动在备份文件之前生成如果打算把该脚本放在非GTID模式的数据库执行，建议添加 –set-gtid-purged=OFF ，关闭生成purge 或者是去文件中注释掉该语句 -d只导出表结构 –databases不更随–tables的时候，可以指定多个db，如果指定了–tables，则默认第一个是database，其他的是table也就是只允许导多个DB的数据文件，或者导同个DB的多个table文件；不允许到不同DB的某些table文件 使用说明语法主要有以下三类：123Usage: mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS] 实例备份恢复123456#实例备份mysqldump -S /tmp/mysql3330.sock -uroot -p --all-datqabases &gt;/data/backup/3330/mysqldump_20161229.sql #实例恢复#新建实例后，导入脚本mysql --socket=/tmp/mysql3306.sock -uroot -p &lt; /data/backup/3330/mysqldump_20161229.sql 部分备份恢复12345678910111213141516171819#指定单个或者多个DB备份mysqldump -S /tmp/mysql3330.sock -uroot -p db1 db2 db3 &gt;/data/backup/3330/mysqldump_20161229.sqlmysqldump -S /tmp/mysql3330.sock -uroot -p --databases db1 db2 db3 &gt;/data/backup/3330/mysqldump_20161229.sql #指定单个或者多个表格备份mysqldump -S /tmp/mysql3330.sock -uroot -p --databases db1 --tables tb1 tb2 tb3 &gt;/data/backup/3330/mysqldump_20161229.sqlmysqldump -S /tmp/mysql3330.sock -uroot -p db1 tb1 tb2 tb3 &gt;/data/backup/3330/mysqldump_20161229.sql #只导出单个表格的某些行数据mysqldump -S /tmp/mysql3330.sock -uroot -pycf.com zero pt --where=&apos;1=1 limit 2&apos; &gt;/data/backup/3330/mysqldump_20161229.sql #只备份表结构，不要表数据mysqldump -S /tmp/mysql3330.sock -uroot -p --databases db1 --tables tb1 tb2 tb3 -d &gt;/data/backup/3330/mysqldump_20161229.sql #只备份表数据，不要表结构mysqldump -S /tmp/mysql3330.sock -uroot -pycf.com zero pt --where=&apos;id&gt;3&apos; --no-create-info &gt;/data/backup/3330/mysqldump_20161229.sql #恢复数据source /data/backup/3330/mysqldump_20161229.sql PerconaXtraBackupPerconaXtraBackup软件中，含有xtrabackup跟innobackupex，xtrabackup中不备份表结构，innobackupex调用xtrabackup子线程后再备份表结构，故常用innobackupex，xtraback不做日常使用。目前支持 Myisam,innodb，可以备份 .frm, .MRG, .MYD, .MYI, .MAD, .MAI, .TRG, .TRN, .ARM, .ARZ, .CSM, CSV, .opt, .par, innoDB data 及innobdb log 文件。 innobackupex原理（全量说明）对数据库文件进行copy操作，同时建立多一个xtrabackup log 同步mysql的redo线程，copy数据文件结束时，flush table with read lock，拷贝非innodb数据文件的文件，拷贝结束后解锁。原理图见下图（图片来自知数堂）。通过general log查看mysqldump运行原理，详细流程见代码块 innobackupex。 这里需要注意2个点： 锁表时间innobackupex锁表时间是 data文件及log文件copy结束时，才锁表，锁表时长为拷贝non-InnoDB tables and files的时长，相对时间较短，对业务影响小。 大事务copy数据文件的过程中，由于是不锁表，允许数据进行DML操作，这里需要注意，如果这个时候，拷贝的过程中有大事务一直没有提交，界面显示log scanned up，持续copy binlog追上数据库的binlog文件，并且该时间点刚好所有事务已提交（这里测试的时候，如果是单条 insert ，delete，update的大事务，则是要等待单条完成才提交，但是如果是begin事务里边的，不用等待是否commit or rollback，begin里边的单条事务执行结束，则就开始提交，恢复的时候，当作是undo 事务，不会提交该事物，回滚该事务）。大事务容易导致备份时长加长，IO占用。 123456789101112131415161718192016-12-26T15:18:39.627366Z 1659 Connect root@localhost on using Socket2016-12-26T15:18:39.627789Z 1659 Query SET SESSION wait_timeout=21474832016-12-26T15:18:39.628193Z 1659 Query SHOW VARIABLES #记录LSN号码，开始copy ibd文件2016-12-26T15:18:55.673740Z 1659 Query SET SESSION lock_wait_timeout=315360002016-12-26T15:18:55.674281Z 1659 Query FLUSH NO_WRITE_TO_BINLOG TABLES#强制把没有 还没写入binlog 磁盘文件的缓存 强制刷新到磁盘#开始拷贝数据库文件，这里需要注意，如果这个时候，拷贝的过程中有大事务一直没有提交，则会一直拷贝其产生的 ，界面显示log scanned up，直到copy binlog追上数据库的binlog文件，并且该时间点刚好所有事务已提交（这里测试的时候，如果是单条 insert ，delete，update的大事务，则是要等待单条完成才提交，但是如果是begin事务里边的，不用等待是否commit or rollback，begin里边的单条事务执行结束，则就开始提交，恢复的时候，当作是undo 事务，不会提交该事物，回滚该事务。 ）2016-12-26T15:18:55.676345Z 1659 Query FLUSH TABLES WITH READ LOCK#锁表，只允许读，不允许写及其他架构修改操作#拷贝除innodb 数据文件外的其他所有文件，包括表结构等，Starting to backup non-InnoDB tables and files2016-12-26T15:18:59.691409Z 1659 Query SHOW MASTER STATUS#记录 备份到的 binlog文件及position位置，这个记录在 xtrabackup_binlog_info 文件，可提供复制使用2016-12-26T15:18:59.734418Z 1659 Query SHOW VARIABLES2016-12-26T15:18:59.754530Z 1659 Query FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS2016-12-26T15:18:59.968452Z 1659 Query UNLOCK TABLES#解锁，表格恢复可写，架构可修改2016-12-26T15:18:59.991046Z 1659 Query SELECT UUID()2016-12-26T15:19:00.005980Z 1659 Query SELECT VERSION() 重要参数备份参数12345678910111213141516171819innobackupex [--compress] [--compress-threads=NUMBER-OF-THREADS] [--compress-chunk-size=CHUNK-SIZE] [--encrypt=ENCRYPTION-ALGORITHM] [--encrypt-threads=NUMBER-OF-THREADS] [--encrypt-chunk-size=CHUNK-SIZE] [--encrypt-key=LITERAL-ENCRYPTION-KEY] | [--encryption-key-file=MY.KEY] [--include=REGEXP] [--user=NAME] [--password=WORD] [--port=PORT] [--socket=SOCKET] [--no-timestamp] [--ibbackup=IBBACKUP-BINARY] [--slave-info] [--galera-info] [--stream=tar|xbstream] [--defaults-file=MY.CNF] [--defaults-group=GROUP-NAME] [--databases=LIST] [--no-lock] #不执行FLUSH TABLES WITH READ LOCK，建议不使用，不会拷贝undo及redo文件 [--no-timestamp] [--kill-long-queries-timeout=#] [--tmpdir=DIRECTORY] [--tables-file=FILE] [--history=NAME] [--incremental] [--incremental-basedir] [--incremental-dir] [--incremental-force-scan] [--incremental-lsn] [--incremental-history-name=NAME] [--incremental-history-uuid=UUID] [--close-files] [--compact] BACKUP-ROOT-DIR 准备还原参数根据 BACKUP-DIR/xtrabackup_logfile创建新的logfile，xtrabackup为子进程，不连接数据库服务.1234innobackupex --apply-log [--use-memory=B] [--defaults-file=MY.CNF] [--export] [--redo-only] [--ibbackup=IBBACKUP-BINARY] BACKUP-DIR 备份目录拷贝参数拷贝备份目录到指定目录，备份目录及拷贝目录文件均存在innobackupex –copy-back [–defaults-file=MY.CNF] [–defaults-group=GROUP-NAME] BACKUP-DIR 移动备份目录到指定目录，备份目录为空innobackupex –move-back [–defaults-file=MY.CNF] [–defaults-group=GROUP-NAME] BACKUP-DIR 使用说明实例备份及恢复全量备份1234567#全量备份 实例备份及恢复#备份innobackupex --defaults-file=/data/mysql/mysql3330.cnf --user=root --password=ycf.com --no-timestamp /data/backup/3330/20161229innobackupex --apply-log /data/backup/3330/20161229 #恢复innobackupex --copy-back --datadir=/data/mysql/mysql3350/data /data/backup/3330/20161229 增量备份恢复#增量备份12345678910111213innobackupex --defaults-file=/data/mysql/mysql3376.cnf --user=root --password=ycf.com --no-timestamp --incremental-basedir=/data/backup/3330/20161229 --incremental /data/backup/mysql3376/20161230diff innobackupex --defaults-file=/data/mysql/mysql3376.cnf --user=root --password=ycf.com --no-timestamp --incremental-basedir=/data/backup/3330/20161230diff --incremental /data/backup/mysql3376/20161231diff #增量恢复#现在完整备份文件中中应用redo日志，记得是redo-only， redo-only， redo-only， redo-only， 不是readonly，打死记得，不要乱来！！！！！！innobackupex --apply-log --redo-only /data/backup/3330/20161229 #应用第一个增量备份文件的redo日志到完整备份文件夹中innobackupex --apply-log --redo-only /data/backup/3330/20161229 --incremental-dir=/data/backup/mysql3376/20161230diff #应用最后一个增量备份文件的redo日志到完整备份文件夹中，可以直接apply-loginnobackupex --apply-log /data/backup/3330/20161229 --incremental-dir=/data/backup/mysql3376/20161231diff 部分备份12#部分备份#指定数据库备份 innobackupex –defaults-file=/data/mysql/mysql3330.cnf –databases=’zero mysql’ –user=root –password=ycf.com –no-timestamp /data/backup/3330/20161202 #指定表格备份 #3.1 –include 使用正则表达式 #3.2 –table-file 备份的完整表名写在file文件中vim /tmp/backupfile #每行写一个库名，或者一个表的全名（database.table），写完库名或者表名后，千万不要有空格或者其他空白符号，会导致识别不了该表格或者库名，从而导致跳过innobackupex –defaults-file=/data/mysql/mysql3330.cnf –tables-file=/tmp/backupfile –user=root –password=ycf.com –no-timestamp /data/backup/3330/20161204 #3.3 –databases 完整库名和表名写在一起，用空格隔开innobackupex –defaults-file=/data/mysql/mysql3330.cnf –user=root –password=ycf.com –no-timestamp –databases=zero.s1 /data/backup/3330/20161229 #指定表格恢复(开启独立表空间) #首先要自己现在需要恢复的数据库上，创建该表格，然后discard tablespace,拷贝ibd文件过来，chown 文件所有者及用户组为mysql，再 import tablespace。 #如果有大量表格，用这个操作就比较麻烦，需要一个个来创建，包括指定数据库，也是这样处理，整个数据库先创建之后，在一个个表格discard，再import。ALTER TABLE S1 DISCARD TABLESPACE;ALTER TABLE S1 import TABLESPACE;`]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python基本算法]]></title>
    <url>%2F2017%2F08%2F23%2FPython-base-operation.html</url>
    <content type="text"><![CDATA[时间复杂度用来评估算法运行效率的一个东西12345678910111213141516171819def func(): print(&quot;hello world&quot;) def func1(n): for i in range(n): print(&quot;hello world&quot;) def func2(n): for i in range(n): for j in range(n): print(&quot;hello world&quot;) def func3(n): for i in range(n): for j in range(n): for k in range(n): print(&quot;hello world&quot;)时间复杂度分别为：O(1),O(n),O(n^2),O(n^3) 特殊的时间复杂度123456def func4(n): while n &gt;1: print(n) n = n//2时间复杂度叫O(logn) 时间复杂度是用来估计算法运行时间的一个式子（单位） 一般来说，时间复杂度高的算法比复杂度低的算法慢 常见的时间复杂度（按效率排序） O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n^2)&lt;O(n*nlogn)&lt;O(n^3) 通常简单的判断时间复杂度的方法： 循环减半的过程——O(logn) 基层循环就是n的几次方的复杂度 空间复杂度用来评估算法内存占用大小的一个式子 算法二分查找二分查找又叫折半查找，二分查找应该属于减治技术的成功应用。所谓减治法，就是将原问题分解成若干个子问题后，利用了规模为n的原问题的解与较小规模（通常是n/2）的子问题的解之间的关系。二分查找利用了记录按关键码有序的特点，其基本思想为：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键码相等，则查找成功；若给定值小于中间记录的关键码，则在中间记录的左半边继续查找；若给定值大于中间记录的关键码，则在中间记录右半边区继续查找。不断重复上述过程，直到查找成功，或所查找的区域无记录，查找失败。二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)。1234567在一个排序数组中找一个数，返回该数出现的任意位置，如果不存在，返回-1样例给出数组 [1, 2, 2, 4, 5, 5].对于 target = 2, 返回 1 或者 2.对于 target = 5, 返回 4 或者 5.对于 target = 6, 返回 -1. 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python#coding=utf-8#自定义函数，实现二分查找，并返回查找结果def binary_search(find, list1) : low = 0 high = len(list1) while low &lt;= high : mid = (low + high) / 2 if list1[mid] == find : return mid #左半边 elif list1[mid] &gt; find : high = mid -1 #右半边 else : low = mid + 1 #未找到返回-1 return -1list1 = [1,2,3,7,8,9,10,5]#进行二分查找算法前必须保证要查找的序列时有序的，这里假设是升序列表list1.sort()print &quot;原有序列表为:&quot;,list1try : find = int(raw_input(&quot;请输入要查找的数：&quot;))except : print &quot;请输入正整数！&quot; exit()result = binary_search(find, list1)if result != -1 : print &quot;要找的元素%d的序号为：%d&quot; %(find,result)else : print &quot;未找到！&quot; 排序插入排序插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。12345678910111213141516171819list = [55,45,345,6,7,2,88,53,12,889,21]print listdef insert_sort(list): count = len(list) for i in range(1,count): k = list[i] #print i #print k j = i -1 #print list[j] while j &gt;= 0: if list[j] &gt;k: list[j+1]=list[j] list[j]=k j -=1 #print list return listprint insert_sort(list) 冒泡排序它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。每一趟只能将一个数归位, 如果有n个数进行排序,只需将n-1个数归位, 也就是说要进行n-1趟操作(已经归位的数不用再比较)缺点: 冒泡排序解决了桶排序浪费空间的问题, 但是冒泡排序的效率特别低12345678910111213#!/usr/bin/env python# coding:utf-8def bubbleSort(nums): for i in range(len(nums)-1): # 这个循环负责设置冒泡排序进行的次数 for j in range(len(nums)-i-1): # ｊ为列表下标 if nums[j] &gt; nums[j+1]: nums[j], nums[j+1] = nums[j+1], nums[j] return numsnums = [5,2,45,6,8,2,1]print bubbleSort(nums) 选择排序基本思想：第1趟，在待排序记录r1 ~ r[n]中选出最小的记录，将它与r1交换；第2趟，在待排序记录r2 ~ r[n]中选出最小的记录，将它与r2交换；以此类推，第i趟在待排序记录r[i] ~ r[n]中选出最小的记录，将它与r[i]交换，使有序序列不断增长直到全部排序完毕。1234567891011121314#!/usr/bin/env python# coding:utf-8def selectSort(nums): for i in range(len(nums)): max_index = 0 for j in range(len(nums)-i): if nums[max_index] &lt; nums[j]: max_index = j nums[max_index], nums[len(nums)-i-1] = nums[len(nums)-i-1], nums[max_index] return numsnums = [6,2,54435,3141]print selectSort(nums) 桶排序通排序非常浪费空间, 比如需要排序的范围在0~2000之间, 需要排序的数是[3,9,4,2000], 同样需要2001个空间 注意: 通排序不能排序小数123456789101112131415161718192021222324#!/usr/bin/env python# coding:utf-8def bucketSort(nums): # 选择一个最大的数 max_num = max(nums) # 创建一个元素全是0的列表, 当做桶 bucket = [0]*(max_num+1) # 把所有元素放入桶中, 即把对应元素个数加一 for i in nums: bucket[i] += 1 # 存储排序好的元素 sort_nums = [] # 取出桶中的元素 for j in range(len(bucket)): if bucket[j] != 0: for y in range(bucket[j]): sort_nums.append(j) return sort_numsnums = [5,6,3,2,1,65,2,0,8,0]print bucketSort(nums) 希尔排序希尔排序的实质就是分组插入排序，该方法又称缩小增量排序，因DL．Shell于1959年提出而得名。希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。希尔排序是基于插入排序的以下两点性质而提出改进方法的：插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位12345678910111213141516171819#!/usr/bin/env python# coding:utf-8def shellSort(nums): # 设定步长 step = len(nums)/2 while step &gt; 0: for i in range(step, len(nums)): # 类似插入排序, 当前值与指定步长之前的值比较, 符合条件则交换位置 while i &gt;= step and nums[i-step] &gt; nums[i]: nums[i], nums[i-step] = nums[i-step], nums[i] i -= step step = step/2 return numsif __name__ == &apos;__main__&apos;: nums = [9,3,5,8,2,7,1] print shellSort(nums)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux几个常用命令使用介绍]]></title>
    <url>%2F2017%2F08%2F10%2FLinux-some-command-recommend.html</url>
    <content type="text"><![CDATA[grep命令文本查找命令, 能够使用正则表达式的方式搜索文本，其搜索对象可以是单个或则多个文件1234567891011121314基本格式 grep [option] [regex] [path]-o 只按行显示匹配的字符-c 只输出匹配行的数目-n 显示匹配行的行号-v 显示不包含匹配文本的行-i 不区分大小写 (grep是大小写敏感的)-R 文件夹下递归搜索-l 只显示匹配的文件名 -H 显示文件名-A NUM(after)显示匹配的后几行-B NUM(before)显示匹配的前几行-C NUM显示匹配的前后几行 –color 标出颜色 ls命令ls是命令行中用的最多的命令之一了，用于显示目录下的文件1234567891011基本格式 ls [option]-a 列出所有文件，包括’.’开头的隐藏文件-h 使打印结果易于使用者查看(human readable)-l 列出文件的详细信息：创建者，创建时间，读写权限等-s 显示文件大小-t 按时间进行文件的排序-S 以大小进行排序-r 当前条件逆序-L 显示文件链接名-R 将目录中所有文件都递归显示出来 find命令文件查找命令,find命令将递归的搜索目录下符合要求的所有文件12345678910基本格式 find [path] [option] [expression]-name 查找名为filename的文件-perm 查找符合执行权限 -user 按照文件的所属主查找-mtime -n +n 按照文件的更改时间查找文件，n代表天数-ctime -n +n 按照创建时间查找-newer f1 !f2 查更改时间在f1和f2之间的文件 -size n 查找长度为n块的文件，一块为512 bytes-depth 使得查找在进入子目录前先行查找完本目录-prune 查找时忽略某个目录 -type 按文件类型查找，b为块设备，d为目录，f为普通文档 wc命令用于统计输入中的字节数，字数，行数并输出123456基本格式 wc [option] [filename]-c 统计字节数-l 统计行数-m 统计字符数-w 统计字数，一个字为由空白，跳格或换行字符分隔的字符串 cat命令连结命令(Concatenation)，连结多个文本，或者以标准输出形式打印文件的内容1234基本格式 cat [option] [filename]-n 队输出的所有行编号-b 与-n类似，但空行不编号 tail命令文本查看命令，可以看文本的最后几行。tail命令的优点在于其内容能够与输入同步更新，非常适用于查看实时日志。1234567基本格式 tail [option] [filename]-n number 定位参数，+5表示从第五行开始显示，10或-10表示显示最后10行-f 监控文本变化，更新内容-k number 从number所指的KB处开始读取 head命令该命令与tail命令类似，默认显示文件前两行的内容12345基本格式 head [option] [filename]-n number 显示前几行,-5表示文件中除了最后5行之外的所有内容-c number 显示前几个字节 du命令该命令用于查看系统中文件和目录所占用的空间1234567基本格式 du [option] [name]-h 用human readable的方式显示--max-depth=number 最大的查询层次-a 显示所有文件的大小，默认只显示目录的大小 which和whereiswhich命令的作用是在PATH变量制定的路径中，查找系统命令的位置。whereis命令用于程序名的搜索，且只能搜索｛二进制文件，man说明文件，源代码文件｝。whereis的查询时通过查询系统的数据库文件记录，所以速度比find更快，但由于数据库的更新频率较为缓慢，其结果与实际状况并不一定一致。123-m 只查找说明文件-b 只查找二进制文件 sort命令sort命令用于对文本进行排序，并将结果输出。其以文本的每一行为单位，从首字符向后，依次按照ascii码值进行比较，最后升序排列。（默认是忽略每行前面空格的）123456789基本格式 sort [option] [filename]-u 忽略重复行-n 按照数字大小排序-r 逆序-k start,endstart为比较的起始位置，end为结束位置 netstat命令netstat用于输出linux系统的网络情况信息，以前面试的时候还被问过：“如何查看占用某个端口的程序的pid?”，这个问题实际用netstat -anp输出，然后再grep一下即可。1234567891011121314151617基本格式 netstat [option]-a 显示所有socket连接-l 显示监控中(listening)的socket连接-n 直接使用ip地址，而不使用域名服务器-p 显示正在使用socket的程序的pid和名称-r 打印路由表-t 显示TCP传输协议的连线状况-u 显示UDP传输协议的连线状况-s 显示网络工作信息统计表 more命令more命令用于显示文件的内容，与cat和tail等命令不同的是，more命令是按页显示文件内容，同时具有搜寻字符串的功能。（由于more具有向前翻页功能，因此该命令会加载整个文件）1234567891011121314151617181920212223基本格式 more [option] [filename]+n 从第n行开始显示-n 定义屏幕大小为n行+/pattern 再显示前按pattern匹配子串并显示-s 把连续的多个空行显示为一行常用操作命令：Enter 向下n行，默认为1行Ctrl+F 跳过一屏Ctrl+B 返回上一屏空格键 向下滚动一屏= 输出当前行的行号在more模式中回车，输入/pattern可以持续向下搜索 less命令less命令与more命令对应，既可以前后翻看文件，同时还有前后搜索功能，除此之外，less在查看前不会加载整个文件。123456789101112131415161718192021222324252627基本格式 less [option] [filename]－N 显示每行的行号-i 忽略搜索时的大小写-s 将连续空行显示为一行-m 显示百分比常用操作命令：/字符串 向下搜索“字符串”功能?字符串 向上搜索“字符串”功能n 重复前一个搜索空格键 滚动一页d 滚动半页b 回溯一页y 回溯一行q 退出less命令 ps命令ps命令用来在Linux系统中显示进程的状态快照，其参数选项可谓非常之多。12345678910111213基本格式 ps [option]-a 显示所有用户的进程-x 显示没有控制终端的进程-u 按照用户名称查询进程-f 列出全部信息，常和其它选项联用-j 用任务格式来显示进程-e 显示所有进程 kill命令kill命令用于终止指定的进程，其工作原理是通过向进程发送指定的信号。12345678910111213141516171819基本格式 kill [params] [pid]常用的是：kill -9 pid //强制终止-1 Hup 终端断线-2 INT 中断（同Ctrl+c）-3 QUIT 退出(同Ctrl+\)-15 TERM 终止，是默认的信号，如果应用本身会捕获该信号，则不能终止-9 KILL 强制终止-18 CONT 继续-19 STOP 暂停(同Ctrl+z)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>grep</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[备份数据库脚本并将备份数据库同步到又拍云存储空间]]></title>
    <url>%2F2017%2F08%2F09%2F%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E8%84%9A%E6%9C%AC%E5%B9%B6%E5%B0%86%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8C%E6%AD%A5%E5%88%B0%E5%8F%88%E6%8B%8D%E4%BA%91%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4.html</url>
    <content type="text"><![CDATA[经历过一次意外，可能某拥有服务器权限的同事将测试器将全部数据给删除了，导致服务器数据库全部丢失，服务器崩溃，只能重装。特弄了一个简单的数据库脚本备份并将数据库同步到又拍云存储空间。123##又拍云UPX工具https://github.com/polym/upx 同步脚本 123456789101112[root@localhost backup]# cat backup.sh #!/bin/bash##用于本地目录中的所有文件同步上传到又拍云存储，用时监控目录变化service_name=&quot;testbackup&quot;username=&quot;******&quot;password=&quot;******&quot;/home/backup/upx login testbackup ****** ******/home/backup/upx sync /home/backup mysql备份脚本12345678910111213141516171819202122232425262728[root@localhost backup]# cat xtrabackup-full.sh #!/bin/bash user=&apos;root&apos; passwd=&apos;123456&apos;host=&apos;127.0.0.1&apos;port=&apos;3307&apos;database=&apos;cloud_yssj&apos; my_config=&apos;/usr/local/mysql-test1/my.cnf&apos; log=$database-$(date +%Y%m%d%H%M).log str=$database-$(date +%Y%m%d%H%M).tar.gz backup_dir=&apos;/home/backup/mysql&apos;echo &quot;Start to backup at $(date +%Y%m%d%H%M)&quot; if [ ! -d &quot;$backup_dir&quot; ];then mkdir -p $backup_dir fi /usr/bin/innobackupex --defaults-file=$my_config --user=$user --password=$passwd --port=$port --host=$host --database=$database --stream=tar $backup_dir 2&gt;$backup_dir/$log | gzip 1&gt;$backup_dir/$str if [ $? -eq 0 ];then echo &quot;Backup is finish! at $(date +%Y%m%d%H%M)&quot; exit 0 else echo &quot;Backup is Fail! at $(date +%Y%m%d%H%M)&quot; exit 1 fi echo &quot;Backup Process Done&quot; mongodb、redis备份脚本123456789101112131415161718192021222324[root@localhost backup]# cat mongodb.sh #!/bin/bash host=&apos;127.0.0.1:37018&apos;database=&apos;cloud_yssj&apos; backup_dir1=&apos;/home/backup/mongodb&apos;backup_dir2=&apos;/home/backup/redis&apos; if [ ! -d &quot;$backup_dir1&quot; ];then mkdir -p $backup_dir1 fi if [ ! -d &quot;$backup_dir2&quot; ];then mkdir -p $backup_dir2 fi /home/mongodb/bin/mongodump -h $host -d $database -o $backup_dir1 tar zcvf $backup_dir1/mongodb-$(date +%Y%m%d%H%M).tar.gz $backup_dir1/$databaserm -rf /home/backup/mongodb/cloud_yssjtar zcvf $backup_dir2/redis-$(date +%Y%m%d%H%M).tar.gz /home/redis/data/dump8000.rdb 增加定时任务1234[root@localhost backup]# crontab -l30 1 * * * /home/backup/mongodb.sh20 2 * * * /home/backup/xtrabackup-full.sh40 3 * * * /home/backup/backup.sh]]></content>
      <categories>
        <category>备份</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>xtrabackup</tag>
        <tag>mongodb</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Xtrabackup进行MySQL备份]]></title>
    <url>%2F2017%2F08%2F08%2Fuse-Xtrabackup-MySQL-backup.html</url>
    <content type="text"><![CDATA[Xtrabackup介绍Xtrabackup是由percona提供的mysql数据库备份工具，据官方介绍，这也是世界上惟一一款开源的能够对innodb和xtradb数据库进行热备的工具。特点： 备份过程快速、可靠；备份过程不会打断正在执行的事务；能够基于压缩等功能节约磁盘空间和流量；自动实现备份检验；还原速度快； 下载安装xtrabackup1234https://www.percona.com/downloads/XtraBackup/LATEST/[root@node1 ~]# yum localinstall percona-xtrabackup-24-2.4.8-1.el6.x86_64.rpm[root@node1 ~]# yum install http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm 备份完全备份1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 /home/backup/ 使用innobakupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以时间命令的目录中。 在备份的同时，innobackupex还会在备份目录中创建如下文件：(1)xtrabackup_checkpoints – 备份类型（如完全或增量）、备份状态（如是否已经为prepared状态）和LSN(日志序列号)范围信息；每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的。 (2)xtrabackup_binlog_info – mysql服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置。 (3)xtrabackup_binlog_pos_innodb – 二进制日志文件及用于InnoDB或XtraDB表的二进制日志文件的当前position。 (4)xtrabackup_binary – 备份中用到的xtrabackup的可执行文件； (5)backup-my.cnf – 备份命令用到的配置选项信息； 在使用innobackupex进行备份时，还可以使用–no-timestamp选项来阻止命令自动创建一个以时间命名的目录；如此一来，innobackupex命令将会创建一个BACKUP-DIR目录来存储备份数据。 准备(prepare)一个完全备份一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log /home/backup/2017-08-08_15-28-09/ 在实现“准备”的过程中，innobackupex通常还可以使用–use-memory选项来指定其可以使用的内存的大小，默认通常为100M。如果有足够的内存可用，可以多划分一些内存给prepare的过程，以提高其完成速度。 从一个完全备份中恢复数据innobackupex命令的–copy-back选项用于执行恢复操作，其通过复制所有数据相关的文件至mysql服务器DATADIR目录中来执行恢复过程。innobackupex通过backup-my.cnf来获取DATADIR目录的相关信息。123456789[root@localhost ~]# rm -rf data/*[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --copy-back /home/backup/2017-08-08_15-28-09/[root@localhost ~]# chown -R mysql:mysql data[root@localhost ~]# killall mysqld#####可以不用启动mysql恢复数据##### 增量备份每个InnoDB的页面都会包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长。这正是InnoDB表可以进行增量备份的基础，即innobackupex通过备份上次完全备份之后发生改变的页面来实现。1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --incremental /home/backup/ --incremental-basedir=/home/backup/2017-08-08_15-28-09/ 此命令执行结束后，innobackupex命令会在/backup目录中创建一个新的以时间命名的目录以存放所有的增量备份数据。另外，在执行过增量备份之后再一次进行增量备份时，其–incremental-basedir应该指向上一次的增量备份所在的目录。 需要注意的是，增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 “准备”(prepare)增量备份与整理完全备份有着一些不同，尤其要注意的是：(1)需要在每个备份(包括完全和各个增量备份)上，将已经提交的事务进行“重放”。“重放”之后，所有的备份数据将合并到完全备份上。(2)基于所有的备份将未提交的事务进行“回滚”。123[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log --redo-only /home/backup/2017-08-08_15-28-09/[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log --redo-only /home/backup/2017-08-08_15-28-09/ --incremental-dir=/home/backup/2017-08-08_16-10-12/ Xtrabackup的“流”及“备份压缩”功能Xtrabackup对备份的数据文件支持“流”功能，即可以将备份的数据通过STDOUT传输给tar程序进行归档，而不是默认的直接保存至某备份目录中。要使用此功能，仅需要使用–stream选项即可。如： 1innobackupex --stream=tar /backup | gzip &gt; /backup/`date +%F_%H-%M-%S`.tar.gz 甚至也可以使用类似如下命令将数据备份至其它服务器：1innobackupex --stream=tar /backup | ssh &quot;cat - &gt; /backups/`date +%F_%H-%M-%S`.tar&quot; 此外，在执行本地备份时，还可以使用–parallel选项对多个文件进行并行复制。此选项用于指定在复制时启动的线程数目。当然，在实际进行备份时要利用此功能的便利性，也需要启用innodb_file_per_table选项或共享的表空间通过innodb_data_file_path选项存储在多个ibdata文件中。对某一数据库的多个文件的复制无法利用到此功能。其简单使用方法如下：1innobackupex --parallel /path/to/backup 同时，innobackupex备份的数据文件也可以存储至远程主机，这可以使用–remote-host选项来实现：1innobackupex --remote-host=root@ww agedu.com /path/IN/REMOTE/HOST/to/backup 导入或导出单张表默认情况下，InnoDB表不能通过直接复制表文件的方式在mysql服务器之间进行移植，即便使用了innodb_file_per_table选项。而使用Xtrabackup工具可以实现此种功能，不过，此时需要“导出”表的mysql服务器启用了innodb_file_per_table选项（严格来说，是要“导出”的表在其创建之前，mysql服务器就启用了innodb_file_per_table选项），并且“导入”表的服务器同时启用了innodb_file_per_table和innodb_expand_import选项。 (1)“导出”表导出表是在备份的prepare阶段进行的，因此，一旦完全备份完成，就可以在preparef过程中通过–export选项将某表导出了：1innobackupex --apply-log --export /path/to/backup 此命令会为每个innodb表的表空间创建一个以.exp结尾的文件，这些以.exp结尾的文件则可以用于导入至其它服务器。 (2)“导入”表要在mysql服务器上导入来自于其它服务器的某innodb表，需要先在当前服务器上创建一个跟原表表结构一致的表，而后才能实现将表导入：1mysql&gt; CREATE TABLE mytable (...) ENGINE=InnoDB; 然后将此表的表空间删除：1mysql&gt; ALTER TABLE mydatabase.mytable DISCARD TABLESPACE; 接下来，将来自于“导出”表的服务器的mytable表的mytable.ibd和mytable.exp文件复制到当前服务器的数据目录，然后使用如下命令将其“导入”：1mysql&gt; ALTER TABLE mydatabase.mytable IMPORT TABLESPACE; 使用Xtrabackup对数据库进行部分备份Xtrabackup也可以实现部分备份，即只备份某个或某些指定的数据库或某数据库中的某个或某些表。但要使用此功能，必须启用innodb_file_per_table选项，即每张表保存为一个独立的文件。同时，其也不支持–stream选项，即不支持将数据通过管道传输给其它程序进行处理。 此外，还原部分备份跟还原全部数据的备份也有所不同，即你不能通过简单地将prepared的部分备份使用–copy-back选项直接复制回数据目录，而是要通过导入表的方向来实现还原。当然，有些情况下，部分备份也可以直接通过–copy-back进行还原，但这种方式还原而来的数据多数会产生数据不一致的问题，因此，无论如何不推荐使用这种方式。 (1)创建部分备份 创建部分备份的方式有三种：正则表达式(–include), 枚举表文件(–tables-file)和列出要备份的数据库(–databases)。 (a)使用–include使用–include时，要求为其指定要备份的表的完整名称，即形如databasename.tablename，如：1innobackupex --include=&apos;^mageedu[.]tb1&apos; /path/to/backup (b)使用–tables-file此选项的参数需要是一个文件名，此文件中每行包含一个要备份的表的完整名称；如：12echo -e &apos;mageedu.tb1\nmageedu.tb2&apos; &gt; /tmp/tables.txtinnobackupex --tables-file=/tmp/tables.txt /path/to/backup (c)使用–databases此选项接受的参数为数据名，如果要指定多个数据库，彼此间需要以空格隔开；同时，在指定某数据库时，也可以只指定其中的某张表。此外，此选项也可以接受一个文件为参数，文件中每一行为一个要备份的对象。如：1innobackupex --databases=&apos;mageedu.tb1 testdb&quot; /path/to/backup (2)整理(preparing)部分备份 prepare部分备份的过程类似于导出表的过程，要使用–export选项进行：1innobackupex --apply-log --export /pat/to/partial/backup 此命令执行过程中，innobackupex会调用xtrabackup命令从数据字典中移除缺失的表，因此，会显示出许多关于“表不存在”类的警告信息。同时，也会显示出为备份文件中存在的表创建.exp文件的相关信息。 (3)还原部分备份 还原部分备份的过程跟导入表的过程相同。当然，也可以通过直接复制prepared状态的备份直接至数据目录中实现还原，不要此时要求数据目录处于一致状态。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>xtrabackup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis4.0配置文件介绍]]></title>
    <url>%2F2017%2F08%2F01%2Fredis4.0-config-file-explain.html</url>
    <content type="text"><![CDATA[Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程1daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定1pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字1port 6379 绑定的主机地址1bind 127.0.0.1 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能1timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null1logfile stdout 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： 123save 900 1save 300 10save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大1rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb1dbfilename dump.rdb 指定本地数据库存放目录1dir ./ 设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务设置了密码保护时，slave服务连接master的密码1masterauth &lt;master-password&gt; 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no1appendonly no 指定更新日志文件名，默认为appendonly.aof1appendfilename appendonly.aof 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）1appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中1vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享1vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为01vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值1vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。1vm-pages 134217728 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为41vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）1activerehashing yes 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件1include /path/to/local.conf]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaltStack学习记录]]></title>
    <url>%2F2017%2F05%2F09%2FSaltStack-stuty-record.html</url>
    <content type="text"><![CDATA[SaltStack 介绍salt是一个新的基础平台管理工具, 只需要花费数分钟即可运行起来, 扩展性足以支撑管理上万台服务器, 数秒钟即可完成数据传递。 经常被描述为Func加强版+Puppet精简版。 SaltStack采用C/S架构。简单的说: salt是一种全新的基础设施管理方式, 部署轻松, 在几分钟内可运行起来, 扩展性好。很容易管理上万台服务器, 速度快, 服务器之间秒级通信。 salt底层采用动态的连接总线, 使其可以用于编配, 远程执行, 配置管理等等。最为重要的一点, salt是开源的。 而且是python实现的自动化运维工具, 这意味着我们可以对其进行一些改动, 在其基础之上加上我们想要的功能, 对其进行二次开发。 环境介绍系统Centos7.2 x64两台, 一台为master,另一台为minion。 SaltStack安装两台安装epel1[root@localhost ~]# rpm -Uvh http://ftp.linux.ncsu.edu/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm 在master安装1[root@localhost ~]# yum -y install salt-master 在minion上运行1[root@localhost ~]# yum -y install salt-minion SAltStack配置修改master配置文件，并启动服务1234[root@localhost ~]# vim /etc/salt/master修改interface: 192.168.1.226 #master ip地址[root@localhost ~]# systemctl start salt-master 修改被管理端(minion)，并启动服务1234[root@localhost ~]# vim /etc/salt/minion修改master： 192.168.1.226[root@localhost ~]# systemctl start salt-minion master接受minion的托管请求，在master上操作1234567891011121314151617181920[root@localhost ~]# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:192.168.1.136Rejected Keys:[root@localhost ~]# salt-key -a 192.168.1.136The following keys are going to be accepted:Unaccepted Keys:192.168.1.136Proceed? [n/Y] yKey for minion 192.168.1.136 accepted.[root@localhost ~]# salt-key -LAccepted Keys:192.168.1.136Denied Keys:Unaccepted Keys:Rejected Keys: SAltStack操作基本操作命令通用格式1格式: 命令 对象 执行模块 参数salt ‘*’ cmd.run “ping -c 4 www.baidu.com&quot; 举个例子123456789[root@localhost ~]# salt &apos;*&apos; cmd.run &apos;uptime&apos;192.168.1.136: 21:14:44 up 1 day, 2:29, 3 users, load average: 0.10, 0.18, 0.13[root@localhost ~]# salt &apos;*&apos; cmd.run &apos;date&apos;192.168.1.136: Fri May 5 21:14:51 CST 2017[root@object1 ~]# salt &apos;*&apos; disk.usage 默认情况下master和minion之间使用以下端口进行通信:4505(publish_port)：salt的消息发布系统4506(ret_port)：salt客户端与服务端通信的端口cmd.run 为模块,又称之为超级命令. 可以执行Linux中的任何命令 Salt StatesSLS(代表Salt State文件)是Salt State系统的核心。SLS描述了系统的目标状态, 由格式简单的数据构成。 这经常被称作配置管理。 默认的数据 - YAML12]]></content>
      <tags>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录redis的RDB、AOF持久化]]></title>
    <url>%2F2017%2F05%2F08%2Frecord-redis-RDB%E3%80%81AOF-persistence.html</url>
    <content type="text"><![CDATA[Redis是个支持持久化的内存数据库，redis需要经常将内存中的数据同步到磁盘来保证持久化。 快照（Snapshotting）默认持久化方式配置1234snapshotting： save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒内如果超过10个key被修改，则发起快照保存save 60 10000 工作原理 Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）； 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件； 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。 优点 RDB是个非常紧凑的文件，保存了redis在某个时间点上的数据集，使得我们可以通过定时备份RDB文件来实现Redis数据库备份和灾难恢复，也可以将其传送到其他的数据中心用于保存。 RDB可以最大化redis的性能，执行RDB持久化时只需要fork一个子进程，并由子进程进行持久化工作，父进程不需要处理任何磁盘I/O操作。 RDB在恢复大数据集时比AOF要快，启动效率要高许多。 RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。 缺点 每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步增数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io操作，可能会严重影响性能。 快照方式是在一定间隔时间做一次的，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改，有一些数据丢失的风险。 client的save通知redis做一次快照持久化不推荐。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有client的请求，这种方式会阻塞所有client请求，所以不推荐使用。 日志追加方式（append-only file）方式配置12345aof：appendonly yes #启动aof持久化方式有三种修改方式#appendfsync always #收到写命令就立即写入到硬盘，效率最慢，但是保证完全持久化#appendfsync everysec #每秒种就写入一次硬盘，在性能和持久化方面做了折中#appendfsync no #完全依赖操作系统，性能最好，但是持久化没保证，不知道何时持久化 工作原理 redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 优点 该机制可以带来更高的数据安全性，即数据持久性。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，也可以通过该文件完成数据的重建。 缺点 对于相同数量的数据集而言，AOF文件通常要大于RDB文件，持久化文件会变的越来越大。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7用DevStack安装OpenStack]]></title>
    <url>%2F2017%2F05%2F05%2FCentOS7-DevStack-install-OpenStack.html</url>
    <content type="text"><![CDATA[准备阶段OpenStack源码1https://github.com/openstack DevStack源码1https://git.openstack.org/cgit/openstack-dev/devstack 设置aliyun的base源12[root@compute ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo[root@compute ~]# yum makecache DevStack和OpenStack源码可以替换为TryStack镜像1234# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git pip源地址可以换为国内的豆瓣源12345[root@compute ~]# mkdir /root/.pip[root@compute ~]# cat /root/.pip/pip.conf[global]index-url = http://pypi.douban.com/simple/trusted-host = pypi.douban.com 安装阶段下载DevStack1git clone http://git.trystack.cn/openstack-dev/devstack.git -b stable/ocata 创建stack用户123456[root@controller home]# mkdir -p /home/stack/logs[root@controller home]# cd devstack/tools/[root@controller home]# sudo ./create-stack-user.sh[root@controller home]# sudo passwd stack[root@controller home]# sudo chown –R stack:stack /home/devstack[root@controller home]# sudo chown –R stack:stack /home/stack 授权stack用户123[root@controller ~]# vim /etc/sudoers第98行，添加1行stack ALL=(ALL:ALL) ALL 创建local.conf文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@controller ~]# cat /home/devstack/local.conf [[local|localrc]]# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git#OFFLINE=TrueRECLONE=True# Define images to be automatically downloaded during the DevStack built process.DOWNLOAD_DEFAULT_IMAGES=FalseIMAGE_URLS=&quot;http://images.trystack.cn/cirros/cirros-0.3.4-x86_64-disk.img&quot;HOST_IP=192.168.1.225# CredentialsDATABASE_PASSWORD=passADMIN_PASSWORD=passSERVICE_PASSWORD=passSERVICE_TOKEN=passRABBIT_PASSWORD=passHORIZON_BRANCH=stable/ocataKEYSTONE_BRANCH=stable/ocataNOVA_BRANCH=stable/ocataNEUTRON_BRANCH=stable/ocataGLANCE_BRANCH=stable/ocataCINDER_BRANCH=stable/ocata#keystoneKEYSTONE_TOKEN_FORMAT=UUID##HeatHEAT_BRANCH=stable/ocataenable_service h-eng h-api h-api-cfn h-api-cw## SwiftSWIFT_BRANCH=stable/ocataENABLED_SERVICES+=,s-proxy,s-object,s-container,s-accountSWIFT_REPLICAS=1SWIFT_HASH=011688b44136573e209e# Enabling Neutron (network) Servicedisable_service n-netenable_service q-svcenable_service q-agtenable_service q-dhcpenable_service q-l3enable_service q-metaenable_service q-meteringenable_service neutron## Neutron optionsQ_USE_SECGROUP=TrueFLOATING_RANGE=&quot;192.168.1.0/24&quot;FIXED_RANGE=&quot;10.0.0.0/24&quot;NETWORK_GATEWAY=&quot;10.0.0.2&quot;Q_FLOATING_ALLOCATION_POOL=start=192.168.1.150,end=192.168.1.180PUBLIC_NETWORK_GATEWAY=&quot;192.168.1.200&quot;Q_L3_ENABLED=TruePUBLIC_INTERFACE=eth0Q_USE_PROVIDERNET_FOR_PUBLIC=TrueOVS_PHYSICAL_BRIDGE=br-exPUBLIC_BRIDGE=br-exOVS_BRIDGE_MAPPINGS=public:br-ex# #VLAN configuration.Q_PLUGIN=ml2ENABLE_TENANT_VLANS=True# LoggingLOGFILE=/home/stack/logs/stack.sh.logVERBOSE=TrueLOG_COLOR=TrueSCREEN_LOGDIR=/home/stack/logs 以stack用户身份运行脚本安装123[root@controller ~]# su stack[root@controller ~]# cd /home/devstack/[root@controller devstack]# ./stack.sh]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装KVM虚拟机]]></title>
    <url>%2F2017%2F05%2F04%2FCentOS7-install-KVM.html</url>
    <content type="text"><![CDATA[kvm相关安装包及其作用qemu-kvm 主要的KVM程序包python-virtinst 创建虚拟机所需要的命令行工具和程序库virt-manager GUI虚拟机管理工具virt-top 虚拟机统计命令virt-viewer GUI连接程序，连接到已配置好的虚拟机libvirt C语言工具包，提供libvirt服务libvirt-client 为虚拟客户机提供的C语言工具包virt-install 基于libvirt服务的虚拟机创建命令bridge-utils 创建和管理桥接设备的工具 验证CPU是否支持KVM；如果结果中有vmx（Intel）或svm(AMD)字样，就说明CPU的支持的。1[root@object1 ~]# egrep &apos;(vmx|svm)&apos; /proc/cpuinfo 安装KVM及其依赖项1[root@object1 ~]# yum install qemu-kvm virt-install bridge-utils libvirt virt-install virt-manager -y 验证安装结果123[root@object1 ~]# lsmod | grep kvmkvm_intel 162153 0 kvm 525409 1 kvm_intel 开启kvm服务，并且设置其开机自动启动12[root@object1 ~]# systemctl start libvirtd[root@object1 ~]# systemctl enable libvirtd 配置网桥模式1234567891011121314151617181920212223242526272829303132333435363738394041//创建 ifcfg-br0 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 BOOTPROTO=&quot;static&quot;DEVICE=&quot;br0&quot;NAME=&quot;br0&quot;TYPE=&quot;Bridge&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.1.226&quot;NETMASK=&quot;255.255.255.0&quot;GATEWAY=&quot;192.168.1.200&quot;DNS1=&quot;114.114.114.114&quot;DNS2=&quot;8.8.8.8&quot;//修改ifcfg-eno16777736 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eno16777736 #TYPE=&quot;Ethernet&quot;#BOOTPROTO=&quot;static&quot;#DEFROUTE=&quot;yes&quot;#PEERDNS=&quot;yes&quot;#PEERROUTES=&quot;yes&quot;#IPV4_FAILURE_FATAL=&quot;no&quot;#IPV6INIT=&quot;yes&quot;#IPV6_AUTOCONF=&quot;yes&quot;#IPV6_DEFROUTE=&quot;yes&quot;#IPV6_PEERDNS=&quot;yes&quot;#IPV6_PEERROUTES=&quot;yes&quot;#IPV6_FAILURE_FATAL=&quot;no&quot;#NAME=&quot;eno16777736&quot;#UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;#DEVICE=&quot;eno16777736&quot;#ONBOOT=&quot;yes&quot;#IPADDR=192.168.1.226#NETMASK=255.255.255.0#GATEWAY=192.168.1.200#PEERDNS=&quot;yes&quot;#DNS1=8.8.8.8NAME=&quot;eno16777736&quot;UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;DEVICE=&quot;eno16777736&quot;BRIDGE=&quot;br0&quot;ONBOOT=&quot;yes&quot; 重启网络服务12345[root@object1 ~]# systemctl restart network[root@object1 ~]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000c29e16c76 no eno16777736virbr0 8000.000000000000 yes 安装虚拟机//下载cirros linux，下载地址：http://download.cirros-cloud.net/1[root@object1 ~]# virt-install -n test001 -r 2048 --disk /home/test.img,format=qcow2,size=1 --network bridge=br0 --os-type=linux --os-variant=rhel7.2 --cdrom /root/cirros-0.3.5-x86_64-disk.img --vnc --vncport=5900 --vnclisten=0.0.0.0 使用VNC Viewer连接该虚拟机官网下载：https://www.realvnc.com/download/vnc/ //通过图形界面操作 安装X(X Window System)1[root@object1 ~]# yum groupinstall &quot;X Window System&quot; -y 安装GNOME(GNOME Desktop)1[root@object1 ~]# yum groupinstall &quot;GNOME Desktop&quot; -y 使用virt-manager管理kvm//本地需要安装xmanager和xshell工具 ，并使用xshell建立连接时勾选x11转移。1[root@object1 ~]# virt-manager]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建FastDFS分布式文件系统]]></title>
    <url>%2F2017%2F05%2F03%2Fdeploy-FastDFS.html</url>
    <content type="text"><![CDATA[FastDFS介绍FastDFS是一款类Google FS的开源分布式文件系统，它用纯C语言实现，支持Linux、FreeBSD、AIX等UNIX系统。它只能通过专有API对文件进行存取访问，不支持POSIX接口方式，不能mount使用。准确地讲，Google FS以及FastDFS、mogileFS、HDFS、TFS等类Google FS都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。FastDFS是一个开源的，高性能的的分布式文件系统，他主要的功能包括：文件存储，同步和访问，设计基于高可用和负载均衡，fastfd非常适用于基于文件服务的站点，例如图片分享和视频分享网站。FastDFS有两个角色：跟踪服务和存储服务，跟踪服务控制，调度文件以负载均衡的方式访问；存储服务包括：文件存储，文件同步，提供文件访问接口，同时以key value的方式管理文件的元数据。跟踪和存储服务可以由1台或者多台服务器组成，同时可以动态的添加，删除跟踪和存储服务而不会对在线的服务产生影响，在集群中，tracker服务是对等的。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 FastDFS架构客户端和Storage server主动连接Tracker server。Storage server主动向Tracker server报告其状态信息，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。Storage server会连接集群中所有的Tracker server，向他们报告自己的状态。Storage server启动一个单独的线程来完成对一台Tracker server的连接和定时报告。需要说明的是，一个组包含的Storage server不是通过配置文件设定的，而是通过Tracker server获取到的。不同组的Storage server之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步。Storage server采用binlog文件记录文件上传、删除等更新操作。binlog中只记录文件名，不记录文件内容。文件同步只在同组内的Storage server之间进行，采用push方式，即源头服务器同步给目标服务器。只有源头数据才需要同步，备份数据并不需要再次同步，否则就构成环路了。有个例外，就是新增加一台Storage server时，由已有的一台Storage server将已有的所有数据（包括源头数据和备份数据）同步给该新增服务器。Storage server中由专门的线程根据binlog进行文件同步。为了最大程度地避免相互影响以及出于系统简洁性考虑，Storage server对组内除自己以外的每台服务器都会启动一个线程来进行文件同步。文件同步采用增量同步方式，系统记录已同步的位置（binlog文件偏移量）到标识文件中。标识文件名格式：{dest storage IP}_{port}.mark，例如：192.168.1.14_23000.mark。 FastDFS文件上传下载交互过程 文件下载流程 Client询问Tracker server可以下载指定文件的Storage server，参数为文件ID（包含组名和文件名）； Tracker server返回一台可用的Storage server； Client直接和该Storage server建立连接，完成文件下载。文件上传流程 Client询问Tracker server上传到的Storage server； Tracker server返回一台可用的Storage server，返回的数据为该Storage server的IP地址和端口； Client直接和该Storage server建立连接，进行文件上传，Storage server返回新生成的文件ID，文件上传结束。 FastDFS安装系统环境1CentOS Linux release 7.2.1511 (Core) 下载并安装FastDFS依赖包libfastcommon12345[root@object1 ~]# wget https://codeload.github.com/happyfish100/libfastcommon/zip/master[root@object1 ~]# unzip master[root@object1 ~]# cd libfastcommon-master/[root@object1 libfastcommon-master]# ./make.sh[root@object1 libfastcommon-master]# ./make.sh install 下载并安装FastDFS1234[root@object1 ~]# wget https://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Server%20Source%20Code/FastDFS%20Server%20with%20PHP%20Extension%20Source%20Code%20V5.08/FastDFS_v5.08.tar.gz[root@object1 ~]# tar zxvf FastDFS_v5.08.tar.gz [root@object1 ~]# cd FastDFS[root@object1 FastDFS]# ./make.sh &amp;&amp; ./make.sh install 默认脚本目录1[root@object1 ~]# ll /etc/init.d/ | grep fdfs 样例配置文件1[root@object1 ~]# ll /etc/fdfs/ 注意：虽然FastDFS区分tracker和storage服务器，但是安装的软件及步骤均相同，只是不同的配置文件而已，因此以上安装适用tracker server和storage server 配置跟踪服务器（tracker server）拷贝tracker server和client端样例配置文件并重命名12[root@object1 ~]# cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf[root@object1 ~]# cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 修改client.conf12第14行 tracker_server=192.168.1.226:22122 启动tracker server12[root@object1 ~]# /etc/init.d/fdfs_trackerd start[root@object1 ~]# ss -tunlp | grep 22122 配置存储服务器（storage server）拷贝storage server样例配置文件并重命名1[root@object1 ~]# cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 修改storage.conf12第118行tracker_server=192.168.1.226:22122 启动storage server（启动storage server的前提是tracker server必须事先已启动）12[root@object1 ~]# /etc/init.d/fdfs_storaged start[root@object1 ~]# ss -tunlp | grep 23000 文件上传测试12[root@object1 ~]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/test.jpg group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg 存储服务器（storage server）安装并配置nginx下载并安装fastdfs-nginx-module模块注：FastDFS通过Tracker服务器,将文件放在Storage服务器存储，但是同组存储服务器之间需要进入文件复制，有同步延迟的问题。假设Tracker服务器将文件上传到了192.168.1.226，上传成功后文件ID已经返回给客户端。此时FastDFS存储集群机制会将这个文件同步到同组存储192.168.1.227，在文件还没有复制完成的情况下，客户端如果用这个文件ID在192.168.1.227上取文件,就会出现文件无法访问的错误。而fastdfs-nginx-module可以重定向文件连接到源服务器取文件,避免客户端由于复制延迟导致的文件无法访问错误。 12345678910[root@object1 ~]# wget http://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Nginx%20Module%20Source%20Code/fastdfs-nginx-module_v1.16.tar.gz[root@object1 ~]# tar zxvf fastdfs-nginx-module_v1.16.tar.gz [root@object1 ~]# cd fastdfs-nginx-module/src/[root@object1 src]# vim config 编辑config文件，执行如下命令进行批量替换并保存退出:%s+/usr/local/+/usr/+g[root@object1 src]# cp mod_fastdfs.conf /etc/fdfs/修改mod_fastdfs.conf第40行tracker_server=192.168.1.226:22122 安装nginx依赖库1[root@object1 ~]# yum install -y pcre-devel zlib-devel nginx 安装nginx12345[root@object1 ~]# wget http://nginx.org/download/nginx-1.13.0.tar.gz[root@object1 ~]# tar zxvf nginx-1.13.0.tar.gz[root@object1 ~]# cd nginx-1.13.0[root@object1 nginx-1.13.0]# ./configure --prefix=/usr/local/nginx --add-module=/root/fastdfs-nginx-module/src/[root@object1 nginx-1.13.0]# make &amp;&amp; make install 拷贝FastDFS中的部分配置文件到/etc/fdfs目录中12[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/http.conf /etc/fdfs/[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/mime.types /etc/fdfs/ 配置nginx123456789[root@object1 ~]# vim /usr/local/nginx/conf/nginx.conf修改1行user root; #解决下载操作时报404的问题修改36行listen 8888; #storage.conf配置文件一致添加location ~/group[0-9]/ &#123; ngx_fastdfs_module; &#125; 拷贝nginx服务到/etc/init.d/目录下并启动123[root@object1 ~]# cp /usr/local/nginx/sbin/nginx /etc/init.d/[root@object1 ~]# /etc/init.d/nginx[root@object1 ~]# ss -tunlp | grep 8888 通过浏览器访问之前已经上传的文件123456789101112http://192.168.1.226:8888/group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg访问出现400 Bad Request查看日志[root@object1 ~]# vim /usr/local/nginx/logs/error.log 报错信息[2017-05-03 17:00:38] ERROR - file: ../common/fdfs_global.c, line: 52, the format of filename &quot;group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg&quot; is invalid解决方法：[root@object1 ~]# vim /etc/fdfs/mod_fastdfs.conf修改53行url_have_group_name = true]]></content>
      <tags>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录MongoDB3.4分片的一些配置]]></title>
    <url>%2F2017%2F05%2F03%2Frecord-MongoDB3.4-shard-some-config.html</url>
    <content type="text"><![CDATA[MongoDB介绍MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB特点 MongoDB的提供了一个面向文档存储，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Ning”,Address=”Beijing”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装yum安装官网：https://docs.mongodb.com/master/tutorial/install-mongodb-on-red-hat/ 123456789[root@object1 ~]# vim /etc/yum.repos.d/mongodb-org-3.4.repo[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc[root@object1 ~]#sudo yum install -y mongodb-org 下载官网：https://www.mongodb.com/download-center?jmp=nav#community 123456[root@object1 ~]#curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.4.tgz[root@object1 ~]#tar -zxvf mongodb-linux-x86_64-rhel70-3.4.4.tgz [root@object1 ~]# mv mongodb-linux-x86_64-rhel70-3.4.4 /usr/local/mongodb#把安装目录添加到系统环境中export PATH=/usr/local/mongodb/bin:$PATH 配置文件官网：https://docs.mongodb.com/manual/administration/configuration/ 12345678910111213141516171819202122232425262728#使用YAML配置也可以使用原ini配置#基本设置processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: true#安全security: authorization: enablednet: bindIp: 192.168.1.226 port: 27017#副本集replication: replSetName: set0#副本集安全security: keyFile: /home/mongodb/keyfile 分片配置分片服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truenet: bindIp: 192.168.1.226 port: 27017sharding: clusterRole: shardsvrreplication: replSetName: shardA 配置服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truesharding: clusterRole: configsvrnet: bindIp: 192.168.1.226 port: 27001replication: replSetName: csRS 路由服务器 1234567891011121314151617processManagement: fork: true pidFilePath: /home/mongodb/mongos.pid#storage:# dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongos.log&quot; logAppend: true#storage:# journal:# enabled: truenet: bindIp: 192.168.1.226 port: 28001sharding: configDB: csRS/192.168.1.226:27001,192.168.1.226:27002,192.168.1.226:27003 启动mongodb123[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 分片服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 配置服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongos -f 路由服务器配置文件 初始化mongodb分片服务器 12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27017&gt;use admin&gt;config = &#123;_id:&quot;shardA&quot;,members:[&#123;_id:0, host:&quot;192.168.1.226:27017&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27018&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27019&quot;&#125;]&#125;&gt;rs.initiate(config) 配置服务器12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27001&gt;use admin&gt;config = &#123;_id:&quot;csRS&quot;,configsvr:true,members:[&#123;_id:0, host:&quot;192.168.1.226:27001&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27002&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27003&quot;&#125;]&#125;&gt;rs.initiate(config) 启动分片123[root@object1 mongodb]# mongo --port 28001mongos&gt; use adminmongos&gt; db.runCommand( &#123; addShard: &quot;shardA/192.168.1.226:27017,192.168.1.226:27018,192.168.1.226:27019&quot;&#125; )]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 LDAP统一认证部署]]></title>
    <url>%2F2017%2F05%2F02%2FCentOS7-LDAP-deployment.html</url>
    <content type="text"><![CDATA[LDAP介绍LDAP是轻量目录访问协议，英文全称是Lightweight Directory Access Protocol，简称为LDAP。它是基于X.500标准的，但是简单多了并且可以根据需要定制。与X.500不同，LDAP支持TCP/IP。LDAP的核心规范在RFC中都有定义，所有与LDAP相关的RFC都可以在LDAPman RFC网页中找到。 使用目的使用LDAP对运维相关用户名密码做统一管理。可以实现一个帐号登录多个不同系统。 LDAP部署LDAP Server端安装1[root@object1 ~]# yum install -y openldap openldap-clients openldap-servers migrationtools LDAP 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#配置 OpenLDAP Server[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;2\&#125;hdb.ldif dn: olcDatabase=&#123;2&#125;hdb修改两行olcSuffix: dc=hyman,dc=comolcRootDN: cn=Manager,dc=hyman,dc=com新增一行olcRootPW: 123456#配置 Monitoring Database[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;1\&#125;monitor.ldifdn: olcDatabase=&#123;1&#125;monitor修改一行olcAccess: &#123;0&#125;to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=extern al,cn=auth&quot; read by dn.base=&quot;cn=Manager,dc=hyman,dc=com&quot; read by * none#初始化 LDAP database[root@object1 ~]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG[root@object1 ~]# chown -R ldap.ldap /var/lib/ldap/#测试 configuration[root@object1 ~]# slaptest -u#启动服务并开机自启[root@object1 ~]# systemctl start slapd[root@object1 ~]# systemctl enable slapd#查看状态[root@object1 ~]# netstat -lt | grep ldap#将所有的配置LDAP server, 添加到LDAP schemas中[root@object1 ~]# cd /etc/openldap/schema/ ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f cosine.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f nis.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f collective.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f corba.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f core.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f duaconf.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f dyngroup.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f inetorgperson.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f java.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f ppolicy.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f pmi.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f openldap.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f misc.ldif#使用Migration Tools 创建 LDAP DIT[root@object1 schema]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_common.ph修改61行$NAMINGCONTEXT&#123;&apos;group&apos;&#125; = &quot;ou=Groups&quot;;修改71行$DEFAULT_MAIL_DOMAIN = &quot;hyman.com&quot;;修改74行$DEFAULT_BASE = &quot;dc=hyman,dc=com&quot;;修改90行$EXTENDED_SCHEMA = 1;#创建 base.ldif[root@object1 migrationtools]# ./migrate_base.pl &gt; /root/base.ldif#导入LDAP database[root@object1 migrationtools]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f /root/base.ldif#创建用户和用户组，并将其从本地数据库迁移到LDAP数据库[root@object1 migrationtools]# mkdir /home/guests[root@object1 migrationtools]# useradd -d /home/guests/ldapuser1 ldapuser1[root@object1 migrationtools]# useradd -d /home/guests/ldapuser2 ldapuser2[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser1[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser2#过滤掉这些用户和组和密码从/etc/shadow到不同的文件[root@object1 ~]# getent passwd | tail -n 5 &gt; /root/users[root@object1 ~]# getent shadow | tail -n 5 &gt; /root/shadow[root@object1 ~]# getent group | tail -n 5 &gt; /root/groups#创建这些用户使用migrationtools[root@object1 ~]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_passwd.pl 修改188行把 /etc/shadow 替换为 /root/shadow[root@object1 migrationtools]# ./migrate_passwd.pl /root/users &gt; users.ldif[root@object1 migrationtools]# ./migrate_passwd.pl /root/groups &gt; groups.ldif#上传这些用户和组LDAP数据库[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f users.ldif[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f groups.ldif#所有记录搜索LDAP DIT[root@object1 ~]# ldapsearch -x -b &quot;dc=hyman,dc=com&quot; -H ldap://127.0.0.1 LDAP 客户端验证1234[root@block1 ~]# yum install -y nss-pam*[root@block1 ~]# authconfig-tui 选择第二个Use LDAP[root@block1 ~]# su ldaduser1]]></content>
      <tags>
        <tag>LDAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7通过yum安装ansible]]></title>
    <url>%2F2017%2F04%2F27%2FCentOS7-install-ansible.html</url>
    <content type="text"><![CDATA[一、ansible介绍1、ansible 简介Ansible官方的 title 是“Ansible is Simple IT Automation”——简单的自动化IT工具。Ansible是一款为类Unix系统开发的自由开源的配置和自动化工具。它用Python写成，类似于Chef和Puppet，但是有一个不同的优点是我们不需要在节点中安装任何客户端。它使用SSH来和节点进行通信。 2、ansible 特点（1） No agents：不需要在被管控主机上安装任意客户端；（2） No server：无服务器端，使用时直接运行命令即可；（3） Modules in any languages：基于模块工作，可使用任意语言开发模块（4） YAML，not code：使用yaml语言定制剧本playbook；（5） SSH by default：基于SSH工作；（6） Strong multi-tier solution：可实现多级指挥； 二、Ansible安装使用1、 设置EPEL仓库1[root@object1 ~]# rpm -iUvh http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm 2、使用yum安装Ansible1[root@object1 ~]# yum install -y ansible 3、设置用于节点鉴权的SSH密钥1234#在Ansible服务端生成密钥[root@object1 ~]# ssh-keygen #使用ssh-copy-id命令来复制Ansible公钥到节点中[root@object1 ~]# ssh-copy-id -i root@192.168.1.215 4、为Ansible定义节点的清单1234[root@object1 ~]# cat /etc/ansible/hosts[test]192.168.1.226192.168.1.215 5、尝试在Ansible服务端运行命令123456789101112131415161718192021222324252627282930313233343536#使用ping检查ansible节点的连通性[root@object1 ~]# ansible -m ping &apos;test&apos;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;#检查Ansible节点的运行时间（uptime）[root@object1 ~]# ansible -m command -a &quot;uptime&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 07:11:16 up 42 days, 13:43, 1 user, load average: 0.00, 0.00, 0.00#检查节点的内核版本[root@object1 ~]# ansible -m command -a &quot;uname -r&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt;2.6.32-573.3.1.el6.x86_64#给节点增加用户[root@object1 ~]# ansible -m command -a &quot;useradd test&quot; &quot;test&quot;192.168.1.226 | SUCCESS | rc=0 &gt;&gt;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 6、模块的使用查看各模块的使用方法12345ansible-doc [options] [modules] ：Show Ansible module documentation -l 列出所有的ansible模块 -s 列出该模块的相关指令可以直接使用 ansible-doc 模块名 来查看模块的使用，如# ansible-doc htpasswd 三、playbook的使用YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。 YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。 1、playbook使用1ansible-playbook test.yaml 下面就是一个只包含了一个play的playbook，在写playbook的时候，一定要记住在 hosts，yum（模块儿名）等后带空格，否则会报错。 12345678910111213141516171819202122#这个是你选择的主机- hosts: webservers#这个是变量 vars: http_port: 80 max_clients: 200#远端的执行权限 remote_user: root tasks:#利用yum模块来操作 - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf #触发重启服务器 notify: - restart apache - name: ensure apache is running service: name=httpd state=started #这里的restart apache 和上面的触发是配对的。这就是handlers的作用。相当于tag handlers: - name: restart apache service: name=httpd state=restarted 2、playbook案例corosync.yaml 12345678910111213141516171819202122232425262728293031323334353637- hosts: hanodes #指定要执行任务的主机，可由冒号分隔主机组 remote_user: root #指定远程主机上执行任务的用户 vars: #定义如下2个变量 crmsh: crmsh-1.2.6.4.el6.x86_64.rpm pssh: pssh-2.3.1-2.el6.x86_64.rpm tasks: #指定需执行的任务列表，每个task都有其name和使用的模块及参数 - name: test connection ping: #ping模块无需执行参数 remote_user: jason #在task中指定远程主机上执行任务的用户 sudo: yes #使用sudo在远程主机上执行任务 - name: corosync installing yum: name=corosync state=present - name: pacemaker installing #定义一个软件安装任务 yum: name=pacemaker state=present #使用yum安装，并配置需安装的软件名（name），及状态（state） - name: crmsh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; crmsh &#125;&#125; dest=/tmp/&#123;&#123; crmsh &#125;&#125; - name: pssh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; pssh &#125;&#125; dest=/tmp/&#123;&#123; pssh &#125;&#125; - name: crmsh installing command: yum -y reinstall /tmp/&#123;&#123; crmsh &#125;&#125; /tmp/&#123;&#123; pssh &#125;&#125; - name: authkey configure file copy: src=/ansible/corosync/conf/authkey dest=/etc/corosync/authkey - name: authkey mode 400 #定义一个文件权限设置任务 file: path=/etc/corosync/authkey mode=400 notify: #定义一个通知，当此任务执行时，可以激发响应的handler - restart corosync - name: corosync.conf configure file copy: src=/ansible/corosync/conf/corosync.conf dest=/etc/corosync/corosync.conf tags: - conf notify: - restart corosync - name: ensure the corosync service startup on boot service: name=corosync state=started enabled=yes handlers: #定义当关注的资源发生变化时，需采取的操作 - name: restart corosync #定义一个服务重启任务 service: name=corosync state=restarted heartbeat.yaml 123456789101112131415161718- hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted]]></content>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper、Dubbo-Admin管理平台的搭建]]></title>
    <url>%2F2017%2F04%2F26%2FZookeeper-Dubbo-Admin-platform-deploy.html</url>
    <content type="text"><![CDATA[ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。 ZooKeeper官网为：http://zookeeper.apache.org/Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容。 Dubbo官网为：http://dubbo.io/ 一、zookeeper安装与启动首先需要安装JdK，从Oracle的Java网站下载，安装很简单，就不再详述。zookeeper的下载地址 1http://www.apache.org/dyn/closer.cgi/zookeeper/ 下载后直接解压，不用安装 1[root@object1 home]# tar zxvf zookeeper-3.4.10.tar.gz 修改默认配置 1[root@object1 conf]# cp zoo_sample.cfg zoo.cfg 参数说明: tickTime：zookeeper中使用的基本时间单位, 毫秒值这个时间是作为Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：数据目录. 可以是任意目录，默认情况下，Zookeeper 将写数据 的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 至此, zookeeper的单机模式已经配置好了，启动ZooKeeper 1[root@object1 zookeeper-3.4.10]# sh bin/zkServer.sh start 二、Dubbo-admin管理平台的安装因为zookeeper只是一个黑框，我们无法看到是否存在了什么提供者或消费者，这时就要借助Dubbo-Admin管理平台来实时的查看，也可以通过这个平台来管理提者和消费者。制作了基于jdk1.8打包的dubbo-admin.war 下载地址 1http://download.csdn.net/detail/qq_30567735/9826361 dubbo源码 1https://github.com/alibaba/dubbo 下载好dubbo-admin.war后，我们就可以按常用的web部署方式进行部署即可，把war包放到tomcat的webapps目录下，启动tomcat，后再部署下相应的参数。 启动tomcat 1[root@object1 apache-tomcat-7.0.62]# sh bin/startup.sh 访问项目地址即可 1http: //ip地址:端口号/dubbo-admin-2.5.4/]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL自带压力测试工具mysqlslap的使用方法]]></title>
    <url>%2F2017%2F04%2F26%2FMySQL%E8%87%AA%E5%B8%A6%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7mysqlslap%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[mysqlslap是从5.1.4版开始的一个MySQL官方提供的压力测试工具。通过模拟多个并发客户端访问MySQL来执行压力测试，并输出计时信息。并且能很好的对比多个存储引擎在相同环境下的并发压力性能差别。可以指定SQL语句。如果没有指定SQL语句，mysqlslap会自动生成查询schema的SELECT语句。1、查看帮助信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126[root@object1 local]# mysqlslap --helpmysqlslap Ver 1.0 Distrib 5.7.18, for Linux (x86_64)Copyright (c) 2005, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Run a query multiple times against the server.Usage: mysqlslap [OPTIONS]Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf The following groups are read: mysqlslap clientThe following options may be given as the first argument:--print-defaults Print the program argument list and exit.--no-defaults Don&apos;t read default options from any option file, except for login file.--defaults-file=# Only read default options from the given file #.--defaults-extra-file=# Read this file after the global files are read.--defaults-group-suffix=# Also read groups with concat(group, suffix)--login-path=# Read this path from the login file. -?, --help Display this help and exit. -a, --auto-generate-sql 自动生成测试表和数据 Generate SQL where not supplied by file or command line. --auto-generate-sql-add-autoincrement 增加auto_increment一列 Add an AUTO_INCREMENT column to auto-generated tables. --auto-generate-sql-execute-number=# 自动生成的查询的个数 Set this number to generate a set number of queries to run. --auto-generate-sql-guid-primary 增加基于GUID的主键 Add GUID based primary keys to auto-generated tables. --auto-generate-sql-load-type=name 测试语句的类型。取值包括：read，key，write，update和mixed(默认) Specify test load type: mixed, update, write, key, or read; default is mixed. --auto-generate-sql-secondary-indexes=# 增加二级索引的个数，默认是0 Number of secondary indexes to add to auto-generated tables. --auto-generate-sql-unique-query-number=# 不同查询的数量，默认值是10 Number of unique queries to generate for automatic tests. --auto-generate-sql-unique-write-number=# 不同插入的数量，默认是100 Number of unique queries to generate for auto-generate-sql-write-number. --auto-generate-sql-write-number=# Number of row inserts to perform for each thread (default is 100). --commit=# 多少条DML后提交一次 Commit records every X number of statements. -C, --compress 如果服务器和客户端支持都压缩，则压缩信息传递 Use compression in server/client protocol. -c, --concurrency=name 模拟N个客户端并发执行select。可指定多个值，以逗号或者 --delimiter 参数指定的值做为分隔符 Number of clients to simulate for query to run. --create=name 指定用于创建表的.sql文件或者字串 File or string to use create tables. --create-schema=name 指定待测试的数据库名，MySQL中schema也就是database，默认是mysqlslap Schema to run tests in. --csv[=name] Generate CSV output to named file or to stdout if no file is named. -#, --debug[=#] This is a non-debug version. Catch this and exit. --debug-check This is a non-debug version. Catch this and exit. -T, --debug-info 打印内存和CPU的信息 This is a non-debug version. Catch this and exit. --default-auth=name Default authentication client-side plugin to use. -F, --delimiter=name 文件中的SQL语句使用分割符号 Delimiter to use in SQL statements supplied in file or command line. --detach=# 每执行完N个语句，先断开再重新打开连接 Detach (close and reopen) connections after X number of requests. --enable-cleartext-plugin Enable/disable the clear text authentication plugin. -e, --engine=name 创建测试表所使用的存储引擎，可指定多个 Storage engine to use for creating the table. -h, --host=name Connect to host. -i, --iterations=# 迭代执行的次数 Number of times to run the tests. --no-drop Do not drop the schema after the test. -x, --number-char-cols=name 自动生成的测试表中包含多少个字符类型的列，默认1 Number of VARCHAR columns to create in table if specifying --auto-generate-sql. -y, --number-int-cols=name 自动生成的测试表中包含多少个数字类型的列，默认1 Number of INT columns to create in table if specifying --auto-generate-sql. --number-of-queries=# 总的测试查询次数(并发客户数×每客户查询次数) Limit each client to this number of queries (this is not exact). --only-print 只输出模拟执行的结果，不实际执行Do not connect to the databases, but instead print out what would have been done. -p, --password[=name] Password to use when connecting to server. If password is not given it&apos;s asked from the tty. --plugin-dir=name Directory for client-side plugins. -P, --port=# Port number to use for connection. --post-query=name 测试完成以后执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute after tests have completed. --post-system=name 测试完成以后执行的系统语句 这个过程不影响时间计算system() string to execute after tests have completed. --pre-query=name 测试执行之前执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute before running tests. --pre-system=name 测试执行之前执行的系统语句 这个过程不影响时间计算system() string to execute before running tests. --protocol=name The protocol to use for connection (tcp, socket, pipe, memory). -q, --query=name 指定自定义.sql脚本执行测试。例如可以调用自定义的一个存储过程或者sql语句来执行测试Query to run or file containing query to run. --secure-auth Refuse client connecting to server if it uses old (pre-4.1.1) protocol. Deprecated. Always TRUE -s, --silent 不输出Run program in silent mode - no output. -S, --socket=name The socket file to use for connection. --sql-mode=name Specify sql-mode to run mysqlslap tool. --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) --ssl-verify-server-cert Deprecated. Use --ssl-mode=VERIFY_IDENTITY instead. --ssl-ca=name CA file in PEM format. --ssl-capath=name CA directory. --ssl-cert=name X509 cert in PEM format. --ssl-cipher=name SSL cipher to use. --ssl-key=name X509 key in PEM format. --ssl-crl=name Certificate revocation list. --ssl-crlpath=name Certificate revocation list path. --tls-version=name TLS version to use, permitted values are: TLSv1, TLSv1.1 -u, --user=name User for login if not current user. -v, --verbose 输出更多的信息More verbose output; you can use this multiple times to get even more verbose output. -V, --version Output version information and exit. 2、以自动生成测试表和数据的形式，分别模拟 50 和 100 个客户端并发连接处理 1000 个 query 的情况。 123456789101112131415[root@object1 local]# mysqlslap -uroot -p&apos;CAOcao123~!@&apos; -a --concurrency=50,100 --number-of-queries=1000 mysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Average number of seconds to run all queries: 0.605 seconds Minimum number of seconds to run all queries: 0.605 seconds Maximum number of seconds to run all queries: 0.605 seconds Number of clients running queries: 50 Average number of queries per client: 20Benchmark Average number of seconds to run all queries: 0.534 seconds Minimum number of seconds to run all queries: 0.534 seconds Maximum number of seconds to run all queries: 0.534 seconds Number of clients running queries: 100 Average number of queries per client: 10 3、增加 –debug-info 选项，可以输出内存和CPU信息。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7通过yum安装最新版本MySQL]]></title>
    <url>%2F2017%2F04%2F26%2FCentOS7-yum-install-MySQL.html</url>
    <content type="text"><![CDATA[CentOS 7之后的版本yum的默认源中使用MariaDB替代原先MySQL，因此安装方式较为以往有一些改变： 卸载原来的MariaDB 1yum remove -y mariadb-config-3:10.1.17-1.el7.x86_64 下载mysql的源 1wget http://dev.mysql.com/get/mysql57-community-release-el7-7.noarch.rpm 安装yum库 1yum localinstall -y mysql57-community-release-el7-7.noarch.rpm 安装MySQL 1yum install -y mysql-community-server 启动MySQL服务 1systemctl start mysqld.service MySQL5.7加强了root用户的安全性，因此在第一次安装后会初始化一个随机密码，以下为查看初始随机密码的方式 1grep &apos;temporary password&apos; /var/log/mysqld.log 使用初始随机密码登录后MySQL会强制要求修改密码，否则无法正常使用，（密码必须包含小写、大写字母及特殊字符，当然也有其他方法不受此限制，再次不多做描述），修改方法如下： 123SET PASSWORD = PASSWORD(&apos;your new password&apos;);ALTER USER &apos;root&apos;@&apos;localhost&apos; PASSWORD EXPIRE NEVER;flush privileges; 然后退出后即可用新密码登录。 远程连接授权： 1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;your password&apos; WITH GRANT OPTION;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+github+next搭建的blog]]></title>
    <url>%2F2017%2F01%2F13%2FHexo-github-next-blog.html</url>
    <content type="text"><![CDATA[搭建环境：Windows 10 软件工具：git、node.js、hexo、Markdownpad2 一、环境搭建 安装git git官网(http://git-scm.com) 安装Node.js node.js官网(https://nodejs.org/en/) 二、安装和配置Hexo 执行cmd命令 npm install -g hexo-cli 本地创建Hexo文件夹，本目录下执行cmd命令 hexo init npm install 启动Hexo hexo server 更改hexo主题，在Hexo目录下载next主题 git clone https://github.com/iissnan/hexo-theme-next themes/next 修改Hexo配置文件_config.yml theme: next 重启Hexo，基本更改过来了，其他修改具体查看GITBUB 创建文章，执行cmd命令 hexo new 文章主题 执行命令后，在文件下的source_posts，自动生成以后缀为md的文件，修改md内容 生成html文件，执行cmd命令 hexo d -g 自动会生存静态文件在public文件夹下，把里面的文件全部上传至自己的github下即可]]></content>
  </entry>
</search>
