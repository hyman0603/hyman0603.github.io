<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[使用Xtrabackup进行MySQL备份]]></title>
      <url>%2F2017%2F08%2F08%2F%E4%BD%BF%E7%94%A8Xtrabackup%E8%BF%9B%E8%A1%8CMySQL%E5%A4%87%E4%BB%BD%2F</url>
      <content type="text"><![CDATA[Xtrabackup介绍Xtrabackup是由percona提供的mysql数据库备份工具，据官方介绍，这也是世界上惟一一款开源的能够对innodb和xtradb数据库进行热备的工具。特点： 备份过程快速、可靠；备份过程不会打断正在执行的事务；能够基于压缩等功能节约磁盘空间和流量；自动实现备份检验；还原速度快； 下载安装xtrabackup1234https://www.percona.com/downloads/XtraBackup/LATEST/[root@node1 ~]# yum localinstall percona-xtrabackup-24-2.4.8-1.el6.x86_64.rpm[root@node1 ~]# yum install http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm 备份完全备份1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 /home/backup/ 使用innobakupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以时间命令的目录中。 在备份的同时，innobackupex还会在备份目录中创建如下文件：(1)xtrabackup_checkpoints – 备份类型（如完全或增量）、备份状态（如是否已经为prepared状态）和LSN(日志序列号)范围信息；每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的。 (2)xtrabackup_binlog_info – mysql服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置。 (3)xtrabackup_binlog_pos_innodb – 二进制日志文件及用于InnoDB或XtraDB表的二进制日志文件的当前position。 (4)xtrabackup_binary – 备份中用到的xtrabackup的可执行文件； (5)backup-my.cnf – 备份命令用到的配置选项信息； 在使用innobackupex进行备份时，还可以使用–no-timestamp选项来阻止命令自动创建一个以时间命名的目录；如此一来，innobackupex命令将会创建一个BACKUP-DIR目录来存储备份数据。 准备(prepare)一个完全备份一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log /home/backup/2017-08-08_15-28-09/ 在实现“准备”的过程中，innobackupex通常还可以使用–use-memory选项来指定其可以使用的内存的大小，默认通常为100M。如果有足够的内存可用，可以多划分一些内存给prepare的过程，以提高其完成速度。 从一个完全备份中恢复数据innobackupex命令的–copy-back选项用于执行恢复操作，其通过复制所有数据相关的文件至mysql服务器DATADIR目录中来执行恢复过程。innobackupex通过backup-my.cnf来获取DATADIR目录的相关信息。123456789[root@localhost ~]# rm -rf data/*[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --copy-back /home/backup/2017-08-08_15-28-09/[root@localhost ~]# chown -R mysql:mysql data[root@localhost ~]# killall mysqld#####可以不用启动mysql恢复数据##### 增量备份每个InnoDB的页面都会包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长。这正是InnoDB表可以进行增量备份的基础，即innobackupex通过备份上次完全备份之后发生改变的页面来实现。1[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --incremental /home/backup/ --incremental-basedir=/home/backup/2017-08-08_15-28-09/ 此命令执行结束后，innobackupex命令会在/backup目录中创建一个新的以时间命名的目录以存放所有的增量备份数据。另外，在执行过增量备份之后再一次进行增量备份时，其–incremental-basedir应该指向上一次的增量备份所在的目录。 需要注意的是，增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 “准备”(prepare)增量备份与整理完全备份有着一些不同，尤其要注意的是：(1)需要在每个备份(包括完全和各个增量备份)上，将已经提交的事务进行“重放”。“重放”之后，所有的备份数据将合并到完全备份上。(2)基于所有的备份将未提交的事务进行“回滚”。123[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log --redo-only /home/backup/2017-08-08_15-28-09/[root@localhost ~]# innobackupex --defaults-file=/usr/local/mysql-test3/my.cnf --user=root --password=123456 --port=3312 --host=127.0.0.1 --apply-log --redo-only /home/backup/2017-08-08_15-28-09/ --incremental-dir=/home/backup/2017-08-08_16-10-12/ Xtrabackup的“流”及“备份压缩”功能Xtrabackup对备份的数据文件支持“流”功能，即可以将备份的数据通过STDOUT传输给tar程序进行归档，而不是默认的直接保存至某备份目录中。要使用此功能，仅需要使用–stream选项即可。如： 1innobackupex --stream=tar /backup | gzip &gt; /backup/`date +%F_%H-%M-%S`.tar.gz 甚至也可以使用类似如下命令将数据备份至其它服务器：1innobackupex --stream=tar /backup | ssh &quot;cat - &gt; /backups/`date +%F_%H-%M-%S`.tar&quot; 此外，在执行本地备份时，还可以使用–parallel选项对多个文件进行并行复制。此选项用于指定在复制时启动的线程数目。当然，在实际进行备份时要利用此功能的便利性，也需要启用innodb_file_per_table选项或共享的表空间通过innodb_data_file_path选项存储在多个ibdata文件中。对某一数据库的多个文件的复制无法利用到此功能。其简单使用方法如下：1innobackupex --parallel /path/to/backup 同时，innobackupex备份的数据文件也可以存储至远程主机，这可以使用–remote-host选项来实现：1innobackupex --remote-host=root@ww agedu.com /path/IN/REMOTE/HOST/to/backup 导入或导出单张表默认情况下，InnoDB表不能通过直接复制表文件的方式在mysql服务器之间进行移植，即便使用了innodb_file_per_table选项。而使用Xtrabackup工具可以实现此种功能，不过，此时需要“导出”表的mysql服务器启用了innodb_file_per_table选项（严格来说，是要“导出”的表在其创建之前，mysql服务器就启用了innodb_file_per_table选项），并且“导入”表的服务器同时启用了innodb_file_per_table和innodb_expand_import选项。 (1)“导出”表导出表是在备份的prepare阶段进行的，因此，一旦完全备份完成，就可以在preparef过程中通过–export选项将某表导出了：1innobackupex --apply-log --export /path/to/backup 此命令会为每个innodb表的表空间创建一个以.exp结尾的文件，这些以.exp结尾的文件则可以用于导入至其它服务器。 (2)“导入”表要在mysql服务器上导入来自于其它服务器的某innodb表，需要先在当前服务器上创建一个跟原表表结构一致的表，而后才能实现将表导入：1mysql&gt; CREATE TABLE mytable (...) ENGINE=InnoDB; 然后将此表的表空间删除：1mysql&gt; ALTER TABLE mydatabase.mytable DISCARD TABLESPACE; 接下来，将来自于“导出”表的服务器的mytable表的mytable.ibd和mytable.exp文件复制到当前服务器的数据目录，然后使用如下命令将其“导入”：1mysql&gt; ALTER TABLE mydatabase.mytable IMPORT TABLESPACE; 使用Xtrabackup对数据库进行部分备份Xtrabackup也可以实现部分备份，即只备份某个或某些指定的数据库或某数据库中的某个或某些表。但要使用此功能，必须启用innodb_file_per_table选项，即每张表保存为一个独立的文件。同时，其也不支持–stream选项，即不支持将数据通过管道传输给其它程序进行处理。 此外，还原部分备份跟还原全部数据的备份也有所不同，即你不能通过简单地将prepared的部分备份使用–copy-back选项直接复制回数据目录，而是要通过导入表的方向来实现还原。当然，有些情况下，部分备份也可以直接通过–copy-back进行还原，但这种方式还原而来的数据多数会产生数据不一致的问题，因此，无论如何不推荐使用这种方式。 (1)创建部分备份 创建部分备份的方式有三种：正则表达式(–include), 枚举表文件(–tables-file)和列出要备份的数据库(–databases)。 (a)使用–include使用–include时，要求为其指定要备份的表的完整名称，即形如databasename.tablename，如：1innobackupex --include=&apos;^mageedu[.]tb1&apos; /path/to/backup (b)使用–tables-file此选项的参数需要是一个文件名，此文件中每行包含一个要备份的表的完整名称；如：12echo -e &apos;mageedu.tb1\nmageedu.tb2&apos; &gt; /tmp/tables.txtinnobackupex --tables-file=/tmp/tables.txt /path/to/backup (c)使用–databases此选项接受的参数为数据名，如果要指定多个数据库，彼此间需要以空格隔开；同时，在指定某数据库时，也可以只指定其中的某张表。此外，此选项也可以接受一个文件为参数，文件中每一行为一个要备份的对象。如：1innobackupex --databases=&apos;mageedu.tb1 testdb&quot; /path/to/backup (2)整理(preparing)部分备份 prepare部分备份的过程类似于导出表的过程，要使用–export选项进行：1innobackupex --apply-log --export /pat/to/partial/backup 此命令执行过程中，innobackupex会调用xtrabackup命令从数据字典中移除缺失的表，因此，会显示出许多关于“表不存在”类的警告信息。同时，也会显示出为备份文件中存在的表创建.exp文件的相关信息。 (3)还原部分备份 还原部分备份的过程跟导入表的过程相同。当然，也可以通过直接复制prepared状态的备份直接至数据目录中实现还原，不要此时要求数据目录处于一致状态。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis4.0配置文件介绍]]></title>
      <url>%2F2017%2F08%2F01%2Fredis4-0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程1daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定1pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字1port 6379 绑定的主机地址1bind 127.0.0.1 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能1timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null1logfile stdout 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： 123save 900 1save 300 10save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大1rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb1dbfilename dump.rdb 指定本地数据库存放目录1dir ./ 设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务设置了密码保护时，slave服务连接master的密码1masterauth &lt;master-password&gt; 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no1appendonly no 指定更新日志文件名，默认为appendonly.aof1appendfilename appendonly.aof 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）1appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中1vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享1vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为01vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值1vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。1vm-pages 134217728 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为41vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）1activerehashing yes 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件1include /path/to/local.conf]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack学习记录]]></title>
      <url>%2F2017%2F05%2F09%2FSaltStack%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[SaltStack 介绍salt是一个新的基础平台管理工具, 只需要花费数分钟即可运行起来, 扩展性足以支撑管理上万台服务器, 数秒钟即可完成数据传递。 经常被描述为Func加强版+Puppet精简版。 SaltStack采用C/S架构。简单的说: salt是一种全新的基础设施管理方式, 部署轻松, 在几分钟内可运行起来, 扩展性好。很容易管理上万台服务器, 速度快, 服务器之间秒级通信。 salt底层采用动态的连接总线, 使其可以用于编配, 远程执行, 配置管理等等。最为重要的一点, salt是开源的。 而且是python实现的自动化运维工具, 这意味着我们可以对其进行一些改动, 在其基础之上加上我们想要的功能, 对其进行二次开发。 环境介绍系统Centos7.2 x64两台, 一台为master,另一台为minion。 SaltStack安装两台安装epel1[root@localhost ~]# rpm -Uvh http://ftp.linux.ncsu.edu/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm 在master安装1[root@localhost ~]# yum -y install salt-master 在minion上运行1[root@localhost ~]# yum -y install salt-minion SAltStack配置修改master配置文件，并启动服务1234[root@localhost ~]# vim /etc/salt/master修改interface: 192.168.1.226 #master ip地址[root@localhost ~]# systemctl start salt-master 修改被管理端(minion)，并启动服务1234[root@localhost ~]# vim /etc/salt/minion修改master： 192.168.1.226[root@localhost ~]# systemctl start salt-minion master接受minion的托管请求，在master上操作1234567891011121314151617181920[root@localhost ~]# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:192.168.1.136Rejected Keys:[root@localhost ~]# salt-key -a 192.168.1.136The following keys are going to be accepted:Unaccepted Keys:192.168.1.136Proceed? [n/Y] yKey for minion 192.168.1.136 accepted.[root@localhost ~]# salt-key -LAccepted Keys:192.168.1.136Denied Keys:Unaccepted Keys:Rejected Keys: SAltStack操作基本操作命令通用格式1格式: 命令 对象 执行模块 参数salt ‘*’ cmd.run “ping -c 4 www.baidu.com&quot; 举个例子123456789[root@localhost ~]# salt &apos;*&apos; cmd.run &apos;uptime&apos;192.168.1.136: 21:14:44 up 1 day, 2:29, 3 users, load average: 0.10, 0.18, 0.13[root@localhost ~]# salt &apos;*&apos; cmd.run &apos;date&apos;192.168.1.136: Fri May 5 21:14:51 CST 2017[root@object1 ~]# salt &apos;*&apos; disk.usage 默认情况下master和minion之间使用以下端口进行通信:4505(publish_port)：salt的消息发布系统4506(ret_port)：salt客户端与服务端通信的端口cmd.run 为模块,又称之为超级命令. 可以执行Linux中的任何命令 Salt StatesSLS(代表Salt State文件)是Salt State系统的核心。SLS描述了系统的目标状态, 由格式简单的数据构成。 这经常被称作配置管理。 默认的数据 - YAML12]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记录redis的RDB、AOF持久化]]></title>
      <url>%2F2017%2F05%2F08%2F%E8%AE%B0%E5%BD%95redis%E7%9A%84RDB%E3%80%81AOF%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[Redis是个支持持久化的内存数据库，redis需要经常将内存中的数据同步到磁盘来保证持久化。 快照（Snapshotting）默认持久化方式配置1234snapshotting： save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒内如果超过10个key被修改，则发起快照保存save 60 10000 工作原理 Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）； 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件； 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。 优点 RDB是个非常紧凑的文件，保存了redis在某个时间点上的数据集，使得我们可以通过定时备份RDB文件来实现Redis数据库备份和灾难恢复，也可以将其传送到其他的数据中心用于保存。 RDB可以最大化redis的性能，执行RDB持久化时只需要fork一个子进程，并由子进程进行持久化工作，父进程不需要处理任何磁盘I/O操作。 RDB在恢复大数据集时比AOF要快，启动效率要高许多。 RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。 缺点 每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步增数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io操作，可能会严重影响性能。 快照方式是在一定间隔时间做一次的，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改，有一些数据丢失的风险。 client的save通知redis做一次快照持久化不推荐。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有client的请求，这种方式会阻塞所有client请求，所以不推荐使用。 日志追加方式（append-only file）方式配置12345aof：appendonly yes #启动aof持久化方式有三种修改方式#appendfsync always #收到写命令就立即写入到硬盘，效率最慢，但是保证完全持久化#appendfsync everysec #每秒种就写入一次硬盘，在性能和持久化方面做了折中#appendfsync no #完全依赖操作系统，性能最好，但是持久化没保证，不知道何时持久化 工作原理 redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 优点 该机制可以带来更高的数据安全性，即数据持久性。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，也可以通过该文件完成数据的重建。 缺点 对于相同数量的数据集而言，AOF文件通常要大于RDB文件，持久化文件会变的越来越大。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7用DevStack安装OpenStack]]></title>
      <url>%2F2017%2F05%2F05%2FCentOS-7%E7%94%A8DevStack%E5%AE%89%E8%A3%85OpenStack%2F</url>
      <content type="text"><![CDATA[准备阶段OpenStack源码1https://github.com/openstack DevStack源码1https://git.openstack.org/cgit/openstack-dev/devstack 设置aliyun的base源12[root@compute ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo[root@compute ~]# yum makecache DevStack和OpenStack源码可以替换为TryStack镜像1234# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git pip源地址可以换为国内的豆瓣源12345[root@compute ~]# mkdir /root/.pip[root@compute ~]# cat /root/.pip/pip.conf[global]index-url = http://pypi.douban.com/simple/trusted-host = pypi.douban.com 安装阶段下载DevStack1git clone http://git.trystack.cn/openstack-dev/devstack.git -b stable/ocata 创建stack用户123456[root@controller home]# mkdir -p /home/stack/logs[root@controller home]# cd devstack/tools/[root@controller home]# sudo ./create-stack-user.sh[root@controller home]# sudo passwd stack[root@controller home]# sudo chown –R stack:stack /home/devstack[root@controller home]# sudo chown –R stack:stack /home/stack 授权stack用户123[root@controller ~]# vim /etc/sudoers第98行，添加1行stack ALL=(ALL:ALL) ALL 创建local.conf文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@controller ~]# cat /home/devstack/local.conf [[local|localrc]]# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git#OFFLINE=TrueRECLONE=True# Define images to be automatically downloaded during the DevStack built process.DOWNLOAD_DEFAULT_IMAGES=FalseIMAGE_URLS=&quot;http://images.trystack.cn/cirros/cirros-0.3.4-x86_64-disk.img&quot;HOST_IP=192.168.1.225# CredentialsDATABASE_PASSWORD=passADMIN_PASSWORD=passSERVICE_PASSWORD=passSERVICE_TOKEN=passRABBIT_PASSWORD=passHORIZON_BRANCH=stable/ocataKEYSTONE_BRANCH=stable/ocataNOVA_BRANCH=stable/ocataNEUTRON_BRANCH=stable/ocataGLANCE_BRANCH=stable/ocataCINDER_BRANCH=stable/ocata#keystoneKEYSTONE_TOKEN_FORMAT=UUID##HeatHEAT_BRANCH=stable/ocataenable_service h-eng h-api h-api-cfn h-api-cw## SwiftSWIFT_BRANCH=stable/ocataENABLED_SERVICES+=,s-proxy,s-object,s-container,s-accountSWIFT_REPLICAS=1SWIFT_HASH=011688b44136573e209e# Enabling Neutron (network) Servicedisable_service n-netenable_service q-svcenable_service q-agtenable_service q-dhcpenable_service q-l3enable_service q-metaenable_service q-meteringenable_service neutron## Neutron optionsQ_USE_SECGROUP=TrueFLOATING_RANGE=&quot;192.168.1.0/24&quot;FIXED_RANGE=&quot;10.0.0.0/24&quot;NETWORK_GATEWAY=&quot;10.0.0.2&quot;Q_FLOATING_ALLOCATION_POOL=start=192.168.1.150,end=192.168.1.180PUBLIC_NETWORK_GATEWAY=&quot;192.168.1.200&quot;Q_L3_ENABLED=TruePUBLIC_INTERFACE=eth0Q_USE_PROVIDERNET_FOR_PUBLIC=TrueOVS_PHYSICAL_BRIDGE=br-exPUBLIC_BRIDGE=br-exOVS_BRIDGE_MAPPINGS=public:br-ex# #VLAN configuration.Q_PLUGIN=ml2ENABLE_TENANT_VLANS=True# LoggingLOGFILE=/home/stack/logs/stack.sh.logVERBOSE=TrueLOG_COLOR=TrueSCREEN_LOGDIR=/home/stack/logs 以stack用户身份运行脚本安装123[root@controller ~]# su stack[root@controller ~]# cd /home/devstack/[root@controller devstack]# ./stack.sh]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7 安装KVM虚拟机]]></title>
      <url>%2F2017%2F05%2F04%2FCentOS-7-%E5%AE%89%E8%A3%85KVM%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
      <content type="text"><![CDATA[kvm相关安装包及其作用qemu-kvm 主要的KVM程序包python-virtinst 创建虚拟机所需要的命令行工具和程序库virt-manager GUI虚拟机管理工具virt-top 虚拟机统计命令virt-viewer GUI连接程序，连接到已配置好的虚拟机libvirt C语言工具包，提供libvirt服务libvirt-client 为虚拟客户机提供的C语言工具包virt-install 基于libvirt服务的虚拟机创建命令bridge-utils 创建和管理桥接设备的工具 验证CPU是否支持KVM；如果结果中有vmx（Intel）或svm(AMD)字样，就说明CPU的支持的。1[root@object1 ~]# egrep &apos;(vmx|svm)&apos; /proc/cpuinfo 安装KVM及其依赖项1[root@object1 ~]# yum install qemu-kvm virt-install bridge-utils libvirt virt-install virt-manager -y 验证安装结果123[root@object1 ~]# lsmod | grep kvmkvm_intel 162153 0 kvm 525409 1 kvm_intel 开启kvm服务，并且设置其开机自动启动12[root@object1 ~]# systemctl start libvirtd[root@object1 ~]# systemctl enable libvirtd 配置网桥模式1234567891011121314151617181920212223242526272829303132333435363738394041//创建 ifcfg-br0 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 BOOTPROTO=&quot;static&quot;DEVICE=&quot;br0&quot;NAME=&quot;br0&quot;TYPE=&quot;Bridge&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.1.226&quot;NETMASK=&quot;255.255.255.0&quot;GATEWAY=&quot;192.168.1.200&quot;DNS1=&quot;114.114.114.114&quot;DNS2=&quot;8.8.8.8&quot;//修改ifcfg-eno16777736 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eno16777736 #TYPE=&quot;Ethernet&quot;#BOOTPROTO=&quot;static&quot;#DEFROUTE=&quot;yes&quot;#PEERDNS=&quot;yes&quot;#PEERROUTES=&quot;yes&quot;#IPV4_FAILURE_FATAL=&quot;no&quot;#IPV6INIT=&quot;yes&quot;#IPV6_AUTOCONF=&quot;yes&quot;#IPV6_DEFROUTE=&quot;yes&quot;#IPV6_PEERDNS=&quot;yes&quot;#IPV6_PEERROUTES=&quot;yes&quot;#IPV6_FAILURE_FATAL=&quot;no&quot;#NAME=&quot;eno16777736&quot;#UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;#DEVICE=&quot;eno16777736&quot;#ONBOOT=&quot;yes&quot;#IPADDR=192.168.1.226#NETMASK=255.255.255.0#GATEWAY=192.168.1.200#PEERDNS=&quot;yes&quot;#DNS1=8.8.8.8NAME=&quot;eno16777736&quot;UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;DEVICE=&quot;eno16777736&quot;BRIDGE=&quot;br0&quot;ONBOOT=&quot;yes&quot; 重启网络服务12345[root@object1 ~]# systemctl restart network[root@object1 ~]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000c29e16c76 no eno16777736virbr0 8000.000000000000 yes 安装虚拟机//下载cirros linux，下载地址：http://download.cirros-cloud.net/1[root@object1 ~]# virt-install -n test001 -r 2048 --disk /home/test.img,format=qcow2,size=1 --network bridge=br0 --os-type=linux --os-variant=rhel7.2 --cdrom /root/cirros-0.3.5-x86_64-disk.img --vnc --vncport=5900 --vnclisten=0.0.0.0 使用VNC Viewer连接该虚拟机官网下载：https://www.realvnc.com/download/vnc/ //通过图形界面操作 安装X(X Window System)1[root@object1 ~]# yum groupinstall &quot;X Window System&quot; -y 安装GNOME(GNOME Desktop)1[root@object1 ~]# yum groupinstall &quot;GNOME Desktop&quot; -y 使用virt-manager管理kvm//本地需要安装xmanager和xshell工具 ，并使用xshell建立连接时勾选x11转移。1[root@object1 ~]# virt-manager]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搭建FastDFS分布式文件系统]]></title>
      <url>%2F2017%2F05%2F03%2F%E6%90%AD%E5%BB%BAFastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[FastDFS介绍FastDFS是一款类Google FS的开源分布式文件系统，它用纯C语言实现，支持Linux、FreeBSD、AIX等UNIX系统。它只能通过专有API对文件进行存取访问，不支持POSIX接口方式，不能mount使用。准确地讲，Google FS以及FastDFS、mogileFS、HDFS、TFS等类Google FS都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。 FastDFS是一个开源的，高性能的的分布式文件系统，他主要的功能包括：文件存储，同步和访问，设计基于高可用和负载均衡，fastfd非常适用于基于文件服务的站点，例如图片分享和视频分享网站。FastDFS有两个角色：跟踪服务和存储服务，跟踪服务控制，调度文件以负载均衡的方式访问；存储服务包括：文件存储，文件同步，提供文件访问接口，同时以key value的方式管理文件的元数据。跟踪和存储服务可以由1台或者多台服务器组成，同时可以动态的添加，删除跟踪和存储服务而不会对在线的服务产生影响，在集群中，tracker服务是对等的。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 FastDFS架构客户端和Storage server主动连接Tracker server。Storage server主动向Tracker server报告其状态信息，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。Storage server会连接集群中所有的Tracker server，向他们报告自己的状态。Storage server启动一个单独的线程来完成对一台Tracker server的连接和定时报告。需要说明的是，一个组包含的Storage server不是通过配置文件设定的，而是通过Tracker server获取到的。不同组的Storage server之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步。Storage server采用binlog文件记录文件上传、删除等更新操作。binlog中只记录文件名，不记录文件内容。文件同步只在同组内的Storage server之间进行，采用push方式，即源头服务器同步给目标服务器。只有源头数据才需要同步，备份数据并不需要再次同步，否则就构成环路了。有个例外，就是新增加一台Storage server时，由已有的一台Storage server将已有的所有数据（包括源头数据和备份数据）同步给该新增服务器。Storage server中由专门的线程根据binlog进行文件同步。为了最大程度地避免相互影响以及出于系统简洁性考虑，Storage server对组内除自己以外的每台服务器都会启动一个线程来进行文件同步。文件同步采用增量同步方式，系统记录已同步的位置（binlog文件偏移量）到标识文件中。标识文件名格式：{dest storage IP}_{port}.mark，例如：192.168.1.14_23000.mark。 FastDFS文件上传下载交互过程 文件下载流程 Client询问Tracker server可以下载指定文件的Storage server，参数为文件ID（包含组名和文件名）； Tracker server返回一台可用的Storage server； Client直接和该Storage server建立连接，完成文件下载。文件上传流程 Client询问Tracker server上传到的Storage server； Tracker server返回一台可用的Storage server，返回的数据为该Storage server的IP地址和端口； Client直接和该Storage server建立连接，进行文件上传，Storage server返回新生成的文件ID，文件上传结束。 FastDFS安装系统环境1CentOS Linux release 7.2.1511 (Core) 下载并安装FastDFS依赖包libfastcommon12345[root@object1 ~]# wget https://codeload.github.com/happyfish100/libfastcommon/zip/master[root@object1 ~]# unzip master[root@object1 ~]# cd libfastcommon-master/[root@object1 libfastcommon-master]# ./make.sh[root@object1 libfastcommon-master]# ./make.sh install 下载并安装FastDFS1234[root@object1 ~]# wget https://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Server%20Source%20Code/FastDFS%20Server%20with%20PHP%20Extension%20Source%20Code%20V5.08/FastDFS_v5.08.tar.gz[root@object1 ~]# tar zxvf FastDFS_v5.08.tar.gz [root@object1 ~]# cd FastDFS[root@object1 FastDFS]# ./make.sh &amp;&amp; ./make.sh install 默认脚本目录1[root@object1 ~]# ll /etc/init.d/ | grep fdfs 样例配置文件1[root@object1 ~]# ll /etc/fdfs/ 注意：虽然FastDFS区分tracker和storage服务器，但是安装的软件及步骤均相同，只是不同的配置文件而已，因此以上安装适用tracker server和storage server 配置跟踪服务器（tracker server）拷贝tracker server和client端样例配置文件并重命名12[root@object1 ~]# cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf[root@object1 ~]# cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 修改client.conf12第14行 tracker_server=192.168.1.226:22122 启动tracker server12[root@object1 ~]# /etc/init.d/fdfs_trackerd start[root@object1 ~]# ss -tunlp | grep 22122 配置存储服务器（storage server）拷贝storage server样例配置文件并重命名1[root@object1 ~]# cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 修改storage.conf12第118行tracker_server=192.168.1.226:22122 启动storage server（启动storage server的前提是tracker server必须事先已启动）12[root@object1 ~]# /etc/init.d/fdfs_storaged start[root@object1 ~]# ss -tunlp | grep 23000 文件上传测试12[root@object1 ~]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/test.jpg group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg 存储服务器（storage server）安装并配置nginx下载并安装fastdfs-nginx-module模块注：FastDFS通过Tracker服务器,将文件放在Storage服务器存储，但是同组存储服务器之间需要进入文件复制，有同步延迟的问题。假设Tracker服务器将文件上传到了192.168.1.226，上传成功后文件ID已经返回给客户端。此时FastDFS存储集群机制会将这个文件同步到同组存储192.168.1.227，在文件还没有复制完成的情况下，客户端如果用这个文件ID在192.168.1.227上取文件,就会出现文件无法访问的错误。而fastdfs-nginx-module可以重定向文件连接到源服务器取文件,避免客户端由于复制延迟导致的文件无法访问错误。 12345678910[root@object1 ~]# wget http://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Nginx%20Module%20Source%20Code/fastdfs-nginx-module_v1.16.tar.gz[root@object1 ~]# tar zxvf fastdfs-nginx-module_v1.16.tar.gz [root@object1 ~]# cd fastdfs-nginx-module/src/[root@object1 src]# vim config 编辑config文件，执行如下命令进行批量替换并保存退出:%s+/usr/local/+/usr/+g[root@object1 src]# cp mod_fastdfs.conf /etc/fdfs/修改mod_fastdfs.conf第40行tracker_server=192.168.1.226:22122 安装nginx依赖库1[root@object1 ~]# yum install -y pcre-devel zlib-devel nginx 安装nginx12345[root@object1 ~]# wget http://nginx.org/download/nginx-1.13.0.tar.gz[root@object1 ~]# tar zxvf nginx-1.13.0.tar.gz[root@object1 ~]# cd nginx-1.13.0[root@object1 nginx-1.13.0]# ./configure --prefix=/usr/local/nginx --add-module=/root/fastdfs-nginx-module/src/[root@object1 nginx-1.13.0]# make &amp;&amp; make install 拷贝FastDFS中的部分配置文件到/etc/fdfs目录中12[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/http.conf /etc/fdfs/[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/mime.types /etc/fdfs/ 配置nginx123456789[root@object1 ~]# vim /usr/local/nginx/conf/nginx.conf修改1行user root; #解决下载操作时报404的问题修改36行listen 8888; #storage.conf配置文件一致添加location ~/group[0-9]/ &#123; ngx_fastdfs_module; &#125; 拷贝nginx服务到/etc/init.d/目录下并启动123[root@object1 ~]# cp /usr/local/nginx/sbin/nginx /etc/init.d/[root@object1 ~]# /etc/init.d/nginx[root@object1 ~]# ss -tunlp | grep 8888 通过浏览器访问之前已经上传的文件123456789101112http://192.168.1.226:8888/group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg访问出现400 Bad Request查看日志[root@object1 ~]# vim /usr/local/nginx/logs/error.log 报错信息[2017-05-03 17:00:38] ERROR - file: ../common/fdfs_global.c, line: 52, the format of filename &quot;group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg&quot; is invalid解决方法：[root@object1 ~]# vim /etc/fdfs/mod_fastdfs.conf修改53行url_have_group_name = true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记录MongoDB3.4分片的一些配置]]></title>
      <url>%2F2017%2F05%2F03%2F%E8%AE%B0%E5%BD%95MongoDB3.4%E5%88%86%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[MongoDB介绍MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB特点 MongoDB的提供了一个面向文档存储，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Ning”,Address=”Beijing”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装yum安装官网：https://docs.mongodb.com/master/tutorial/install-mongodb-on-red-hat/ 123456789[root@object1 ~]# vim /etc/yum.repos.d/mongodb-org-3.4.repo[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc[root@object1 ~]#sudo yum install -y mongodb-org 下载官网：https://www.mongodb.com/download-center?jmp=nav#community 123456[root@object1 ~]#curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.4.tgz[root@object1 ~]#tar -zxvf mongodb-linux-x86_64-rhel70-3.4.4.tgz [root@object1 ~]# mv mongodb-linux-x86_64-rhel70-3.4.4 /usr/local/mongodb#把安装目录添加到系统环境中export PATH=/usr/local/mongodb/bin:$PATH 配置文件官网：https://docs.mongodb.com/manual/administration/configuration/ 12345678910111213141516171819202122232425262728#使用YAML配置也可以使用原ini配置#基本设置processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: true#安全security: authorization: enablednet: bindIp: 192.168.1.226 port: 27017#副本集replication: replSetName: set0#副本集安全security: keyFile: /home/mongodb/keyfile 分片配置分片服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truenet: bindIp: 192.168.1.226 port: 27017sharding: clusterRole: shardsvrreplication: replSetName: shardA 配置服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truesharding: clusterRole: configsvrnet: bindIp: 192.168.1.226 port: 27001replication: replSetName: csRS 路由服务器 1234567891011121314151617processManagement: fork: true pidFilePath: /home/mongodb/mongos.pid#storage:# dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongos.log&quot; logAppend: true#storage:# journal:# enabled: truenet: bindIp: 192.168.1.226 port: 28001sharding: configDB: csRS/192.168.1.226:27001,192.168.1.226:27002,192.168.1.226:27003 启动mongodb123[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 分片服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 配置服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongos -f 路由服务器配置文件 初始化mongodb分片服务器 12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27017&gt;use admin&gt;config = &#123;_id:&quot;shardA&quot;,members:[&#123;_id:0, host:&quot;192.168.1.226:27017&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27018&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27019&quot;&#125;]&#125;&gt;rs.initiate(config) 配置服务器12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27001&gt;use admin&gt;config = &#123;_id:&quot;csRS&quot;,configsvr:true,members:[&#123;_id:0, host:&quot;192.168.1.226:27001&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27002&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27003&quot;&#125;]&#125;&gt;rs.initiate(config) 启动分片123[root@object1 mongodb]# mongo --port 28001mongos&gt; use adminmongos&gt; db.runCommand( &#123; addShard: &quot;shardA/192.168.1.226:27017,192.168.1.226:27018,192.168.1.226:27019&quot;&#125; )]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7 LDAP统一认证部署]]></title>
      <url>%2F2017%2F05%2F02%2FCentOS7-LDAP%E7%BB%9F%E4%B8%80%E8%AE%A4%E8%AF%81%E9%83%A8%E7%BD%B2%2F</url>
      <content type="text"><![CDATA[LDAP介绍LDAP是轻量目录访问协议，英文全称是Lightweight Directory Access Protocol，简称为LDAP。它是基于X.500标准的，但是简单多了并且可以根据需要定制。与X.500不同，LDAP支持TCP/IP。LDAP的核心规范在RFC中都有定义，所有与LDAP相关的RFC都可以在LDAPman RFC网页中找到。 使用目的使用LDAP对运维相关用户名密码做统一管理。可以实现一个帐号登录多个不同系统。 LDAP部署LDAP Server端安装1[root@object1 ~]# yum install -y openldap openldap-clients openldap-servers migrationtools LDAP 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#配置 OpenLDAP Server[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;2\&#125;hdb.ldif dn: olcDatabase=&#123;2&#125;hdb修改两行olcSuffix: dc=hyman,dc=comolcRootDN: cn=Manager,dc=hyman,dc=com新增一行olcRootPW: 123456#配置 Monitoring Database[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;1\&#125;monitor.ldifdn: olcDatabase=&#123;1&#125;monitor修改一行olcAccess: &#123;0&#125;to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=extern al,cn=auth&quot; read by dn.base=&quot;cn=Manager,dc=hyman,dc=com&quot; read by * none#初始化 LDAP database[root@object1 ~]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG[root@object1 ~]# chown -R ldap.ldap /var/lib/ldap/#测试 configuration[root@object1 ~]# slaptest -u#启动服务并开机自启[root@object1 ~]# systemctl start slapd[root@object1 ~]# systemctl enable slapd#查看状态[root@object1 ~]# netstat -lt | grep ldap#将所有的配置LDAP server, 添加到LDAP schemas中[root@object1 ~]# cd /etc/openldap/schema/ ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f cosine.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f nis.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f collective.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f corba.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f core.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f duaconf.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f dyngroup.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f inetorgperson.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f java.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f ppolicy.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f pmi.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f openldap.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f misc.ldif#使用Migration Tools 创建 LDAP DIT[root@object1 schema]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_common.ph修改61行$NAMINGCONTEXT&#123;&apos;group&apos;&#125; = &quot;ou=Groups&quot;;修改71行$DEFAULT_MAIL_DOMAIN = &quot;hyman.com&quot;;修改74行$DEFAULT_BASE = &quot;dc=hyman,dc=com&quot;;修改90行$EXTENDED_SCHEMA = 1;#创建 base.ldif[root@object1 migrationtools]# ./migrate_base.pl &gt; /root/base.ldif#导入LDAP database[root@object1 migrationtools]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f /root/base.ldif#创建用户和用户组，并将其从本地数据库迁移到LDAP数据库[root@object1 migrationtools]# mkdir /home/guests[root@object1 migrationtools]# useradd -d /home/guests/ldapuser1 ldapuser1[root@object1 migrationtools]# useradd -d /home/guests/ldapuser2 ldapuser2[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser1[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser2#过滤掉这些用户和组和密码从/etc/shadow到不同的文件[root@object1 ~]# getent passwd | tail -n 5 &gt; /root/users[root@object1 ~]# getent shadow | tail -n 5 &gt; /root/shadow[root@object1 ~]# getent group | tail -n 5 &gt; /root/groups#创建这些用户使用migrationtools[root@object1 ~]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_passwd.pl 修改188行把 /etc/shadow 替换为 /root/shadow[root@object1 migrationtools]# ./migrate_passwd.pl /root/users &gt; users.ldif[root@object1 migrationtools]# ./migrate_passwd.pl /root/groups &gt; groups.ldif#上传这些用户和组LDAP数据库[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f users.ldif[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f groups.ldif#所有记录搜索LDAP DIT[root@object1 ~]# ldapsearch -x -b &quot;dc=hyman,dc=com&quot; -H ldap://127.0.0.1 LDAP 客户端验证1234[root@block1 ~]# yum install -y nss-pam*[root@block1 ~]# authconfig-tui 选择第二个Use LDAP[root@block1 ~]# su ldaduser1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7通过yum安装ansible]]></title>
      <url>%2F2017%2F04%2F27%2FCentOS-7%E9%80%9A%E8%BF%87yum%E5%AE%89%E8%A3%85ansible%2F</url>
      <content type="text"><![CDATA[一、ansible介绍1、ansible 简介Ansible官方的 title 是“Ansible is Simple IT Automation”——简单的自动化IT工具。Ansible是一款为类Unix系统开发的自由开源的配置和自动化工具。它用Python写成，类似于Chef和Puppet，但是有一个不同的优点是我们不需要在节点中安装任何客户端。它使用SSH来和节点进行通信。 2、ansible 特点（1） No agents：不需要在被管控主机上安装任意客户端；（2） No server：无服务器端，使用时直接运行命令即可；（3） Modules in any languages：基于模块工作，可使用任意语言开发模块（4） YAML，not code：使用yaml语言定制剧本playbook；（5） SSH by default：基于SSH工作；（6） Strong multi-tier solution：可实现多级指挥； 二、Ansible安装使用1、 设置EPEL仓库1[root@object1 ~]# rpm -iUvh http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm 2、使用yum安装Ansible1[root@object1 ~]# yum install -y ansible 3、设置用于节点鉴权的SSH密钥1234#在Ansible服务端生成密钥[root@object1 ~]# ssh-keygen #使用ssh-copy-id命令来复制Ansible公钥到节点中[root@object1 ~]# ssh-copy-id -i root@192.168.1.215 4、为Ansible定义节点的清单1234[root@object1 ~]# cat /etc/ansible/hosts[test]192.168.1.226192.168.1.215 5、尝试在Ansible服务端运行命令123456789101112131415161718192021222324252627282930313233343536#使用ping检查ansible节点的连通性[root@object1 ~]# ansible -m ping &apos;test&apos;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;#检查Ansible节点的运行时间（uptime）[root@object1 ~]# ansible -m command -a &quot;uptime&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 07:11:16 up 42 days, 13:43, 1 user, load average: 0.00, 0.00, 0.00#检查节点的内核版本[root@object1 ~]# ansible -m command -a &quot;uname -r&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt;2.6.32-573.3.1.el6.x86_64#给节点增加用户[root@object1 ~]# ansible -m command -a &quot;useradd test&quot; &quot;test&quot;192.168.1.226 | SUCCESS | rc=0 &gt;&gt;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 6、模块的使用查看各模块的使用方法12345ansible-doc [options] [modules] ：Show Ansible module documentation -l 列出所有的ansible模块 -s 列出该模块的相关指令可以直接使用 ansible-doc 模块名 来查看模块的使用，如# ansible-doc htpasswd 三、playbook的使用YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。 YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。 1、playbook使用1ansible-playbook test.yaml 下面就是一个只包含了一个play的playbook，在写playbook的时候，一定要记住在 hosts，yum（模块儿名）等后带空格，否则会报错。 12345678910111213141516171819202122#这个是你选择的主机- hosts: webservers#这个是变量 vars: http_port: 80 max_clients: 200#远端的执行权限 remote_user: root tasks:#利用yum模块来操作 - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf #触发重启服务器 notify: - restart apache - name: ensure apache is running service: name=httpd state=started #这里的restart apache 和上面的触发是配对的。这就是handlers的作用。相当于tag handlers: - name: restart apache service: name=httpd state=restarted 2、playbook案例corosync.yaml 12345678910111213141516171819202122232425262728293031323334353637- hosts: hanodes #指定要执行任务的主机，可由冒号分隔主机组 remote_user: root #指定远程主机上执行任务的用户 vars: #定义如下2个变量 crmsh: crmsh-1.2.6.4.el6.x86_64.rpm pssh: pssh-2.3.1-2.el6.x86_64.rpm tasks: #指定需执行的任务列表，每个task都有其name和使用的模块及参数 - name: test connection ping: #ping模块无需执行参数 remote_user: jason #在task中指定远程主机上执行任务的用户 sudo: yes #使用sudo在远程主机上执行任务 - name: corosync installing yum: name=corosync state=present - name: pacemaker installing #定义一个软件安装任务 yum: name=pacemaker state=present #使用yum安装，并配置需安装的软件名（name），及状态（state） - name: crmsh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; crmsh &#125;&#125; dest=/tmp/&#123;&#123; crmsh &#125;&#125; - name: pssh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; pssh &#125;&#125; dest=/tmp/&#123;&#123; pssh &#125;&#125; - name: crmsh installing command: yum -y reinstall /tmp/&#123;&#123; crmsh &#125;&#125; /tmp/&#123;&#123; pssh &#125;&#125; - name: authkey configure file copy: src=/ansible/corosync/conf/authkey dest=/etc/corosync/authkey - name: authkey mode 400 #定义一个文件权限设置任务 file: path=/etc/corosync/authkey mode=400 notify: #定义一个通知，当此任务执行时，可以激发响应的handler - restart corosync - name: corosync.conf configure file copy: src=/ansible/corosync/conf/corosync.conf dest=/etc/corosync/corosync.conf tags: - conf notify: - restart corosync - name: ensure the corosync service startup on boot service: name=corosync state=started enabled=yes handlers: #定义当关注的资源发生变化时，需采取的操作 - name: restart corosync #定义一个服务重启任务 service: name=corosync state=restarted heartbeat.yaml 123456789101112131415161718- hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper、Dubbo-Admin管理平台的搭建]]></title>
      <url>%2F2017%2F04%2F26%2FZookeeper%E3%80%81Dubbo-Admin%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。 ZooKeeper官网为：http://zookeeper.apache.org/ Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容。 Dubbo官网为：http://dubbo.io/ 一、zookeeper安装与启动首先需要安装JdK，从Oracle的Java网站下载，安装很简单，就不再详述。zookeeper的下载地址 1http://www.apache.org/dyn/closer.cgi/zookeeper/ 下载后直接解压，不用安装 1[root@object1 home]# tar zxvf zookeeper-3.4.10.tar.gz 修改默认配置 1[root@object1 conf]# cp zoo_sample.cfg zoo.cfg 参数说明: tickTime：zookeeper中使用的基本时间单位, 毫秒值这个时间是作为Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：数据目录. 可以是任意目录，默认情况下，Zookeeper 将写数据 的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 至此, zookeeper的单机模式已经配置好了，启动ZooKeeper 1[root@object1 zookeeper-3.4.10]# sh bin/zkServer.sh start 二、Dubbo-admin管理平台的安装因为zookeeper只是一个黑框，我们无法看到是否存在了什么提供者或消费者，这时就要借助Dubbo-Admin管理平台来实时的查看，也可以通过这个平台来管理提者和消费者。制作了基于jdk1.8打包的dubbo-admin.war 下载地址 1http://download.csdn.net/detail/qq_30567735/9826361 dubbo源码 1https://github.com/alibaba/dubbo 下载好dubbo-admin.war后，我们就可以按常用的web部署方式进行部署即可，把war包放到tomcat的webapps目录下，启动tomcat，后再部署下相应的参数。 启动tomcat 1[root@object1 apache-tomcat-7.0.62]# sh bin/startup.sh 访问项目地址即可 1http: //ip地址:端口号/dubbo-admin-2.5.4/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL自带压力测试工具mysqlslap的使用方法]]></title>
      <url>%2F2017%2F04%2F26%2FMySQL%E8%87%AA%E5%B8%A6%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7mysqlslap%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[mysqlslap是从5.1.4版开始的一个MySQL官方提供的压力测试工具。通过模拟多个并发客户端访问MySQL来执行压力测试，并输出计时信息。并且能很好的对比多个存储引擎在相同环境下的并发压力性能差别。可以指定SQL语句。如果没有指定SQL语句，mysqlslap会自动生成查询schema的SELECT语句。 1、查看帮助信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126[root@object1 local]# mysqlslap --helpmysqlslap Ver 1.0 Distrib 5.7.18, for Linux (x86_64)Copyright (c) 2005, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Run a query multiple times against the server.Usage: mysqlslap [OPTIONS]Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf The following groups are read: mysqlslap clientThe following options may be given as the first argument:--print-defaults Print the program argument list and exit.--no-defaults Don&apos;t read default options from any option file, except for login file.--defaults-file=# Only read default options from the given file #.--defaults-extra-file=# Read this file after the global files are read.--defaults-group-suffix=# Also read groups with concat(group, suffix)--login-path=# Read this path from the login file. -?, --help Display this help and exit. -a, --auto-generate-sql 自动生成测试表和数据 Generate SQL where not supplied by file or command line. --auto-generate-sql-add-autoincrement 增加auto_increment一列 Add an AUTO_INCREMENT column to auto-generated tables. --auto-generate-sql-execute-number=# 自动生成的查询的个数 Set this number to generate a set number of queries to run. --auto-generate-sql-guid-primary 增加基于GUID的主键 Add GUID based primary keys to auto-generated tables. --auto-generate-sql-load-type=name 测试语句的类型。取值包括：read，key，write，update和mixed(默认) Specify test load type: mixed, update, write, key, or read; default is mixed. --auto-generate-sql-secondary-indexes=# 增加二级索引的个数，默认是0 Number of secondary indexes to add to auto-generated tables. --auto-generate-sql-unique-query-number=# 不同查询的数量，默认值是10 Number of unique queries to generate for automatic tests. --auto-generate-sql-unique-write-number=# 不同插入的数量，默认是100 Number of unique queries to generate for auto-generate-sql-write-number. --auto-generate-sql-write-number=# Number of row inserts to perform for each thread (default is 100). --commit=# 多少条DML后提交一次 Commit records every X number of statements. -C, --compress 如果服务器和客户端支持都压缩，则压缩信息传递 Use compression in server/client protocol. -c, --concurrency=name 模拟N个客户端并发执行select。可指定多个值，以逗号或者 --delimiter 参数指定的值做为分隔符 Number of clients to simulate for query to run. --create=name 指定用于创建表的.sql文件或者字串 File or string to use create tables. --create-schema=name 指定待测试的数据库名，MySQL中schema也就是database，默认是mysqlslap Schema to run tests in. --csv[=name] Generate CSV output to named file or to stdout if no file is named. -#, --debug[=#] This is a non-debug version. Catch this and exit. --debug-check This is a non-debug version. Catch this and exit. -T, --debug-info 打印内存和CPU的信息 This is a non-debug version. Catch this and exit. --default-auth=name Default authentication client-side plugin to use. -F, --delimiter=name 文件中的SQL语句使用分割符号 Delimiter to use in SQL statements supplied in file or command line. --detach=# 每执行完N个语句，先断开再重新打开连接 Detach (close and reopen) connections after X number of requests. --enable-cleartext-plugin Enable/disable the clear text authentication plugin. -e, --engine=name 创建测试表所使用的存储引擎，可指定多个 Storage engine to use for creating the table. -h, --host=name Connect to host. -i, --iterations=# 迭代执行的次数 Number of times to run the tests. --no-drop Do not drop the schema after the test. -x, --number-char-cols=name 自动生成的测试表中包含多少个字符类型的列，默认1 Number of VARCHAR columns to create in table if specifying --auto-generate-sql. -y, --number-int-cols=name 自动生成的测试表中包含多少个数字类型的列，默认1 Number of INT columns to create in table if specifying --auto-generate-sql. --number-of-queries=# 总的测试查询次数(并发客户数×每客户查询次数) Limit each client to this number of queries (this is not exact). --only-print 只输出模拟执行的结果，不实际执行Do not connect to the databases, but instead print out what would have been done. -p, --password[=name] Password to use when connecting to server. If password is not given it&apos;s asked from the tty. --plugin-dir=name Directory for client-side plugins. -P, --port=# Port number to use for connection. --post-query=name 测试完成以后执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute after tests have completed. --post-system=name 测试完成以后执行的系统语句 这个过程不影响时间计算system() string to execute after tests have completed. --pre-query=name 测试执行之前执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute before running tests. --pre-system=name 测试执行之前执行的系统语句 这个过程不影响时间计算system() string to execute before running tests. --protocol=name The protocol to use for connection (tcp, socket, pipe, memory). -q, --query=name 指定自定义.sql脚本执行测试。例如可以调用自定义的一个存储过程或者sql语句来执行测试Query to run or file containing query to run. --secure-auth Refuse client connecting to server if it uses old (pre-4.1.1) protocol. Deprecated. Always TRUE -s, --silent 不输出Run program in silent mode - no output. -S, --socket=name The socket file to use for connection. --sql-mode=name Specify sql-mode to run mysqlslap tool. --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) --ssl-verify-server-cert Deprecated. Use --ssl-mode=VERIFY_IDENTITY instead. --ssl-ca=name CA file in PEM format. --ssl-capath=name CA directory. --ssl-cert=name X509 cert in PEM format. --ssl-cipher=name SSL cipher to use. --ssl-key=name X509 key in PEM format. --ssl-crl=name Certificate revocation list. --ssl-crlpath=name Certificate revocation list path. --tls-version=name TLS version to use, permitted values are: TLSv1, TLSv1.1 -u, --user=name User for login if not current user. -v, --verbose 输出更多的信息More verbose output; you can use this multiple times to get even more verbose output. -V, --version Output version information and exit. 2、以自动生成测试表和数据的形式，分别模拟 50 和 100 个客户端并发连接处理 1000 个 query 的情况。 123456789101112131415[root@object1 local]# mysqlslap -uroot -p&apos;CAOcao123~!@&apos; -a --concurrency=50,100 --number-of-queries=1000 mysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Average number of seconds to run all queries: 0.605 seconds Minimum number of seconds to run all queries: 0.605 seconds Maximum number of seconds to run all queries: 0.605 seconds Number of clients running queries: 50 Average number of queries per client: 20Benchmark Average number of seconds to run all queries: 0.534 seconds Minimum number of seconds to run all queries: 0.534 seconds Maximum number of seconds to run all queries: 0.534 seconds Number of clients running queries: 100 Average number of queries per client: 10 3、增加 –debug-info 选项，可以输出内存和CPU信息。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7通过yum安装最新版本MySQL]]></title>
      <url>%2F2017%2F04%2F26%2FCentOS7%20yum%E5%AE%89%E8%A3%85MySQL%2F</url>
      <content type="text"><![CDATA[CentOS 7之后的版本yum的默认源中使用MariaDB替代原先MySQL，因此安装方式较为以往有一些改变： 卸载原来的MariaDB 1yum remove -y mariadb-config-3:10.1.17-1.el7.x86_64 下载mysql的源 1wget http://dev.mysql.com/get/mysql57-community-release-el7-7.noarch.rpm 安装yum库 1yum localinstall -y mysql57-community-release-el7-7.noarch.rpm 安装MySQL 1yum install -y mysql-community-server 启动MySQL服务 1systemctl start mysqld.service MySQL5.7加强了root用户的安全性，因此在第一次安装后会初始化一个随机密码，以下为查看初始随机密码的方式 1grep &apos;temporary password&apos; /var/log/mysqld.log 使用初始随机密码登录后MySQL会强制要求修改密码，否则无法正常使用，（密码必须包含小写、大写字母及特殊字符，当然也有其他方法不受此限制，再次不多做描述），修改方法如下： 123SET PASSWORD = PASSWORD(&apos;your new password&apos;);ALTER USER &apos;root&apos;@&apos;localhost&apos; PASSWORD EXPIRE NEVER;flush privileges; 然后退出后即可用新密码登录。 远程连接授权： 1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;your password&apos; WITH GRANT OPTION;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo+github+next搭建的blog]]></title>
      <url>%2F2017%2F01%2F13%2FHexo-github-next%E6%90%AD%E5%BB%BA%E7%9A%84blog%2F</url>
      <content type="text"><![CDATA[搭建环境：Windows 10 软件工具：git、node.js、hexo、Markdownpad2 一、环境搭建 安装git git官网(http://git-scm.com) 安装Node.js node.js官网(https://nodejs.org/en/) 二、安装和配置Hexo 执行cmd命令 npm install -g hexo-cli 本地创建Hexo文件夹，本目录下执行cmd命令 hexo init npm install 启动Hexo hexo server 更改hexo主题，在Hexo目录下载next主题 git clone https://github.com/iissnan/hexo-theme-next themes/next 修改Hexo配置文件_config.yml theme: next 重启Hexo，基本更改过来了，其他修改具体查看GITBUB 创建文章，执行cmd命令 hexo new 文章主题 执行命令后，在文件下的source_posts，自动生成以后缀为md的文件，修改md内容 生成html文件，执行cmd命令 hexo d -g 自动会生存静态文件在public文件夹下，把里面的文件全部上传至自己的github下即可]]></content>
    </entry>

    
  
  
</search>
