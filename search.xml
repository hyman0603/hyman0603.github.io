<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[记录redis的RDB、AOF持久化]]></title>
      <url>%2F2017%2F05%2F08%2F%E8%AE%B0%E5%BD%95redis%E7%9A%84RDB%E3%80%81AOF%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[Redis是个支持持久化的内存数据库，redis需要经常将内存中的数据同步到磁盘来保证持久化。 快照（Snapshotting）默认持久化方式配置1234snapshotting： save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒内如果超过10个key被修改，则发起快照保存save 60 10000 工作原理 Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）； 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件； 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。 优点 RDB是个非常紧凑的文件，保存了redis在某个时间点上的数据集，使得我们可以通过定时备份RDB文件来实现Redis数据库备份和灾难恢复，也可以将其传送到其他的数据中心用于保存。 RDB可以最大化redis的性能，执行RDB持久化时只需要fork一个子进程，并由子进程进行持久化工作，父进程不需要处理任何磁盘I/O操作。 RDB在恢复大数据集时比AOF要快，启动效率要高许多。 RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。 缺点 每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步增数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io操作，可能会严重影响性能。 快照方式是在一定间隔时间做一次的，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改，有一些数据丢失的风险。 client的save通知redis做一次快照持久化不推荐。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有client的请求，这种方式会阻塞所有client请求，所以不推荐使用。 日志追加方式（append-only file）方式配置12345aof：appendonly yes #启动aof持久化方式有三种修改方式#appendfsync always #收到写命令就立即写入到硬盘，效率最慢，但是保证完全持久化#appendfsync everysec #每秒种就写入一次硬盘，在性能和持久化方面做了折中#appendfsync no #完全依赖操作系统，性能最好，但是持久化没保证，不知道何时持久化 工作原理 redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 优点 该机制可以带来更高的数据安全性，即数据持久性。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，也可以通过该文件完成数据的重建。 缺点 对于相同数量的数据集而言，AOF文件通常要大于RDB文件，持久化文件会变的越来越大。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7用DevStack安装OpenStack]]></title>
      <url>%2F2017%2F05%2F05%2FCentOS-7%E7%94%A8DevStack%E5%AE%89%E8%A3%85OpenStack%2F</url>
      <content type="text"><![CDATA[准备阶段OpenStack源码1https://github.com/openstack DevStack源码1https://git.openstack.org/cgit/openstack-dev/devstack 设置aliyun的base源12[root@compute ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo[root@compute ~]# yum makecache DevStack和OpenStack源码可以替换为TryStack镜像1234# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git pip源地址可以换为国内的豆瓣源12345[root@compute ~]# mkdir /root/.pip[root@compute ~]# cat /root/.pip/pip.conf[global]index-url = http://pypi.douban.com/simple/trusted-host = pypi.douban.com 安装阶段下载DevStack1git clone http://git.trystack.cn/openstack-dev/devstack.git -b stable/ocata 创建stack用户123456[root@controller home]# mkdir -p /home/stack/logs[root@controller home]# cd devstack/tools/[root@controller home]# sudo ./create-stack-user.sh[root@controller home]# sudo passwd stack[root@controller home]# sudo chown –R stack:stack /home/devstack[root@controller home]# sudo chown –R stack:stack /home/stack 授权stack用户123[root@controller ~]# vim /etc/sudoers第98行，添加1行stack ALL=(ALL:ALL) ALL 创建local.conf文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@controller ~]# cat /home/devstack/local.conf [[local|localrc]]# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git#OFFLINE=TrueRECLONE=True# Define images to be automatically downloaded during the DevStack built process.DOWNLOAD_DEFAULT_IMAGES=FalseIMAGE_URLS=&quot;http://images.trystack.cn/cirros/cirros-0.3.4-x86_64-disk.img&quot;HOST_IP=192.168.1.225# CredentialsDATABASE_PASSWORD=passADMIN_PASSWORD=passSERVICE_PASSWORD=passSERVICE_TOKEN=passRABBIT_PASSWORD=passHORIZON_BRANCH=stable/ocataKEYSTONE_BRANCH=stable/ocataNOVA_BRANCH=stable/ocataNEUTRON_BRANCH=stable/ocataGLANCE_BRANCH=stable/ocataCINDER_BRANCH=stable/ocata#keystoneKEYSTONE_TOKEN_FORMAT=UUID##HeatHEAT_BRANCH=stable/ocataenable_service h-eng h-api h-api-cfn h-api-cw## SwiftSWIFT_BRANCH=stable/ocataENABLED_SERVICES+=,s-proxy,s-object,s-container,s-accountSWIFT_REPLICAS=1SWIFT_HASH=011688b44136573e209e# Enabling Neutron (network) Servicedisable_service n-netenable_service q-svcenable_service q-agtenable_service q-dhcpenable_service q-l3enable_service q-metaenable_service q-meteringenable_service neutron## Neutron optionsQ_USE_SECGROUP=TrueFLOATING_RANGE=&quot;192.168.1.0/24&quot;FIXED_RANGE=&quot;10.0.0.0/24&quot;NETWORK_GATEWAY=&quot;10.0.0.2&quot;Q_FLOATING_ALLOCATION_POOL=start=192.168.1.150,end=192.168.1.180PUBLIC_NETWORK_GATEWAY=&quot;192.168.1.200&quot;Q_L3_ENABLED=TruePUBLIC_INTERFACE=eth0Q_USE_PROVIDERNET_FOR_PUBLIC=TrueOVS_PHYSICAL_BRIDGE=br-exPUBLIC_BRIDGE=br-exOVS_BRIDGE_MAPPINGS=public:br-ex# #VLAN configuration.Q_PLUGIN=ml2ENABLE_TENANT_VLANS=True# LoggingLOGFILE=/home/stack/logs/stack.sh.logVERBOSE=TrueLOG_COLOR=TrueSCREEN_LOGDIR=/home/stack/logs 以stack用户身份运行脚本安装123[root@controller ~]# su stack[root@controller ~]# cd /home/devstack/[root@controller devstack]# ./stack.sh]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7 安装KVM虚拟机]]></title>
      <url>%2F2017%2F05%2F04%2FCentOS-7-%E5%AE%89%E8%A3%85KVM%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
      <content type="text"><![CDATA[kvm相关安装包及其作用qemu-kvm 主要的KVM程序包python-virtinst 创建虚拟机所需要的命令行工具和程序库virt-manager GUI虚拟机管理工具virt-top 虚拟机统计命令virt-viewer GUI连接程序，连接到已配置好的虚拟机libvirt C语言工具包，提供libvirt服务libvirt-client 为虚拟客户机提供的C语言工具包virt-install 基于libvirt服务的虚拟机创建命令bridge-utils 创建和管理桥接设备的工具 验证CPU是否支持KVM；如果结果中有vmx（Intel）或svm(AMD)字样，就说明CPU的支持的。1[root@object1 ~]# egrep &apos;(vmx|svm)&apos; /proc/cpuinfo 安装KVM及其依赖项1[root@object1 ~]# yum install qemu-kvm virt-install bridge-utils libvirt virt-install virt-manager -y 验证安装结果123[root@object1 ~]# lsmod | grep kvmkvm_intel 162153 0 kvm 525409 1 kvm_intel 开启kvm服务，并且设置其开机自动启动12[root@object1 ~]# systemctl start libvirtd[root@object1 ~]# systemctl enable libvirtd 配置网桥模式1234567891011121314151617181920212223242526272829303132333435363738394041//创建 ifcfg-br0 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 BOOTPROTO=&quot;static&quot;DEVICE=&quot;br0&quot;NAME=&quot;br0&quot;TYPE=&quot;Bridge&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.1.226&quot;NETMASK=&quot;255.255.255.0&quot;GATEWAY=&quot;192.168.1.200&quot;DNS1=&quot;114.114.114.114&quot;DNS2=&quot;8.8.8.8&quot;//修改ifcfg-eno16777736 文件[root@object1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eno16777736 #TYPE=&quot;Ethernet&quot;#BOOTPROTO=&quot;static&quot;#DEFROUTE=&quot;yes&quot;#PEERDNS=&quot;yes&quot;#PEERROUTES=&quot;yes&quot;#IPV4_FAILURE_FATAL=&quot;no&quot;#IPV6INIT=&quot;yes&quot;#IPV6_AUTOCONF=&quot;yes&quot;#IPV6_DEFROUTE=&quot;yes&quot;#IPV6_PEERDNS=&quot;yes&quot;#IPV6_PEERROUTES=&quot;yes&quot;#IPV6_FAILURE_FATAL=&quot;no&quot;#NAME=&quot;eno16777736&quot;#UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;#DEVICE=&quot;eno16777736&quot;#ONBOOT=&quot;yes&quot;#IPADDR=192.168.1.226#NETMASK=255.255.255.0#GATEWAY=192.168.1.200#PEERDNS=&quot;yes&quot;#DNS1=8.8.8.8NAME=&quot;eno16777736&quot;UUID=&quot;f3f3b4f8-02ad-44f4-83f7-3639f4df3bff&quot;DEVICE=&quot;eno16777736&quot;BRIDGE=&quot;br0&quot;ONBOOT=&quot;yes&quot; 重启网络服务12345[root@object1 ~]# systemctl restart network[root@object1 ~]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000c29e16c76 no eno16777736virbr0 8000.000000000000 yes 安装虚拟机//下载cirros linux，下载地址：http://download.cirros-cloud.net/1[root@object1 ~]# virt-install -n test001 -r 2048 --disk /home/test.img,format=qcow2,size=1 --network bridge=br0 --os-type=linux --os-variant=rhel7.2 --cdrom /root/cirros-0.3.5-x86_64-disk.img --vnc --vncport=5900 --vnclisten=0.0.0.0 使用VNC Viewer连接该虚拟机官网下载：https://www.realvnc.com/download/vnc/ //通过图形界面操作 安装X(X Window System)1[root@object1 ~]# yum groupinstall &quot;X Window System&quot; -y 安装GNOME(GNOME Desktop)1[root@object1 ~]# yum groupinstall &quot;GNOME Desktop&quot; -y 使用virt-manager管理kvm//本地需要安装xmanager和xshell工具 ，并使用xshell建立连接时勾选x11转移。1[root@object1 ~]# virt-manager]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搭建FastDFS分布式文件系统]]></title>
      <url>%2F2017%2F05%2F03%2F%E6%90%AD%E5%BB%BAFastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[FastDFS介绍FastDFS是一款类Google FS的开源分布式文件系统，它用纯C语言实现，支持Linux、FreeBSD、AIX等UNIX系统。它只能通过专有API对文件进行存取访问，不支持POSIX接口方式，不能mount使用。准确地讲，Google FS以及FastDFS、mogileFS、HDFS、TFS等类Google FS都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。 FastDFS是一个开源的，高性能的的分布式文件系统，他主要的功能包括：文件存储，同步和访问，设计基于高可用和负载均衡，fastfd非常适用于基于文件服务的站点，例如图片分享和视频分享网站。FastDFS有两个角色：跟踪服务和存储服务，跟踪服务控制，调度文件以负载均衡的方式访问；存储服务包括：文件存储，文件同步，提供文件访问接口，同时以key value的方式管理文件的元数据。跟踪和存储服务可以由1台或者多台服务器组成，同时可以动态的添加，删除跟踪和存储服务而不会对在线的服务产生影响，在集群中，tracker服务是对等的。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 FastDFS架构客户端和Storage server主动连接Tracker server。Storage server主动向Tracker server报告其状态信息，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。Storage server会连接集群中所有的Tracker server，向他们报告自己的状态。Storage server启动一个单独的线程来完成对一台Tracker server的连接和定时报告。需要说明的是，一个组包含的Storage server不是通过配置文件设定的，而是通过Tracker server获取到的。不同组的Storage server之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步。Storage server采用binlog文件记录文件上传、删除等更新操作。binlog中只记录文件名，不记录文件内容。文件同步只在同组内的Storage server之间进行，采用push方式，即源头服务器同步给目标服务器。只有源头数据才需要同步，备份数据并不需要再次同步，否则就构成环路了。有个例外，就是新增加一台Storage server时，由已有的一台Storage server将已有的所有数据（包括源头数据和备份数据）同步给该新增服务器。Storage server中由专门的线程根据binlog进行文件同步。为了最大程度地避免相互影响以及出于系统简洁性考虑，Storage server对组内除自己以外的每台服务器都会启动一个线程来进行文件同步。文件同步采用增量同步方式，系统记录已同步的位置（binlog文件偏移量）到标识文件中。标识文件名格式：{dest storage IP}_{port}.mark，例如：192.168.1.14_23000.mark。 FastDFS文件上传下载交互过程 文件下载流程 Client询问Tracker server可以下载指定文件的Storage server，参数为文件ID（包含组名和文件名）； Tracker server返回一台可用的Storage server； Client直接和该Storage server建立连接，完成文件下载。文件上传流程 Client询问Tracker server上传到的Storage server； Tracker server返回一台可用的Storage server，返回的数据为该Storage server的IP地址和端口； Client直接和该Storage server建立连接，进行文件上传，Storage server返回新生成的文件ID，文件上传结束。 FastDFS安装系统环境1CentOS Linux release 7.2.1511 (Core) 下载并安装FastDFS依赖包libfastcommon12345[root@object1 ~]# wget https://codeload.github.com/happyfish100/libfastcommon/zip/master[root@object1 ~]# unzip master[root@object1 ~]# cd libfastcommon-master/[root@object1 libfastcommon-master]# ./make.sh[root@object1 libfastcommon-master]# ./make.sh install 下载并安装FastDFS1234[root@object1 ~]# wget https://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Server%20Source%20Code/FastDFS%20Server%20with%20PHP%20Extension%20Source%20Code%20V5.08/FastDFS_v5.08.tar.gz[root@object1 ~]# tar zxvf FastDFS_v5.08.tar.gz [root@object1 ~]# cd FastDFS[root@object1 FastDFS]# ./make.sh &amp;&amp; ./make.sh install 默认脚本目录1[root@object1 ~]# ll /etc/init.d/ | grep fdfs 样例配置文件1[root@object1 ~]# ll /etc/fdfs/ 注意：虽然FastDFS区分tracker和storage服务器，但是安装的软件及步骤均相同，只是不同的配置文件而已，因此以上安装适用tracker server和storage server 配置跟踪服务器（tracker server）拷贝tracker server和client端样例配置文件并重命名12[root@object1 ~]# cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf[root@object1 ~]# cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 修改client.conf12第14行 tracker_server=192.168.1.226:22122 启动tracker server12[root@object1 ~]# /etc/init.d/fdfs_trackerd start[root@object1 ~]# ss -tunlp | grep 22122 配置存储服务器（storage server）拷贝storage server样例配置文件并重命名1[root@object1 ~]# cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 修改storage.conf12第118行tracker_server=192.168.1.226:22122 启动storage server（启动storage server的前提是tracker server必须事先已启动）12[root@object1 ~]# /etc/init.d/fdfs_storaged start[root@object1 ~]# ss -tunlp | grep 23000 文件上传测试12[root@object1 ~]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/test.jpg group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg 存储服务器（storage server）安装并配置nginx下载并安装fastdfs-nginx-module模块注：FastDFS通过Tracker服务器,将文件放在Storage服务器存储，但是同组存储服务器之间需要进入文件复制，有同步延迟的问题。假设Tracker服务器将文件上传到了192.168.1.226，上传成功后文件ID已经返回给客户端。此时FastDFS存储集群机制会将这个文件同步到同组存储192.168.1.227，在文件还没有复制完成的情况下，客户端如果用这个文件ID在192.168.1.227上取文件,就会出现文件无法访问的错误。而fastdfs-nginx-module可以重定向文件连接到源服务器取文件,避免客户端由于复制延迟导致的文件无法访问错误。 12345678910[root@object1 ~]# wget http://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Nginx%20Module%20Source%20Code/fastdfs-nginx-module_v1.16.tar.gz[root@object1 ~]# tar zxvf fastdfs-nginx-module_v1.16.tar.gz [root@object1 ~]# cd fastdfs-nginx-module/src/[root@object1 src]# vim config 编辑config文件，执行如下命令进行批量替换并保存退出:%s+/usr/local/+/usr/+g[root@object1 src]# cp mod_fastdfs.conf /etc/fdfs/修改mod_fastdfs.conf第40行tracker_server=192.168.1.226:22122 安装nginx依赖库1[root@object1 ~]# yum install -y pcre-devel zlib-devel nginx 安装nginx12345[root@object1 ~]# wget http://nginx.org/download/nginx-1.13.0.tar.gz[root@object1 ~]# tar zxvf nginx-1.13.0.tar.gz[root@object1 ~]# cd nginx-1.13.0[root@object1 nginx-1.13.0]# ./configure --prefix=/usr/local/nginx --add-module=/root/fastdfs-nginx-module/src/[root@object1 nginx-1.13.0]# make &amp;&amp; make install 拷贝FastDFS中的部分配置文件到/etc/fdfs目录中12[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/http.conf /etc/fdfs/[root@object1 nginx-1.13.0]# cp /root/FastDFS/conf/mime.types /etc/fdfs/ 配置nginx123456789[root@object1 ~]# vim /usr/local/nginx/conf/nginx.conf修改1行user root; #解决下载操作时报404的问题修改36行listen 8888; #storage.conf配置文件一致添加location ~/group[0-9]/ &#123; ngx_fastdfs_module; &#125; 拷贝nginx服务到/etc/init.d/目录下并启动123[root@object1 ~]# cp /usr/local/nginx/sbin/nginx /etc/init.d/[root@object1 ~]# /etc/init.d/nginx[root@object1 ~]# ss -tunlp | grep 8888 通过浏览器访问之前已经上传的文件123456789101112http://192.168.1.226:8888/group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg访问出现400 Bad Request查看日志[root@object1 ~]# vim /usr/local/nginx/logs/error.log 报错信息[2017-05-03 17:00:38] ERROR - file: ../common/fdfs_global.c, line: 52, the format of filename &quot;group1/M00/00/00/wKgB4lkJlSSADZazAAMuQxWPTP8989.jpg&quot; is invalid解决方法：[root@object1 ~]# vim /etc/fdfs/mod_fastdfs.conf修改53行url_have_group_name = true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记录MongoDB3.4分片的一些配置]]></title>
      <url>%2F2017%2F05%2F03%2F%E8%AE%B0%E5%BD%95MongoDB3.4%E5%88%86%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[MongoDB介绍MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB特点 MongoDB的提供了一个面向文档存储，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Ning”,Address=”Beijing”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装yum安装官网：https://docs.mongodb.com/master/tutorial/install-mongodb-on-red-hat/ 123456789[root@object1 ~]# vim /etc/yum.repos.d/mongodb-org-3.4.repo[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc[root@object1 ~]#sudo yum install -y mongodb-org 下载官网：https://www.mongodb.com/download-center?jmp=nav#community 123456[root@object1 ~]#curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.4.tgz[root@object1 ~]#tar -zxvf mongodb-linux-x86_64-rhel70-3.4.4.tgz [root@object1 ~]# mv mongodb-linux-x86_64-rhel70-3.4.4 /usr/local/mongodb#把安装目录添加到系统环境中export PATH=/usr/local/mongodb/bin:$PATH 配置文件官网：https://docs.mongodb.com/manual/administration/configuration/ 12345678910111213141516171819202122232425262728#使用YAML配置也可以使用原ini配置#基本设置processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: true#安全security: authorization: enablednet: bindIp: 192.168.1.226 port: 27017#副本集replication: replSetName: set0#副本集安全security: keyFile: /home/mongodb/keyfile 分片配置分片服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truenet: bindIp: 192.168.1.226 port: 27017sharding: clusterRole: shardsvrreplication: replSetName: shardA 配置服务器 12345678910111213141516171819processManagement: fork: true pidFilePath: /home/mongodb/mongodb.pidstorage: dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongod.log&quot; logAppend: truestorage: journal: enabled: truesharding: clusterRole: configsvrnet: bindIp: 192.168.1.226 port: 27001replication: replSetName: csRS 路由服务器 1234567891011121314151617processManagement: fork: true pidFilePath: /home/mongodb/mongos.pid#storage:# dbPath: /home/mongodb/datasystemLog: destination: file path: &quot;/home/mongodb/log/mongos.log&quot; logAppend: true#storage:# journal:# enabled: truenet: bindIp: 192.168.1.226 port: 28001sharding: configDB: csRS/192.168.1.226:27001,192.168.1.226:27002,192.168.1.226:27003 启动mongodb123[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 分片服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongod -f 配置服务器配置文件[root@object1 ~]# /usr/local/mongodb/bin/mongos -f 路由服务器配置文件 初始化mongodb分片服务器 12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27017&gt;use admin&gt;config = &#123;_id:&quot;shardA&quot;,members:[&#123;_id:0, host:&quot;192.168.1.226:27017&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27018&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27019&quot;&#125;]&#125;&gt;rs.initiate(config) 配置服务器12345678[root@object1 ~]# /usr/local/mongodb/bin/mongo --port 27001&gt;use admin&gt;config = &#123;_id:&quot;csRS&quot;,configsvr:true,members:[&#123;_id:0, host:&quot;192.168.1.226:27001&quot;&#125;,&#123;_id:1, host:&quot;192.168.1.226:27002&quot;&#125;,&#123;_id:2, host:&quot;192.168.1.226:27003&quot;&#125;]&#125;&gt;rs.initiate(config) 启动分片123[root@object1 mongodb]# mongo --port 28001mongos&gt; use adminmongos&gt; db.runCommand( &#123; addShard: &quot;shardA/192.168.1.226:27017,192.168.1.226:27018,192.168.1.226:27019&quot;&#125; )]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7 LDAP统一认证部署]]></title>
      <url>%2F2017%2F05%2F02%2FCentOS7-LDAP%E7%BB%9F%E4%B8%80%E8%AE%A4%E8%AF%81%E9%83%A8%E7%BD%B2%2F</url>
      <content type="text"><![CDATA[LDAP介绍LDAP是轻量目录访问协议，英文全称是Lightweight Directory Access Protocol，简称为LDAP。它是基于X.500标准的，但是简单多了并且可以根据需要定制。与X.500不同，LDAP支持TCP/IP。LDAP的核心规范在RFC中都有定义，所有与LDAP相关的RFC都可以在LDAPman RFC网页中找到。 使用目的使用LDAP对运维相关用户名密码做统一管理。可以实现一个帐号登录多个不同系统。 LDAP部署LDAP Server端安装1[root@object1 ~]# yum install -y openldap openldap-clients openldap-servers migrationtools LDAP 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#配置 OpenLDAP Server[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;2\&#125;hdb.ldif dn: olcDatabase=&#123;2&#125;hdb修改两行olcSuffix: dc=hyman,dc=comolcRootDN: cn=Manager,dc=hyman,dc=com新增一行olcRootPW: 123456#配置 Monitoring Database[root@object1 ~]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;1\&#125;monitor.ldifdn: olcDatabase=&#123;1&#125;monitor修改一行olcAccess: &#123;0&#125;to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=extern al,cn=auth&quot; read by dn.base=&quot;cn=Manager,dc=hyman,dc=com&quot; read by * none#初始化 LDAP database[root@object1 ~]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG[root@object1 ~]# chown -R ldap.ldap /var/lib/ldap/#测试 configuration[root@object1 ~]# slaptest -u#启动服务并开机自启[root@object1 ~]# systemctl start slapd[root@object1 ~]# systemctl enable slapd#查看状态[root@object1 ~]# netstat -lt | grep ldap#将所有的配置LDAP server, 添加到LDAP schemas中[root@object1 ~]# cd /etc/openldap/schema/ ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f cosine.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f nis.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f collective.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f corba.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f core.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f duaconf.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f dyngroup.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f inetorgperson.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f java.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f ppolicy.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f pmi.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f openldap.ldif[root@object1 schema]# ldapadd -Y EXTERNAL -H ldapi:/// -D &quot;cn=config&quot; -f misc.ldif#使用Migration Tools 创建 LDAP DIT[root@object1 schema]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_common.ph修改61行$NAMINGCONTEXT&#123;&apos;group&apos;&#125; = &quot;ou=Groups&quot;;修改71行$DEFAULT_MAIL_DOMAIN = &quot;hyman.com&quot;;修改74行$DEFAULT_BASE = &quot;dc=hyman,dc=com&quot;;修改90行$EXTENDED_SCHEMA = 1;#创建 base.ldif[root@object1 migrationtools]# ./migrate_base.pl &gt; /root/base.ldif#导入LDAP database[root@object1 migrationtools]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f /root/base.ldif#创建用户和用户组，并将其从本地数据库迁移到LDAP数据库[root@object1 migrationtools]# mkdir /home/guests[root@object1 migrationtools]# useradd -d /home/guests/ldapuser1 ldapuser1[root@object1 migrationtools]# useradd -d /home/guests/ldapuser2 ldapuser2[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser1[root@object1 migrationtools]# echo &quot;password&quot; | passwd --stdin ldapuser2#过滤掉这些用户和组和密码从/etc/shadow到不同的文件[root@object1 ~]# getent passwd | tail -n 5 &gt; /root/users[root@object1 ~]# getent shadow | tail -n 5 &gt; /root/shadow[root@object1 ~]# getent group | tail -n 5 &gt; /root/groups#创建这些用户使用migrationtools[root@object1 ~]# cd /usr/share/migrationtools/[root@object1 migrationtools]# vim migrate_passwd.pl 修改188行把 /etc/shadow 替换为 /root/shadow[root@object1 migrationtools]# ./migrate_passwd.pl /root/users &gt; users.ldif[root@object1 migrationtools]# ./migrate_passwd.pl /root/groups &gt; groups.ldif#上传这些用户和组LDAP数据库[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f users.ldif[root@object1 ~]# ldapadd -x -W -D &quot;cn=Manager,dc=hyman,dc=com&quot; -f groups.ldif#所有记录搜索LDAP DIT[root@object1 ~]# ldapsearch -x -b &quot;dc=hyman,dc=com&quot; -H ldap://127.0.0.1 LDAP 客户端验证1234[root@block1 ~]# yum install -y nss-pam*[root@block1 ~]# authconfig-tui 选择第二个Use LDAP[root@block1 ~]# su ldaduser1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 7通过yum安装ansible]]></title>
      <url>%2F2017%2F04%2F27%2FCentOS-7%E9%80%9A%E8%BF%87yum%E5%AE%89%E8%A3%85ansible%2F</url>
      <content type="text"><![CDATA[一、ansible介绍1、ansible 简介Ansible官方的 title 是“Ansible is Simple IT Automation”——简单的自动化IT工具。Ansible是一款为类Unix系统开发的自由开源的配置和自动化工具。它用Python写成，类似于Chef和Puppet，但是有一个不同的优点是我们不需要在节点中安装任何客户端。它使用SSH来和节点进行通信。 2、ansible 特点（1） No agents：不需要在被管控主机上安装任意客户端；（2） No server：无服务器端，使用时直接运行命令即可；（3） Modules in any languages：基于模块工作，可使用任意语言开发模块（4） YAML，not code：使用yaml语言定制剧本playbook；（5） SSH by default：基于SSH工作；（6） Strong multi-tier solution：可实现多级指挥； 二、Ansible安装使用1、 设置EPEL仓库1[root@object1 ~]# rpm -iUvh http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm 2、使用yum安装Ansible1[root@object1 ~]# yum install -y ansible 3、设置用于节点鉴权的SSH密钥1234#在Ansible服务端生成密钥[root@object1 ~]# ssh-keygen #使用ssh-copy-id命令来复制Ansible公钥到节点中[root@object1 ~]# ssh-copy-id -i root@192.168.1.215 4、为Ansible定义节点的清单1234[root@object1 ~]# cat /etc/ansible/hosts[test]192.168.1.226192.168.1.215 5、尝试在Ansible服务端运行命令123456789101112131415161718192021222324252627282930313233343536#使用ping检查ansible节点的连通性[root@object1 ~]# ansible -m ping &apos;test&apos;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;#检查Ansible节点的运行时间（uptime）[root@object1 ~]# ansible -m command -a &quot;uptime&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 07:11:16 up 42 days, 13:43, 1 user, load average: 0.00, 0.00, 0.00#检查节点的内核版本[root@object1 ~]# ansible -m command -a &quot;uname -r&quot; &quot;test&quot;192.168.1.226 | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125;192.168.1.215 | SUCCESS | rc=0 &gt;&gt;2.6.32-573.3.1.el6.x86_64#给节点增加用户[root@object1 ~]# ansible -m command -a &quot;useradd test&quot; &quot;test&quot;192.168.1.226 | SUCCESS | rc=0 &gt;&gt;192.168.1.215 | SUCCESS | rc=0 &gt;&gt; 6、模块的使用查看各模块的使用方法12345ansible-doc [options] [modules] ：Show Ansible module documentation -l 列出所有的ansible模块 -s 列出该模块的相关指令可以直接使用 ansible-doc 模块名 来查看模块的使用，如# ansible-doc htpasswd 三、playbook的使用YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。 YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。 1、playbook使用1ansible-playbook test.yaml 下面就是一个只包含了一个play的playbook，在写playbook的时候，一定要记住在 hosts，yum（模块儿名）等后带空格，否则会报错。 12345678910111213141516171819202122#这个是你选择的主机- hosts: webservers#这个是变量 vars: http_port: 80 max_clients: 200#远端的执行权限 remote_user: root tasks:#利用yum模块来操作 - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf #触发重启服务器 notify: - restart apache - name: ensure apache is running service: name=httpd state=started #这里的restart apache 和上面的触发是配对的。这就是handlers的作用。相当于tag handlers: - name: restart apache service: name=httpd state=restarted 2、playbook案例corosync.yaml 12345678910111213141516171819202122232425262728293031323334353637- hosts: hanodes #指定要执行任务的主机，可由冒号分隔主机组 remote_user: root #指定远程主机上执行任务的用户 vars: #定义如下2个变量 crmsh: crmsh-1.2.6.4.el6.x86_64.rpm pssh: pssh-2.3.1-2.el6.x86_64.rpm tasks: #指定需执行的任务列表，每个task都有其name和使用的模块及参数 - name: test connection ping: #ping模块无需执行参数 remote_user: jason #在task中指定远程主机上执行任务的用户 sudo: yes #使用sudo在远程主机上执行任务 - name: corosync installing yum: name=corosync state=present - name: pacemaker installing #定义一个软件安装任务 yum: name=pacemaker state=present #使用yum安装，并配置需安装的软件名（name），及状态（state） - name: crmsh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; crmsh &#125;&#125; dest=/tmp/&#123;&#123; crmsh &#125;&#125; - name: pssh rpm packages copy: src=/ansible/corosync/packages/&#123;&#123; pssh &#125;&#125; dest=/tmp/&#123;&#123; pssh &#125;&#125; - name: crmsh installing command: yum -y reinstall /tmp/&#123;&#123; crmsh &#125;&#125; /tmp/&#123;&#123; pssh &#125;&#125; - name: authkey configure file copy: src=/ansible/corosync/conf/authkey dest=/etc/corosync/authkey - name: authkey mode 400 #定义一个文件权限设置任务 file: path=/etc/corosync/authkey mode=400 notify: #定义一个通知，当此任务执行时，可以激发响应的handler - restart corosync - name: corosync.conf configure file copy: src=/ansible/corosync/conf/corosync.conf dest=/etc/corosync/corosync.conf tags: - conf notify: - restart corosync - name: ensure the corosync service startup on boot service: name=corosync state=started enabled=yes handlers: #定义当关注的资源发生变化时，需采取的操作 - name: restart corosync #定义一个服务重启任务 service: name=corosync state=restarted heartbeat.yaml 123456789101112131415161718- hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper、Dubbo-Admin管理平台的搭建]]></title>
      <url>%2F2017%2F04%2F26%2FZookeeper%E3%80%81Dubbo-Admin%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。 ZooKeeper官网为：http://zookeeper.apache.org/ Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容。 Dubbo官网为：http://dubbo.io/ 一、zookeeper安装与启动首先需要安装JdK，从Oracle的Java网站下载，安装很简单，就不再详述。zookeeper的下载地址 1http://www.apache.org/dyn/closer.cgi/zookeeper/ 下载后直接解压，不用安装 1[root@object1 home]# tar zxvf zookeeper-3.4.10.tar.gz 修改默认配置 1[root@object1 conf]# cp zoo_sample.cfg zoo.cfg 参数说明: tickTime：zookeeper中使用的基本时间单位, 毫秒值这个时间是作为Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：数据目录. 可以是任意目录，默认情况下，Zookeeper 将写数据 的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 至此, zookeeper的单机模式已经配置好了，启动ZooKeeper 1[root@object1 zookeeper-3.4.10]# sh bin/zkServer.sh start 二、Dubbo-admin管理平台的安装因为zookeeper只是一个黑框，我们无法看到是否存在了什么提供者或消费者，这时就要借助Dubbo-Admin管理平台来实时的查看，也可以通过这个平台来管理提者和消费者。制作了基于jdk1.8打包的dubbo-admin.war 下载地址 1http://download.csdn.net/detail/qq_30567735/9826361 dubbo源码 1https://github.com/alibaba/dubbo 下载好dubbo-admin.war后，我们就可以按常用的web部署方式进行部署即可，把war包放到tomcat的webapps目录下，启动tomcat，后再部署下相应的参数。 启动tomcat 1[root@object1 apache-tomcat-7.0.62]# sh bin/startup.sh 访问项目地址即可 1http: //ip地址:端口号/dubbo-admin-2.5.4/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL自带压力测试工具mysqlslap的使用方法]]></title>
      <url>%2F2017%2F04%2F26%2FMySQL%E8%87%AA%E5%B8%A6%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7mysqlslap%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[mysqlslap是从5.1.4版开始的一个MySQL官方提供的压力测试工具。通过模拟多个并发客户端访问MySQL来执行压力测试，并输出计时信息。并且能很好的对比多个存储引擎在相同环境下的并发压力性能差别。可以指定SQL语句。如果没有指定SQL语句，mysqlslap会自动生成查询schema的SELECT语句。 1、查看帮助信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126[root@object1 local]# mysqlslap --helpmysqlslap Ver 1.0 Distrib 5.7.18, for Linux (x86_64)Copyright (c) 2005, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Run a query multiple times against the server.Usage: mysqlslap [OPTIONS]Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf The following groups are read: mysqlslap clientThe following options may be given as the first argument:--print-defaults Print the program argument list and exit.--no-defaults Don&apos;t read default options from any option file, except for login file.--defaults-file=# Only read default options from the given file #.--defaults-extra-file=# Read this file after the global files are read.--defaults-group-suffix=# Also read groups with concat(group, suffix)--login-path=# Read this path from the login file. -?, --help Display this help and exit. -a, --auto-generate-sql 自动生成测试表和数据 Generate SQL where not supplied by file or command line. --auto-generate-sql-add-autoincrement 增加auto_increment一列 Add an AUTO_INCREMENT column to auto-generated tables. --auto-generate-sql-execute-number=# 自动生成的查询的个数 Set this number to generate a set number of queries to run. --auto-generate-sql-guid-primary 增加基于GUID的主键 Add GUID based primary keys to auto-generated tables. --auto-generate-sql-load-type=name 测试语句的类型。取值包括：read，key，write，update和mixed(默认) Specify test load type: mixed, update, write, key, or read; default is mixed. --auto-generate-sql-secondary-indexes=# 增加二级索引的个数，默认是0 Number of secondary indexes to add to auto-generated tables. --auto-generate-sql-unique-query-number=# 不同查询的数量，默认值是10 Number of unique queries to generate for automatic tests. --auto-generate-sql-unique-write-number=# 不同插入的数量，默认是100 Number of unique queries to generate for auto-generate-sql-write-number. --auto-generate-sql-write-number=# Number of row inserts to perform for each thread (default is 100). --commit=# 多少条DML后提交一次 Commit records every X number of statements. -C, --compress 如果服务器和客户端支持都压缩，则压缩信息传递 Use compression in server/client protocol. -c, --concurrency=name 模拟N个客户端并发执行select。可指定多个值，以逗号或者 --delimiter 参数指定的值做为分隔符 Number of clients to simulate for query to run. --create=name 指定用于创建表的.sql文件或者字串 File or string to use create tables. --create-schema=name 指定待测试的数据库名，MySQL中schema也就是database，默认是mysqlslap Schema to run tests in. --csv[=name] Generate CSV output to named file or to stdout if no file is named. -#, --debug[=#] This is a non-debug version. Catch this and exit. --debug-check This is a non-debug version. Catch this and exit. -T, --debug-info 打印内存和CPU的信息 This is a non-debug version. Catch this and exit. --default-auth=name Default authentication client-side plugin to use. -F, --delimiter=name 文件中的SQL语句使用分割符号 Delimiter to use in SQL statements supplied in file or command line. --detach=# 每执行完N个语句，先断开再重新打开连接 Detach (close and reopen) connections after X number of requests. --enable-cleartext-plugin Enable/disable the clear text authentication plugin. -e, --engine=name 创建测试表所使用的存储引擎，可指定多个 Storage engine to use for creating the table. -h, --host=name Connect to host. -i, --iterations=# 迭代执行的次数 Number of times to run the tests. --no-drop Do not drop the schema after the test. -x, --number-char-cols=name 自动生成的测试表中包含多少个字符类型的列，默认1 Number of VARCHAR columns to create in table if specifying --auto-generate-sql. -y, --number-int-cols=name 自动生成的测试表中包含多少个数字类型的列，默认1 Number of INT columns to create in table if specifying --auto-generate-sql. --number-of-queries=# 总的测试查询次数(并发客户数×每客户查询次数) Limit each client to this number of queries (this is not exact). --only-print 只输出模拟执行的结果，不实际执行Do not connect to the databases, but instead print out what would have been done. -p, --password[=name] Password to use when connecting to server. If password is not given it&apos;s asked from the tty. --plugin-dir=name Directory for client-side plugins. -P, --port=# Port number to use for connection. --post-query=name 测试完成以后执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute after tests have completed. --post-system=name 测试完成以后执行的系统语句 这个过程不影响时间计算system() string to execute after tests have completed. --pre-query=name 测试执行之前执行的SQL语句的文件或者字符串 这个过程不影响时间计算Query to run or file containing query to execute before running tests. --pre-system=name 测试执行之前执行的系统语句 这个过程不影响时间计算system() string to execute before running tests. --protocol=name The protocol to use for connection (tcp, socket, pipe, memory). -q, --query=name 指定自定义.sql脚本执行测试。例如可以调用自定义的一个存储过程或者sql语句来执行测试Query to run or file containing query to run. --secure-auth Refuse client connecting to server if it uses old (pre-4.1.1) protocol. Deprecated. Always TRUE -s, --silent 不输出Run program in silent mode - no output. -S, --socket=name The socket file to use for connection. --sql-mode=name Specify sql-mode to run mysqlslap tool. --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) --ssl-verify-server-cert Deprecated. Use --ssl-mode=VERIFY_IDENTITY instead. --ssl-ca=name CA file in PEM format. --ssl-capath=name CA directory. --ssl-cert=name X509 cert in PEM format. --ssl-cipher=name SSL cipher to use. --ssl-key=name X509 key in PEM format. --ssl-crl=name Certificate revocation list. --ssl-crlpath=name Certificate revocation list path. --tls-version=name TLS version to use, permitted values are: TLSv1, TLSv1.1 -u, --user=name User for login if not current user. -v, --verbose 输出更多的信息More verbose output; you can use this multiple times to get even more verbose output. -V, --version Output version information and exit. 2、以自动生成测试表和数据的形式，分别模拟 50 和 100 个客户端并发连接处理 1000 个 query 的情况。 123456789101112131415[root@object1 local]# mysqlslap -uroot -p&apos;CAOcao123~!@&apos; -a --concurrency=50,100 --number-of-queries=1000 mysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Average number of seconds to run all queries: 0.605 seconds Minimum number of seconds to run all queries: 0.605 seconds Maximum number of seconds to run all queries: 0.605 seconds Number of clients running queries: 50 Average number of queries per client: 20Benchmark Average number of seconds to run all queries: 0.534 seconds Minimum number of seconds to run all queries: 0.534 seconds Maximum number of seconds to run all queries: 0.534 seconds Number of clients running queries: 100 Average number of queries per client: 10 3、增加 –debug-info 选项，可以输出内存和CPU信息。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7通过yum安装最新版本MySQL]]></title>
      <url>%2F2017%2F04%2F26%2FCentOS7%20yum%E5%AE%89%E8%A3%85MySQL%2F</url>
      <content type="text"><![CDATA[CentOS 7之后的版本yum的默认源中使用MariaDB替代原先MySQL，因此安装方式较为以往有一些改变： 卸载原来的MariaDB 1yum remove -y mariadb-config-3:10.1.17-1.el7.x86_64 下载mysql的源 1wget http://dev.mysql.com/get/mysql57-community-release-el7-7.noarch.rpm 安装yum库 1yum localinstall -y mysql57-community-release-el7-7.noarch.rpm 安装MySQL 1yum install -y mysql-community-server 启动MySQL服务 1systemctl start mysqld.service MySQL5.7加强了root用户的安全性，因此在第一次安装后会初始化一个随机密码，以下为查看初始随机密码的方式 1grep &apos;temporary password&apos; /var/log/mysqld.log 使用初始随机密码登录后MySQL会强制要求修改密码，否则无法正常使用，（密码必须包含小写、大写字母及特殊字符，当然也有其他方法不受此限制，再次不多做描述），修改方法如下： 123SET PASSWORD = PASSWORD(&apos;your new password&apos;);ALTER USER &apos;root&apos;@&apos;localhost&apos; PASSWORD EXPIRE NEVER;flush privileges; 然后退出后即可用新密码登录。 远程连接授权： 1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;your password&apos; WITH GRANT OPTION;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo+github+next搭建的blog]]></title>
      <url>%2F2017%2F01%2F13%2FHexo-github-next%E6%90%AD%E5%BB%BA%E7%9A%84blog%2F</url>
      <content type="text"><![CDATA[搭建环境：Windows 10 软件工具：git、node.js、hexo、Markdownpad2 一、环境搭建 安装git git官网(http://git-scm.com) 安装Node.js node.js官网(https://nodejs.org/en/) 二、安装和配置Hexo 执行cmd命令 npm install -g hexo-cli 本地创建Hexo文件夹，本目录下执行cmd命令 hexo init npm install 启动Hexo hexo server 更改hexo主题，在Hexo目录下载next主题 git clone https://github.com/iissnan/hexo-theme-next themes/next 修改Hexo配置文件_config.yml theme: next 重启Hexo，基本更改过来了，其他修改具体查看GITBUB 创建文章，执行cmd命令 hexo new 文章主题 执行命令后，在文件下的source_posts，自动生成以后缀为md的文件，修改md内容 生成html文件，执行cmd命令 hexo d -g 自动会生存静态文件在public文件夹下，把里面的文件全部上传至自己的github下即可]]></content>
    </entry>

    
  
  
</search>
